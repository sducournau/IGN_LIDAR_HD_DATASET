Sidebar menu
Search
Write
Notifications

Simon Ducournau
Home
Library
Profile
Stories
Stats
Following
Florent Poux, Ph.D.
Florent Poux, Ph.D.
Find writers and publications to follow.

See suggestions
TDS Archive
TDS Archive
An archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.

Follow publication


1

Top highlight

Member-only story

3D Python
3D Geospatial Data Integration with Python: The Ultimate Guide
Tutorial to integrate geospatial data with a multi-modal Python workflow: combine 3D point clouds, CityGML, voxels, vector + raster data
Florent Poux, Ph.D.
Florent Poux, Ph.D.

Following
39 min read
Â·
Nov 7, 2023
1K


8





The pace of technological progress is just plain crazy nowadays. Even more so when looking at how vital 3D data is for geospatial analysis and digital twins. Being able to capture and analyze data in three dimensions means we can create precise representations of real-world objects and environments.

Press enter or click to view image in full size
The scope of 3D Data Capture by Florent Poux
3D Spatial Data Integration goes through understanding the scope of 3D Data Capture. Â© F. Poux
ğŸ¦„Mila: A picture is worth a thousand words. So what about Digital Twins?

This is especially important for fields like urban planning, infrastructure management, and disaster response.

By incorporating 3D data, we can enhance our ability to make informed decisions by relying on precise and reliable data representations. Furthermore, the integration of this data into digital twins can produce remarkably lifelike replicas of real-world assets and systems, thereby increasing the efficiency of simulation and analysis.

BUT (there is always a but), effective geospatial analysis and digital twin creation rely on efficiently integrating and visualizing different data formats. To achieve this, itâ€™s essential to have a comprehensive understanding of the various data modalities and how they can be seamlessly integrated and visualized together. In data terms, we want to create a unified and comprehensive representation of an area with data overlap. How lucky are we, because this is precisely what we will unlock today!

Press enter or click to view image in full size
How to create Spatial Digital World through 3D Data Integration. Many sources of information, such as vector, raster data, 3D point clouds, or 3D city models, can be combined to form a unified view of what happens on our planet. Â© F. Poux
To constitute a Spatial Digital World, we must study 3D Data Integration. Many sources of information, such as vector, raster data, 3D point clouds, or 3D city models, can be combined to form a unified view of what happens on our planet. Â© F. Poux
In this hands-on guide, I provide a reference system-oriented workflow for 3D data integration with Python. So no need for expensive software or a large serialized pipeline of bricks without mortar! Just our Python friend and a carefully selected tiny range of robust modules and functions.

The ultimate goal of this initiative is that you have a comprehensive guide and companion that will follow you along your 3D data journey! The workflow is structured in seven distinctive phases, as shown below.

Press enter or click to view image in full size
The 3D Data Integration Workflow with Python. It is a Seven-Step Process to produce unified data-centric views. Â© F. Poux
The 3D Data Integration Workflow with Python. It is a Seven-Step Process to produce unified data-centric views. Â© F. Poux
Each phase builds progressively to ensure that you can start from scratch or plug into your existing system modularly. Because it is exhaustively constructed, a table of contents will make it easier for you to go through!

Chapter 1. 3D Python Setup
1.1. Environment Setup
1.2. Base Libraries
1.3. 3D Data Libraries
1.4. Geospatial Libraries
1.5. IDE Setup

Chapter 2. Multi-Modal Data Curation
2.1. 3D Data Sourcing
2.2. Spatial Raster (GIS)
2.3. Vector Data (GIS)
2.4. Other Sources

Chapter 3. Data Analysis and Profiling
3.1. 3D Point Clouds and voxels
3.2. 3D mesh and city models
3.3. Spatial / Raster Imagery
3.4. DSM, DTM, CHM

Chapter 4. Registration / Reprojection
4.1. Selecting a Reference System
4.2. Data Georeferencing
4.3. Data Reprojection
4.4. Rigid Registration

Chapter 5. Data Pre-Processing
5.1. Data Cleaning
5.2. Data Transformation
5.3. Data Reduction
5.4. Data Enrichment (Fusion)

Chapter 6. Data Visualization and Validation
6.1. 3D Data Inspection
6.2. Point Cloud Canonical Link
6.3. Hybrid Multi-Modal Visualization
6.4. Projection-based Inspection

Chapter 7. Data Sharing
7.1. Selection Method Definition
7.2. Data Organization
7.3. File Format Definition
7.4 Export and External Use
Whenever you are ready, let us jump together on this marvelous quest to 3D Data Integration, with a coffee lying around, but not too close to your computer â˜• (speaking from devastating experience)

ğŸµ Note to Readers: This hands-on guide is part of a UTWENTE joint work with co-authors ğŸ¦Š F. Poux, ğŸ¦„ M. Koeva, and ğŸ¦ P. Nourian. We acknowledge the financial contribution from the digital twins @ITC -project granted by the ITC faculty of the University of Twente. All images are Â© F. Poux

Step 1. Implementation Setup for 3D Data
Press enter or click to view image in full size
Implementation Setup for 3D Data by Florent Poux
Step 1. Implementation Setup for 3D Data. Â© F. Poux
The first mission is quickly setting up a lightweight environment for developing our 3D Data Integration workflow. This is a simple phase, but ensuring a proper setup is the key to scalability and replication. So let us get on top of things!

Press enter or click to view image in full size
The Environment Setup of a 3D Data Science Project. It is made of base libraries, 3D Data libraries, Geospatial libraries, and an IDE. All of this is on top of virtual environment management and Python. Â© F. Poux
The Environment Setup comprises base libraries, 3D Data libraries, Geospatial libraries, and an IDE. All of this is on top of virtual environment management and Python. Â© F. Poux
A Lightweight Environment Setup
Python environment setup using Anaconda, robust libraries, and an Integrated Development Environment (IDE) does not have to be painful. Anaconda provides a convenient way to manage Python packages and environments, and you can then use a powerful IDE such as Jupyter Lab or Spyder to make coding a breeze. For a detailed view of the process of setting up a 3D Python development environment, I recommend that you check out the following article:

3D Python Workflows for LiDAR City Models: A Step-by-Step Guide
The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling Applications. The tutorial covers Pythonâ€¦
towardsdatascience.com

ğŸ¦Š Florent: If you do not want to jump on another session, do not worry, I will not leave you high and dry! As part of this ultimate guide, here is a superb lightweight setup to get started, under 5 minutes, clocked âŒš.

To start things off, you can go to the Anaconda website and download a Miniconda installer (a free minimal installer for conda) appropriate for your operating system (Windows, macOS, or Linux), with a Python 10 version. From there, you can follow the installation instructions on the Anaconda website to install Miniconda on your machine.

And that is it! You now have secured the most uncomplicated Python installation with the lightweight miniconda that will make it super easy to isolate a controlled virtual environment. Before moving on to the following steps, we launch miniconda with its command line access:


In Windows, just searching â€œminicondaâ€ should yield this
Once in the Anaconda Prompt, we follow a simple four steps process to be up and running, as shown below.

Press enter or click to view image in full size

Workflow for environment creation. Â© F. Poux
To create a new environment, we write the line: conda create -n GEOTUTO python=3.10
To switch to the newly created environment, we write: conda activate GEOTUTO
To check the Python version, python --version, and the installed packages: conda list. This should yield Python 3.10 and the list of base libraries respectively
To install pip in the new environment, we write: conda install pip
And that is it! We are now ready to move on installing the necessary libraries for 3D Data Integration with the pip manager: pip install package-name, where you change the package name by each of these (one at a time: numpy, matplotlib, laspy[lazrs,laszip], open3d, rasterio, geopandas.

Python base libraries

Python Base libraries: Numpy and Matplotlib.
The first package installation is done via the prompt: pip install numpy.No need to present NumPy, Python's fundamental numerical and scientific computing library. It supports large multi-dimensional matrices and provides a collection of mathematical functions to work with ease. NumPy is the foundation of many other scientific libraries in Python and is heavily used in data analysis, machine learning, and scientific research.

ğŸ¦ Nourian: NumPy is all about Linear Algebra. If you need to get comfortable with re-learning Linear Algebra, you can start from here: Rudiment of Linear Algebra for Computer Graphics (ResearchGate)

Matplotlib is a popular plotting library for Python that enables 2D plotting and basic 3D plotting capabilities. To install it: pip install matplotlib. It provides a wide range of customizable visualization options, allowing users to create various types of plots, such as line plots, scatter plots, bar plots, histograms, 3D plots, and more. Matplotlib is widely used in scientific research and data science workflows.

3D Python Libraries

Python 3D Libraries: Open3D and Laspy.
Open3D is a modern 3D data processing and visualization library, mainly focusing on 3D point clouds and meshes. It provides functionalities to handle 3D data, such as point cloud registration, geometry processing, mesh creation, and visualization. Open3D is particularly useful for tasks related to 3D computer vision, robotics, and augmented reality applications. And for installing Open3D: pip install open3d.

Then, we have to install Laspy: pip install laspy[lazrs,laszip]. This Python library is used for reading, writing, and modifying LiDAR data stored in the LAS (LiDAR data Exchange Format) and LAZ (compressed LAS) file formats. It provides tools to work with point cloud data obtained from LiDAR scanners and is widely (small world) used in geospatial applications for terrain modeling, forestry, urban planning, and more.

Geospatial Libraries
Geopandas is a library built on top of pandas and shapely designed to handle geospatial data efficiently. To install it: pip install geopandas. It extends the capabilities of pandas to include geospatial data types and operations, allowing users to work with vector data (points, lines, polygons) and efficiently perform geospatial analysis. Geopandas is widely used in GIS, cartography, and spatial data analysis.

Rasterio is the last library that we will install with: pip install rasterio. It is used for reading and writing geospatial raster data. It supports various standard raster formats like GeoTIFF or JPEG and provides functionalities for geospatial metadata, spatial referencing, and coordinate transformations. rasterio is valuable for satellite imagery analysis, remote sensing, and GIS (Geographic Information Systems) applications.

Each of these libraries serves a synergic purpose and permits handling a myriad of data types in scientific computing, data science, and geospatial applications.

Setting up an IDE
The last step of our setup is to install an IDE. We are still in the command line interface within the environment, and we type: pip install jupyterlab, which will install jupyterlab on our environment. To use it clearly, we can change the directory to the parent directory of our project (let us call it INTEGRATION), which will hold both a CODE folder and a DATA Folder: cd C://COURSES/POUX/INTEGRATION. And then, we will launch jupyterlab from this location by typing in the console: jupyter lab, which will open a new localhost page in your web browser (Chrome would be the preferred choice, but Firefox or Safari work as well).

Well done! Phase one was completed successfully! ğŸ¯We are now ready to attack the second phase: finding datasets that we can combine for later use in our NASA-graded workflow. ğŸ™ƒ

Step 2. Multi-Modal Data Curation
Press enter or click to view image in full size

Step 2. Multi-Modal Creation. Â© F. Poux
We want to integrate multi-modal datasets. But what is this swearword: multimodal? It refers to data that spans different types and contexts, such as images, point clouds, text, and soundâ€¦

Press enter or click to view image in full size
3D multi-modal datasets. 3D Point Clouds, 3D Mesh, City Models, Voxels, Spatial Rasters, 360Â° Imagery, Tabular Data, Vector Data. Â© F. Poux
We use various 2D/2.5D/3D modalities. 3D Point Clouds, 3D Mesh, City Models, Voxels, Spatial Rasters, 360Â° Imagery, Tabular Data, Vector Data. Â© F. Poux
ğŸ¦ Nourian: Additionally, here is a nice hitchhiker's guide to Web-based computing platforms for Urban Planning: Essential Guide (ResearchGate)

So, our goal in this phase is to identify a zone of interest and gather as much data as possible to help us in our future analysis. The zone of interest selected today is a part of Enschede, a city in Eastern Netherlands in the province of Overijssel (Twente region), where, it makes sense, the University of Twente shines its knowledge beams. ğŸŒ

Press enter or click to view image in full size

Identifying a zone of interest.
ğŸ¦„ Mila: By unlocking the secrets of our cities through the fusion of 3D geospatial and remote sensing data, we give birth to city digital twins that illuminate the past, navigate the present, and shape. If you want to dive even more into data integration on the web using open-source tools, here is a research paper: 3D Data integration for web-based opensource WebGL interactive visualization (ISPRS Archives)

We are now ready to source different datasets. For clarity concerns, I organized this sourcing into four categories by searching for 3D datasets, Spatial Rasters, vector datasets, and finally from other sources, as shown below.

Press enter or click to view image in full size

Multi-modal data curation workflow. Â© F. Poux
3D Data Sourcing
The first step is to source some datasets from some open data repository with a data license that allows us to do some experiments. On that front, for the Netherlands, there is the possibility of obtaining LiDAR data, elevation data models, and raster imagery from one place: geotiles.nl. You can zoom in on the original tiles and get access to the various datasets download links, as shown below.

Press enter or click to view image in full size
Extracting the 34FN2 Tile of the AHN4 Dataset through GeoTiles.nl. Â© Florent Poux
Extracting the 34FN2 Tile of the AHN4 Dataset through GeoTiles.nl. Â© Florent Poux
ğŸ¦Š Florent: To serve you best, all the used data is available in the Drive Folder shared at the end of the section. The AHN version is AHN4.

The second place you can explore to get CityModels is 3D BAG, which stands for 3D Register of Buildings and Addresses (BAG), the most detailed, openly available data set on buildings and addresses in the Netherlands. It contains 3D models at numerous levels of detail, generated by combining two open data sets: the building data from the BAG and the height data from the AHN. Using the 3D Bag Viewer by tile queries, you can explore and access the buildings.

Press enter or click to view image in full size

The BAG Viewer. The Open Data accessible is licensed under CC BY 4.0, 3DBAG by tudelft3d and 3DGI.
The tile extent differs from what we got from the geotiles.nl, making it interesting when we attack the integration phase. At this stage, we already have exciting datasets under our hands. We can now move on to exploring spatial raster datasets.

Spatial Raster Data sources
For satellite and aerial imagery, the USGS Earth Explorer is one of the largest free data sources. It is worldwide, with a friendly user interface that makes accessing remote sensing data simple. It even has a bulk download application if you need to download more than one data set. If this is the first time for you, you will need to execute one additional step: creating an account, but it is free and quick (I did it in under 2 minutes âŒš).

Press enter or click to view image in full size

The USGS Earth Explorer. Open data part of U.S. Public Domain, Credits USGS.
I drew a polygon from the WebUI and then asked to get the Landsat > Landsat Collection 2 â€” Level 1 group (the most recent Landsat imagery is L8â€“9 OLI/TIRS and L7 ETM+). The differences between the collections are based on data quality and level of processing. USGS has classified images into tiers based on quality and processing level (Source). Once in the result section, you can check the footprint before deciding which would best fit your needs, as shown below.

Press enter or click to view image in full size

The polygons to extract LandSAT images. Â© F. Poux
For Digital Elevation models, I suggest sticking with the geotiles.nl data service as it is already on point with the most up-to-date and precise elevation models from the AHN. We are moving at an incredible pace, and the next stage is to get some excellent vector datasets!

Vector data curation
If you are in the GIS community, I hope presenting the power of OpenStreetMap (OSM) will not insult your knowledge base.

Press enter or click to view image in full size

OpenStreetMap Data Curation Portal. The Data is open, under the open database license (ODbL), Credits OpenStreetMap.
OSM provides different maps and layers with a crowd-sourcing initiative that makes it highly exhaustive, with a precision flag nevertheless. Indeed, OSM is open to the public and created by a general audience. So this means that accuracy can vary based on the creator and its â€œmappingâ€ expertise level. However, OSM is a goldmine for openly licensed street-level GIS data.

We have several ways to download OpenStreetMap data to get our hands on some of this gold. Conveniently, there is even an OSM Data Wikipedia page with all the available OSM extracts. My recommendation is the use of the tool Geofabrik. Indeed, you can then leverage a data organization by semantic spatial extent (E.g.: country, state, continent â€¦). You can quickly choose a geographic location and then download OSM data, as shown below.

Press enter or click to view image in full size

GeoFabrik portal to gather vector datasets. Â© F. Poux
ğŸ¦Š Florent: I also prefer downloading OSM data as shapefiles, but more on that later ğŸ˜‰. Mila makes me think that a great piece of knowledge is distilled in this Geospatial Data with Python.

We now have some 3D datasets, some raster datasets, and vector shapefiles. Time to dig the world wide web to find other precious stones ğŸ’.

Other sources
Well, here, the web is your ally. You can find anything you want to tie to your analyses, from web pages to news, to sounds to real-time data feeds. I would not overstate that sky (or your bandwidth ğŸ˜) is the limit! But, let me be very pragmatic again and also guide you toward one platform: Mappillary.

Mappillary is a platform that makes street-level images and map data available to scale. You can explore it and download some 360Â° imagery and points of interest using the Map Explorer.

Press enter or click to view image in full size

Mapillary database with the provided portal. If you download images, they are licensed under CC-BY-SA by Mappillary.
You also have the ability to filter out elements by their class if you want to select only some elements of interest or to cross-validate information with OSM data, for example.

And now, the good news? To follow along the code lines that are coming, I alleviate for you the process of getting all of this data that you can find directly in this Data Drive Repository. Once you have what you need in your DATA folder, we can start a nice exploratory data analysis.

Step 3. Exploratory Data Analysis
Press enter or click to view image in full size

Step 3. Exploratory Data Analysis.
At this stage, we have a Python code setup and a data setup, so we are ready to activate a deep focus mode with 15 minutes on clock timer âŒš. Indeed, we will now explore the various datasets we gathered with Python.

Press enter or click to view image in full size
Loading and Reading 3D Data. We use Open3D (Point Clouds, Mesh, Voxels), RasterIO, and Geopandas. Â© F. Poux
Loading and Reading 3D Data. We use Open3D (Point Clouds, Mesh, Voxels), RasterIO, and Geopandas. Â© F. Poux
This means that, for each modality, we will go through reading, profiling, harmonizing, and categorizing its content. Often, that means dealing with library bidirectional communication. To stay concise, I took the liberty of regrouping some modalities together, as shown below.

Press enter or click to view image in full size

The multiple modalities covered. Â© F. Poux
Before loading anything, let us import all the libraries installed by writing in your notebook/script the following nine lines:

#base libraries
import numpy as np
import matplotlib.pyplot as plt

#3D libraries
import open3d as o3d
import laspy as lp

#geospatial libraries
import rasterio as ra
import geopandas as gpd
3D Point Clouds
Let us start with my protÃ©gÃ©s: 3D point clouds. They are essentially a collection of points in 3D space that represent a physical object or environment. These points are generated from various sources, including LiDAR, photogrammetry, Artificial Intelligence (yes, you read well), scanning devices, etc. The first dataset in our hands comes from the Aerial LiDAR AHN campaign in the LAZ file format. It spans from the LAS LiDAR data Exchange Format (LAS) as its compressed counterpart, widely used for storing LiDAR point cloud data. It supports 2D and 3D point data and attributes such as intensity and classification. To read the file with Python, we use the laspy library with its extensions, as follows:

#Load a las file
las = lp.read("../DATA/34FN2_13.laz")
Great! we now have our file loaded in the las variable, which we can explore quickly using laspy functions to get possible attributes, the max value of the red channel, or the projection information:

print([dimension.name for dimension in las.point_format.dimensions])
print(np.max(las.red))
print(las.header.vlrs[2].string)
This will yield the following:

['X', 'Y', 'Z', 'intensity', â€˜return_numberâ€™, â€˜number_of_returnsâ€™, â€˜syntheticâ€™, â€˜key_pointâ€™, â€˜withheldâ€™, â€˜overlapâ€™, â€˜scanner_channelâ€™, â€˜scan_direction_flagâ€™, â€˜edge_of_flight_lineâ€™, â€˜classificationâ€™, â€˜user_dataâ€™, â€˜scan_angleâ€™, â€˜point_source_idâ€™, â€˜gps_timeâ€™, â€˜redâ€™, â€˜greenâ€™, â€˜blueâ€™, â€˜nirâ€™, â€˜Amplitudeâ€™, â€˜Reflectanceâ€™, â€˜Deviationâ€™]
255
COMPD_CS["Amersfoort / RD New + NAP height",PROJCS[â€œAmersfoort / RD Newâ€,GEOGCS[â€œAmersfoortâ€,DATUM[â€œAmersfoortâ€,SPHEROID[â€œBessel 1841â€,6377397.155,299.1528128,AUTHORITY[â€œEPSGâ€,â€7004"]],AUTHORITY[â€œEPSGâ€,â€6289"]],PRIMEM[â€œGreenwichâ€,0,AUTHORITY[â€œEPSGâ€,â€8901"]],UNIT[â€œdegreeâ€,0.0174532925199433,AUTHORITY[â€œEPSGâ€,â€9122"]],AUTHORITY[â€œEPSGâ€,â€4289"]],PROJECTION[â€œOblique_Stereographicâ€],PARAMETER[â€œlatitude_of_originâ€,52.1561605555556],PARAMETER[â€œcentral_meridianâ€,5.38763888888889],PARAMETER[â€œscale_factorâ€,0.9999079],PARAMETER[â€œfalse_eastingâ€,155000],PARAMETER[â€œfalse_northingâ€,463000],UNIT[â€œmetreâ€,1,AUTHORITY[â€œEPSGâ€,â€9001"]],AXIS[â€œEastingâ€,EAST],AXIS[â€œNorthingâ€,NORTH],AUTHORITY[â€œEPSGâ€,â€28992"]],VERT_CS[â€œNAP heightâ€,VERT_DATUM[â€œNormaal Amsterdams Peilâ€,2005,AUTHORITY[â€œEPSGâ€,â€5109"]],UNIT[â€œmetreâ€,1,AUTHORITY[â€œEPSGâ€,â€9001"]],AXIS[â€œGravity-related heightâ€,UP],AUTHORITY[â€œEPSGâ€,â€5709"]],AUTHORITY[â€œEPSGâ€,â€7415"]]
The third line gives us an interesting profile: the data is expressed in Amersfoort / RD New + NAP height reference system. We note that down for later.

ğŸ¦Š Florent: As you can see, the first line gives us several attributes for later use. This is nice that, by default, we can store so much information in a semi-structured way. However, we need to sort out the relevancy of this information; usually, we default to using X,Y,Z, intensity, red, green, blue. I would call the other one's bonuses ğŸ˜.

At this stage, we have no natural way to visualize if the data is correct; we have to transform it into our beloved numpy object, which we can after that convert to an open3d point cloud object to close the loop of switching between libraries. First, we convert some laspy object attributes to coords and colors numpy objects to hold our point cloud coordinates X,Y, Z and our point cloud colors:

coords = np.vstack((las.x, las.y, las.z))
colors = np.vstack((las.red, las.green, las.blue))
Then we transform our numpy object into an open3d object to visualize the point cloud. Unfortunately, no direct way from laspy exists, yet ğŸ˜.

pcd = o3d.geometry.PointCloud()
pcd.points = o3d.utility.Vector3dVector(coords.transpose())
pcd.colors = o3d.utility.Vector3dVector(colors.transpose()/255)
o3d.visualization.draw_geometries([pcd])
ğŸ¦Š Florent: This is a great exercise to see that switching libraries almost always comes down to losing some processing time between conversions and also exposes to possible memory errors. Therefore, always using a limited number of libraries is my advice when dealing with complex datasets and workflows.

Press enter or click to view image in full size

3D Point Cloud Dataset visualized in Open3D. Â© F. Poux
You can now visualize the full LiDAR point cloud within Python nicely, on par with professional software! Let us now load another point cloud to explore another widely used file format: .ply. The PLY format is used to store 3D mesh data along with attributes like color and normals. It is also suitable for point clouds with additional information.

With open3d, this is super simple; you can execute the following code to fill the pcd_itc variable with the point cloud, and the o3d.visualization function to draw the point cloud:

#Load a point cloud and visualize
pcd_itc = o3d.io.read_point_cloud("../DATA/ITC_outdoor.ply")
o3d.visualization.draw_geometries([pcd_itc])
Press enter or click to view image in full size

3D Indoor Point Cloud visualized in Open3D. Â© F. Poux
This point cloud does not show any metadata information, which means that we will consider that it is expressed in a local reference system that will need to be registered somehow to a reference dataset.

ğŸ¦ŠFlorent: Spoiler alert! Point cloud dataset is like a special central rock, especially dealing with multiple modalities. Indeed, as I will show later, it can act as the canonical reference to then link all the other datasets to it. I warned you of the spoiler!

Time to move on 3D voxels ğŸ§Š

3D Voxels
Voxels are another type of 3D data format. Voxels are essentially 3D pixels that represent a volume of space. They are plain fun, and you can check their plain usefulness in the following case studies:

3D Python Workflows for LiDAR City Models: A Step-by-Step Guide
The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling Applications. The tutorial covers Pythonâ€¦
towardsdatascience.com

How to Automate Voxel Modelling of 3D Point Cloud with Python
Hands-on tutorial to turn large point clouds into 3D voxels ğŸ§Š with Python and open3d. Unlock an automation workflowâ€¦
towardsdatascience.com

ğŸ¦ Pirouz: Voxels are pretty much like LEGO models. Check out this paper about voxelization of spatial data and getting serious with digital LEGO: Voxelization Algorithms for Geospatial Applications (ResearchGate). If you canâ€™t get enough of voxels? Then search Google for â€œvoxel artâ€ and check out the library topoGenesis (GitHub).

Now, we will read and visualize the voxel dataset with the following code lines:

vox_read = o3d.io.read_voxel_grid("../DATA/34FN2_13_vox.ply", format='auto')
o3d.visualization.draw_geometries([vox_read])
Press enter or click to view image in full size

3D Voxel Dataset visualized in Open3D. Â© F. Poux
At this stage, we read, profiled, and made sure that we had a way to deal with all this data with a single library for processing (numpy) and one for 3D visualization (open3d).

Time to get city models in our Python experiments ğŸ˜

City Models
Models of Cities often follow a standard of expression: CityGML models. CityGML is an XML-based data format used to represent the 3D geometry of urban environments. CityGML models can include information about buildings, roads, bridges, and other infrastructure. City planners, architects, and engineers often use these models to simulate and analyze urban environments. An excellent place to get yours, which I did not mention on purpose before, is this GitHub repository curated by my colleague Olaf (Any Frozen reference forbidden â›„): CityGML Models.

ğŸ¦Š Florent: Basically, in Python, we have to make sure to convert these models to 3D meshes while keeping any wanted semantic / topology or other information. A friendly Python tool, again by TUM, is available here: citygml2obj. But I did the heavy lifting for you if you use the data, thus moving on to the next reading modality: 3D meshes.

3D Mesh
Next, letâ€™s talk about meshes. Triangular meshes are constituted of vertices, edges that bind vertices, and triangular faces that finish the â€œenvelopeâ€ of objects. They allow us to depict the shape of a 3D object. Meshes can be created using 3D modeling software or generated from point clouds, city models using specialized algorithms, or even Artificial Intelligence! The dataset is in an OBJ format commonly used to export 3D mesh models representing geometry and texture coordinates.

ğŸ¦ Pirouz: If you want to know why these fancy words are used instead of points, lines, and polygons, you need to learn a bit more about another fancy word: topology.

ğŸ¦Š Florent: You can read a story about topology written by Pirouz which may well be one of the easiest story about topology: Rudiments of Geometry and Topology (ResearchGate)

To load the mesh and get its extent, we will write the following lines:

mesh = o3d.io.read_triangle_mesh("../DATA/10â€“976â€“660-LoD22â€“3D.obj")
mesh.get_axis_aligned_bounding_box()
And we see from the output that we have coordinates that span closely to what Amersfoort / RD New gives. This is comforting; we now have another dataset in this reference system.

From there, to visualize the mesh, we first compute some vertex normals and use the same visualization function from open3d to visualize it:

mesh.compute_vertex_normals()
o3d.visualization.draw_geometries([mesh])
On the 3D side, we are good to go! Let us explore our Spatial Rasters with Python and rasterio

Spatial Imagery
Our imagery is in the GeoTIFF format, an extension of the TIFF format that includes geospatial metadata, making it ideal for raster elevation data (DSM/DTM) and imagery. To open and profile the spatial imagery that we have, we simply use the following lines of code using rasterio:

sat_image = ra.open("../DATA/RGB_34FN2.tiff")
sat_image_array = sat_image.read(1)
print(sat_image.meta)
This results in the following output:

{â€˜driverâ€™: â€˜GTiffâ€™, â€˜dtypeâ€™: â€˜uint8â€™, â€˜nodataâ€™: None, â€˜widthâ€™: 20002, â€˜heightâ€™: 25002, â€˜countâ€™: 3, â€˜crsâ€™: CRS.from_epsg(28992), â€˜transformâ€™: Affine(0.25, 0.0, 254999.75,
 0.0, -0.25, 475000.25)}
Interestingly, we get a clear detail that it is an image of 20002x25002, with three channels (R,G, and B) expressed in the CRS 28992, which corresponds to Amersfoort again! This is great!

Now, to plot with numpy and matplotlib, below is the tiniest possible line of code to get an image with numpy, avoiding Memory errors, with a result shown afterward:

plt.imshow(sat_image_array)
plt.axis("off")
plt.show()
In parallel, rasterio also provides show() function to perform everyday tasks such as displaying multi-band images as RGB and labeling the axes with proper geo-referenced extents. This permits to simplify the plot, as expressed below:

from rasterio.plot import show
cir_image = ra.open("../DATA/CIR_34FN2.tiff")
show(cir_image)
show(sat_image)
Press enter or click to view image in full size
Press enter or click to view image in full size
Press enter or click to view image in full size
Various raster visualized with plot functions from matplotlib and rasterio. Â© F. Poux
This is superb! We have several 3D datasets (3D point clouds, voxels, 3D meshes) and satellite imagery (both infrared and R, G,B) that we could both handle with numpy and express for most of them in one common CRS. Let us move to other rasters focusing on elevation data (2.5D).

Elevation Rasters (DSM, DTM)
Elevation models are usually found as raster files, where each pixel has a value that can be translated to its elevation. This is why we call that 2.5D data as it is a pure top-down or single point of view, also tagged depth image when out of any GIS projection system. We can import elevation models with the same code line:

dtm = ra.open("../DATA/DTM5_34FN2.TIF")
Now that we have a dtm variable that holds the elevation data, we extract its metadata on the whole with dtm.meta, or more specialized with dtm.shape, dtm.crs, dtm.bounds, dtm.overviews(1):

print(dtm.meta)
print(dtm.shape, dtm.crs, dtm.bounds, dtm.overviews(1))
This brings us to the following result:

{â€˜driverâ€™: â€˜GTiffâ€™, â€˜dtypeâ€™: â€˜float32â€™, â€˜nodataâ€™: 3.4028234663852886e+38, â€˜widthâ€™: 1000, â€˜heightâ€™: 1250, â€˜countâ€™: 1, â€˜crsâ€™: CRS.from_epsg(28992), â€˜transformâ€™: Affine(5.0, 0.0, 255000.0,
 0.0, -5.0, 475000.0)}
(1250, 1000) EPSG:28992 BoundingBox(left=255000.0, bottom=468750.0, right=260000.0, top=475000.0)
And again, it is interesting to see that we have the same CRS Amersfoort / RD New for this dataset.

To get a plot and a sense of what we are dealing with, we can transform the dataset to a numpy array and use indexing to select part of it in a selection variable:

dtm_array = dtm.read(1).astype(â€˜float64â€™)
selection = dtm_array[300:800,300:800]
Finally, we plot using the two ways: rasterio and matplotlib both the full-scale dataset and the zoomed-in selection:

#For the dtm plot with rasterio
show(dtm)

#For the dtm zoomed-in plot with matplotlib
fig, ax = plt.subplots(1, figsize=(15, 15))
ra.plot.show(selection, cmap=â€™Greys_râ€™, ax=ax)
plt.axis(â€˜offâ€™)
plt.show()
Press enter or click to view image in full size
Press enter or click to view image in full size
DTM plot with RasterIO and matplotlib. Â© F. Poux
Finally, we cannot discuss raster datasets without diving into vector spatial data.

Spatial Vector Data
At this stage, it is essential to clarify once and for all that, if you find pixels, you are not speaking about vector data. Instead, vector datasets are made of vertices and paths, which are available as points (X, Y coordinates), lines (they connect these points now tagged vertices), and polygons (connect vertices to close a path made of lines).

Press enter or click to view image in full size

Vector Data in GIS Systems. Â© F. Poux
ğŸŒ± Growing: Having that in mind, where does your intuition place 3D point clouds? Voxel models? 3D meshes? These are interesting questions with profound implications, but nice to situate better how 2D stands with a 3D synergy.

Interestingly, cartographers (but not only) use these as â€œsymbolsâ€ to depict real-world components in maps. This means that they constantly have to determine a â€œLevel of Detailâ€ (LoD) that the entity represents, and this gives so much symbolic power to these entities (a point can be a country, or a town, or a citizen, or a specific place, â€¦).

To handle these vector datasets, we mainly use one open specification, the shapefile format. This permits us to spatially describe geometries and attach some kind of additional information to them. On our computer, the shapefile file format is simply a collection of several files formatted to represent different aspects of geodata (Reference):

.shp â€” The shape file, which contains the feature geometry itself.
.shx â€”The shape index format, which holds a positional index of the feature geometry. This is very useful for large files in order to allow quick search thanks to clever â€œindexingâ€.
.dbf â€” The attribute format, which holds various attributes for each shape in a tabular way (dBase IV format).
On top, we may have optional files that accompany the shapefile format. The most noteworthy one is the â€œ.prjâ€ file. This extra file actually defines the coordinate system and any projection information deemed necessary. Thus, having all these files allows us to load street data of the region Overijssel using this time geopandas:

vector_data = gpd.read_file("../DATA/gis_osm_roads_free_1.shp")
Press enter or click to view image in full size

Vector Data output. Â© F. Poux
Let us now explore a bit its projection system by exploring its CRS:

print(vector_data.crs)
Which results in the following:

<Geographic 2D CRS: EPSG:4326>
Name: WGS 84
Axis Info [ellipsoidal]:
- Lat[north]: Geodetic latitude (degree)
- Lon[east]: Geodetic longitude (degree)
Area of Use:
- name: World.
- bounds: (-180.0, -90.0, 180.0, 90.0)
Datum: World Geodetic System 1984 ensemble
- Ellipsoid: WGS 84
- Prime Meridian: Greenwich
As we can see, this dataset is expressed in the ESPG 4326, which stands for WGS84. So this is different from our other datasets so far.

Florent: geopandas is a perfect mashup of pandas and shapely. Thus if you are familiar with both, geopandas will be a breeze! Some useful commands are vector_data.columns or vector_data.describe() that can give you an overview of its content quickly.

But let us now explore our dataset visually to see its content:

vector_data.plot()
Which results in the following plot:

Press enter or click to view image in full size

Vector Data from OpenStreetMap. Â© F. Poux
This is very interesting! We can also use Matplotlib to display vector data. And the region is densely populated with an extensive road network, which is very dense! Let us now extract some points of interest from another source of data.

Vector: Points of Interest
The dataset pack has a GeoJSON file, a lightweight and popular format for representing vector data with geometry and attributes, suitable for web-based applications and data exchange. To load the file, we also use geopandas with this code line:

trashcan_data = gpd.read_file("../DATA/mapillary-trashcan_points.json")
We profile its CRS:

trashcan_data.crs
This gives us an answer that this is in the WGS84 CRS again. Finally, we plot to check any abnormality firsthand:

trashcan_data.plot()
Press enter or click to view image in full size

Points of interest. Â© F. Poux
This may be a bit bland without any more context; thus, layering Raster imagery would be a first choice already. But before that, let us explore another dataset we could try: 360Â° imagery!

360Â° Imagery
From the mappillary platform, we have the ability to extract some 360Â° images that come with a specific license to be used. You can still use geopandas to read these images :

image = ra.open("../DATA/An8XJdYJkSXycbyDWiVyw8dfVi2IzZ-jr9z7IxneeEXnOJPt0K1C89cMdXNkl5FZT0x6aVuPFRpda6eWV9fcnpgJkPfWjrd7k9harUP48csXGFf2azE1qF7FhkYK4h__j9t6Vd3aUfKcEdlqF_rsVO4.jpg")
print(image.meta)
That will output:

Dataset has no geotransform, gcps, or rpcs. The identity matrix will be returned.
  dataset = DatasetReader(path, driver=driver, sharing=sharing, **kwargs)
{'driver': 'JPEG', 'dtype': 'uint8', 'nodata': None, 'width': 2048, 'height': 1024, 'count': 3, 'crs': None, 'transform': Affine(1.0, 0.0, 0.0,
       0.0, 1.0, 0.0)}
Here we can see (of course) that this image has no geotransform data. And this is normal: this is not a spatial raster! However, if we wanted, we could add a position so that a data point represents the place the picture was taken, a hint at layering data modalities through data integration. But before going there, let us plot the image:

ra.plot.show(image)
This results in the following:

Press enter or click to view image in full size

360Â° imagery from Mapillary. Â© F. Poux
We have now successfully loaded 3D Point Clouds, 3D City models as 3D Meshes, 3D Voxel dataset, Spatial rasters (satellite imagery, aerial imagery, and elevation rasters), vector datasets (lines and points), as well as 360Â° imagery. The first objective is now an evident success! But, we need to check how to bring that all together, and the first thing to check is actually if they are expressed in the same Coordinate Reference System (CRS). For that, I compiled the results of our profiling step in the table below.

| Data | Lidar Point Cloud                | TLS Point Cloud | 3D City Mesh                     | Satellite Imagery   | Digital Terrain Model | Streets (Vector)         | Trashcans                      |
|------|----------------------------------|-----------------|----------------------------------|---------------------|-----------------------|--------------------------|--------------------------------|
| Name | 34FN2_13.laz                     | ITC_outdoor.ply | 10-976-660-LoD22-3D.obj          | RGB_34FN2.tiff      | DTM5_34FN2.TIF        | gis_osm_roads_free_1.shp | mapillary-trashcan_points.json |
| CRS  | Amersfoort / RD New + NAP height | None            | Amersfoort / RD New + NAP height | Amersfoort / RD New | Amersfoort / RD New   | WGS 84                   | WGS 84                         |
| CRSC | 7415                             |                 | 7415                             | 28992               | 28992                 | 4326                     | 4326                           |
We see a mix of EPSG:7415, 28992, 4326 or missing EPSG. The next stage is thus to clarify and use a unifying system for all datasets.

Data Registration and Reprojection
Press enter or click to view image in full size

Step 4. Registration and Reprojection
Before integration, we have to ensure that all datasets are in a compatible format and coordinate reference system (CRS). If this is not the case, we perform data reprojection to bring them into a common CRS. This is achieved in four main stages by (1) Selecting a reference system, (2) Georeferencing the primary dataset, (3) Reprojecting other datasets, and (4) Aligning rigidly local datasets, as shown below.

Press enter or click to view image in full size

4 Steps Workflow covered. Â© F. Poux
Let us go through these stages.

Selecting a Reference System
Alright, let us dive into the exciting world of reference systems! Imagine reference systems as the GPS coordinates that guide your data through the vast landscape of planet Earth. A reference system defines a set of rules and parameters to represent the Earthâ€™s surface in a way that makes sense to us mere mortals. Itâ€™s like choosing a secret language that your data speaks fluently, allowing it to find its place in the world. Now, how do we choose the correct reference system? Letâ€™s be pragmatic and attempt to first delineate the scope + region of interest of the project at hands.

Press enter or click to view image in full size

Projection classical cases: One standard line, one standard cone and one standard point. Â© F. Poux
Different reference systems work better for different parts of the globe. Something like the Amersfoort / RD New can be a fantastic choice for local projects in the Netherlands. The trusty WGS84 or Universal Transverse Mercator (UTM) might be your best buddy for more global ventures. Therefore, we use the Amersfoort / RD New + NAP height (for the elevation information) as our CRS.

Remember, when choosing a reference system, let the nature of your project and the region guide your decision. Pick a system that speaks the language of your data and brings harmony to your geospatial endeavors.ğŸ—ºï¸

Data Georeferencing
Okay, we have our CRS defined; this step ensures that the data tagged in EPSG:7415 for 3D data, and EPSG:28992 for 2D data. When profiling, we could then check that these datasets are already coherent:

LiDAR 3D Point Cloud
Raster Imagery (both Spatial Raster and Elevation Raster)
However, the voxel dataset and the mesh from the city model dataset look like they are in the same CRS but have no metadata. Thus, we quickly overlay these datasets to check for any possible inconsistencies:

o3d.visualization.draw_geometries([pcd,vox_read,mesh])
Which results in the following:

Press enter or click to view image in full size

The point cloud, building, and voxel datasets are combined together and visualized. Â© F. Poux
ğŸ¦ŠFlorent: Everything is aligned nicely, as shown in the image. The various datasets are cut on purpose to show the overlap between them. You can also see that point clouds have a bit more roughness and â€œresolutionâ€ over the 3D models that represent the buildings.

the remaining datasets to address are the following:

Vector datasets (both the OSM and Mappillary one) that are expressed in WGS84
The ITC Point Cloud dataset is not georeferenced.
Let us then deal with data projection first.

Data Reprojection
Spatial data reprojection is a fundamental process that involves transforming spatial data from one coordinate reference system to another, typically to match the projection and coordinate units of a specific spatial analysis. Reprojection ensures that different datasets with distinct projections can be accurately overlaid, integrated, or analyzed.

The process involves mathematical calculations that convert geographic coordinates (latitude and longitude) from one datum to another, considering parameters like scale, rotation, and distortion. Spatial data reprojection is essential for achieving data consistency, enabling interoperability between different datasets, and conducting accurate geospatial analyses across diverse mapping systems and applications.

When reprojecting spatial data between reference systems, several important factors must be carefully considered to ensure accurate and meaningful results. Here are some of the key considerations:

Coordinate Systems and Projections: Understand the coordinate systems and projections of both the source and target reference systems. Make sure they are compatible; if not, choose an appropriate transformation method.
Datum and Ellipsoid: Check the datums and ellipsoids used in the source and target systems. Differences in datums can lead to significant shifts in coordinates. Apply datum transformations if needed to align the data correctly. If you feel a bit confused, here is a nice lecture on datum and ellipsoid (tamia.edu)
Accuracy / Precision: While these pinpoint two different characteristics (which extends the scope of our article), it is important to understand the required â€œlevelâ€ for your specific analysis. Reprojection can introduce some errors, especially in large-scale transformations. Indeed, any data â€œerrorâ€ has a potential impact on the results of our analysis.
Distortions: Different map projections can introduce distortions in shape, area, distance, or angles. Be aware of these distortions and their implications on your data interpretation.
Coverage Area: Some projections are suitable for specific regions but may not be ideal for global datasets. Choose a projection that preserves the properties of your data over the entire coverage area.
Metadata and Documentation: Keep track of the reprojection process and document the transformations applied to the data. Properly document the source coordinate system and the target projection for future reference.
By carefully considering these factors, we ensure that reprojection is performed accurately and the resulting data is suitable for our intended applications. It is essential to be mindful of potential errors and artifacts that can arise during the reprojection process and to validate the results to maintain the quality and reliability of the data. In our case, we have to reproject both vector datasets. To do this, we use the following lines:

trashcan_data_georeferenced = trashcan_data.to_crs(â€˜epsg:28992â€™)
trashcan_data_georeferenced.plot(color=â€™redâ€™)
vector_data_georeferenced = vector_data.to_crs(â€˜epsg:28992â€™)
vector_data_georeferenced.plot(edgecolor=â€™greenâ€™)
Which results in the following:

Press enter or click to view image in full size
Press enter or click to view image in full size
The resulting plots. Â© F. Poux
ğŸ¦Š Florent: 3D Reprojection is also possible, but currently extend a bit the scope of this guide. Nevertheless, you can browse the library of course tutorials, where you will find some nice code and examples for 3D reprojection in the context of Segment Anything for Semantic Segmentation.

Note the change in the coordinates on the axes of our plots! At this stage, it looks like we only have one data to register: the 3D Point Cloud of ITC.

Data Rigid Registration
Press enter or click to view image in full size

3D Data Registration classical workflow. Â© F. Poux
In 3D integration, data registration becomes crucial. Point cloud registration methods are usually made of two stages: a coarse alignment to position relatively closely two point clouds quickly. Then a fine registration like Iterative Closest Point (ICP) or feature-based registration to align multiple point clouds with a higher degree of precision. To give you a hint concerning global registration, we can align the ITC point cloud by picking a list of three pairs of common points to get a first estimate, which is later refined with ICP. This permits obtaining an overlaid point cloud. These largely extend the scope of the current guide, and will be covered in another session.ğŸ˜‰

We now possess an aligned dataset expressed in a coherent CRS. The next stage is to see if we can refine the â€œdata oilâ€ to get some intelligent analytical workflow that can be built from there.

Step 5. Data Processing, Transformations, and Fusion
Press enter or click to view image in full size

Step 5. Data Pre-Processing
This stage can also be done before the registration and reprojection part. Indeed, as we predominantly work per dataset, this is a solution and can impact (for better or worse) the results of the previous steps.

Spatial data integration combines different types of spatial data (2D, 3D, or 2.5D) to create a unified and comprehensive representation of an area with data overlap. This process allows us to leverage the strengths of each data type and derive more valuable insights from the integrated dataset. Here is a quick view of some processing strategies for spatial data integration:

Press enter or click to view image in full size
3D Data Pre-Processing major areas: data cleaning, data transformation, data reduction, and data enrichment. Â© F. Poux
3D Data Pre-Processing major areas: data cleaning, data transformation, data reduction, and data enrichment. Â© F. Poux
Now, let us explore what these four main stages actually look like, code-wise.

Data Cleaning (Raster Dataset)
the first stage is to handle missing or erroneous data points carefully. Data cleaning techniques like interpolation or extrapolation may be used to fill in gaps or replace erroneous values. In our case, we could fill empty raster values from our DTM.

I do this by interpolating neighboring pixels for each empty zone to try and give a better structure to our dataset with the following code snippet:

#We import a specific function
from rasterio.fill import fillnodata

#We transform to a numpy array
dtm_array = dtm.read(1)

#We interpolate
interpolated_dtm = fillnodata(dtm_array, mask=dtm.read_masks(1), max_search_distance=100, smoothing_iterations=0)

#We plot the results
fig, ax = plt.subplots(1, figsize=(15, 15))
ra.plot.show(interpolated_dtm, cmap='Greys_r', ax=ax)
plt.axis('off')
plt.show()
ğŸŒ± Growing: How would you use this to extract contour lines on your zone?

This results in the following:

Press enter or click to view image in full size
Press enter or click to view image in full size
DTM Visualization results. Â© F. Poux
Data Transformation (3D Point Cloud)
Aside from conversion between file formats, data transformation refers to the various processes to ensure structural and content integrity toward one or more processing steps. For example, it is imperative in many feature engineering tasks to enhance 3D machine learning model performances.

One critical data transformation method is scaling, ensuring that all the values in a dataset are within a specific range, such as 0 to 1. To do this on a point cloud, we proceed as follows:

#We compute a MinMaxScaler bounds
coords_itc = np.array(pcd_itc.points)
min_itc = np.min(coords_itc, axis=0)
max_itc = np.max(coords_itc, axis=0)

#MinMaxScaling
coords_itc_mmscaling = (coords_itc - min_itc) / (max_itc - min_itc)
This transforms our original point cloud with coordinates between 0 and 1 for all our points. Therefore, if we were to plot their distribution along the three axes, we would use the following:

n_bins = 20
fig, ax = plt.subplots(1, 3, sharey=True, tight_layout=True)
ax[0].hist(coords_itc_mmscaling[:,0], bins=n_bins, color = "skyblue")
ax[1].hist(coords_itc_mmscaling[:,1], bins=n_bins, color = "salmon")
ax[2].hist(coords_itc_mmscaling[:,2], bins=n_bins,color = "purple")
To obtain:

Press enter or click to view image in full size

3D Point Cloud Distribution analysis. Â© F. Poux
As you can see, our point cloud now has X, Y, and Z coordinates that range between 0 and 1.

ğŸ‡ Note: This is interesting on another flavor. Indeed, we tend to a pattern looking at the Z distribution, where a hint toward a Z-driven algorithm makes sense, for example, to distinguish roofs from the ground points.

Data Reduction: Cropping mask, Point Cloud Sampling
Data reduction encompasses the various techniques in which data is reduced to its simplest possible form to enable optimal analytical tasks.

One of these is data cropping: reducing the spatial extent of our dataset. A clear example could be executed on raster datasets to limit the memory footprint by loading a huge zone when we want to focus on a tighter area. To do this, with rasterio, we have first to create a geopandas bounding box that will act as the filtering mask:

from shapely.geometry import Polygon

BBlidar=[np.min(coords, axis=1),np.max(coords, axis=1)]

minx=BBlidar[0][0]
miny=BBlidar[0][1]
maxx=BBlidar[1][0]
maxy=BBlidar[1][1]
areabbox = gpd.GeoDataFrame({'geometry':Polygon([(minx,maxy),(maxx,maxy),(maxx,miny),(minx,miny),(minx,maxy)])},index=[0],crs="EPSG:28992")
We then get a nice area box that we use as a mask on the original file (or any raster of choice) by also making sure we copy the metadata of the original file onto the cropped version:

from rasterio.mask import mask

in_raster = ra.open("../DATA/CIR_34FN2.tiff")

# Do the clip operation
out_raster, out_transform = mask(in_raster, areabbox.geometry, filled=False, crop=True)

# Copy the metadata from the source and update the new clipped layer 
out_meta=in_raster.meta.copy() 
out_meta.update({
    "driver":"GTiff",
    "height":out_raster.shape[1], # height starts with shape[1]
    "width":out_raster.shape[2], # width starts with shape[2]
    "transform":out_transform})

# Plot the CIR raster
ra.plot.show(out_raster)
This results in the following:


Cropping a CIR Image. Â© F. Poux
Another clear data reduction technique is data sampling. In our case, trying to reduce the number of points in our point cloud. This can be done in several ways (which, again, extend the scope of this article), with one using the voxel data structure a priori: we want to keep one best candidate per voxel:

voxel_size = 1

pcd_downsampled = pcd.voxel_down_sample(voxel_size = voxel_size)
o3d.visualization.draw_geometries([pcd_downsampled])
This results in the following downsampled point cloud:

Press enter or click to view image in full size

3D Point Cloud Downsampling results. Â© F. Poux
Finally, we can enrich our dataset in various ways.

Data Enrichment: Inject POI proximity to point clouds
Depending on the application, various fusion techniques can be applied to merge the datasets. For 2D and 2.5D integration, raster-based methods like weighted averaging or majority voting can combine multiple data layers. In 3D integration, point cloud fusion techniques, such as merging, averaging, or voxelization, are employed to create a single, consolidated 3D point cloud representing the entire area.

ğŸ¦Š Florent: Using data enrichment (fusion) techniques, we combine information from multiple sources (it can be web-based, from a data acquisition mission, or any relevant way to gather data). This allows the creation of a more comprehensive and accurate representation of the underlying phenomenon. These can touch on raster Weighted Averaging (Involves taking a weighted average of pixel values from multiple raster layers, where the weights represent the importance or reliability of each raster layer), Majority Voting (Combines categorical raster data by assigning the majority class to each pixel location, helpful in land cover classification). But these are for another time. ğŸ˜‰

A swift way to extend our dataset is to compute additional features. This is done, for example, on the 3D point clouds by extracting normals computed from a neighborhood of points that permits extracting the best fitting plane, then the normals. We automatically do this with the following piece of code:

nn_distance = np.mean(pcd.compute_nearest_neighbor_distance())
print(nn_distance)

#setting the radius search to compute normals
radius_normals=nn_distance*4
pcd_downsampled.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normals, max_nn=16), fast_normal_computation=True)

# Visualizing the point cloud
pcd_downsampled.paint_uniform_color([0.6, 0.6, 0.6])
o3d.visualization.draw_geometries([pcd_downsampled])
And as you can see below, we can visualize our new point cloud without or with normals (pressing â€œnâ€ in the interactive window viewer):

Press enter or click to view image in full size
Press enter or click to view image in full size
Normal computation and visualization from the 3D Point Cloud. Â© F. Poux
Step 6. Multi-modal Data Visualization
Press enter or click to view image in full size

Step 6. Multi-Modal Data Visualization.
Multi-modal data visualization is a powerful approach that seamlessly integrates our diverse geospatial data, including vector data, spatial raster imagery, Digital Surface Models (DSM), Digital Terrain Models (DTM), point clouds, and city models.

Press enter or click to view image in full size

Libraries used for 3D Data Visualization: Matplotlib, Open3D and RasterIO (2D/2.5D). Â© F. Poux
This comprehensive fusion of data types allows for a more holistic understanding of the environment, laying the groundwork for more informed decision-making and sophisticated analyses. Now, letâ€™s dive into a Python solution that showcases how to achieve this remarkable visualization feat!

The trick is to understand the strengths and limits of each of our libraries! Indeed, what we will do is actually to stick to Open3D to check for the consistency between the data modalities (Meshes, 3D Point Clouds, and Voxels) and use the point cloud dataset as the canonical reference to then link all the other datasets to it.


Point Cloud as a canonical frame of reference. Â© F. Poux
Therefore, the first step is to analyze the 3D modalities:

o3d.visualization.draw_geometries([pcd,vox_read,mesh])
Press enter or click to view image in full size

Combined 3D Datasets. Â© F. Poux
ğŸ¦Š Florent: While the image may be confusing, be warned that nothing is going wrong when you visualize these three in one image. Indeed, the extent of the datasets are different to allow us to delineate the modalities better visually.

Great! From there, we use the point cloud dataset with Numpy on a top-down view to check the X-Y consistency, for example, with vector data:

# Plot the Georeferenced Shapefile and Point Cloud together using matplotlib
vector_data_clipped_pc = vector_data_georeferenced.cx[257000:258000, 471200:472400]
fig, ax = plt.subplots(figsize=(15, 15))
vector_data_clipped_pc.plot(ax=ax, color='yellow', edgecolor='yellow')
# Plot the point cloud
ax.scatter(coords[0][::100], coords[1][::100], c=coords[2][::100])
# Customize the plot (add labels, titles, legends, etc. if needed)
ax.set_xlabel('X (meters)')
ax.set_ylabel('Y (meters)')
ax.set_title('Shapefile and Point Cloud Visualization')
# Show the plot
plt.show()
This lays an obvious overlay of the vector dataset onto our point cloud that opens up a world of possibility to make these two dataset talk:

Press enter or click to view image in full size

Integrating Vector and Raster datasets. Â© F. Poux
Then, we continue our linkage by linking the vector dataset, reprojected, with spatial imagery:

#Clipping vector data
vector_data_clipped = vector_data_georeferenced.cx[255000:260000, 469000:475000]

#Plot the Raster Imagery with Vector Dataset
fig, ax = plt.subplots(figsize=(15, 15))
ra.plot.show(sat_image, ax=ax)
vector_data_clipped.plot(ax=ax, facecolor='none', edgecolor='green')

#Zooming-in
fig, ax = plt.subplots(figsize=(15, 15))
plt.axis([258000, 258500, 471000, 471500])
#The line above actually define the extent of the plot using the coordinates in the CRS.
ra.plot.show(sat_image, ax=ax)
vector_data_clipped.plot(ax=ax, facecolor='none', edgecolor='cyan')
This results in the visualization, which demands a bit of zoom, as expressed in the code, to better situate the fit of both datasets.

Press enter or click to view image in full size
Press enter or click to view image in full size
Results of the integration of raster and vector datasets, with the LiDAR reprojection. Â© F. Poux
The exact process is repeated for the locations from Mappillary, with the code below.

#Overlaying Raster with Vector data
fig, ax = plt.subplots(figsize=(15, 15))
plt.axis([257600, 260000, 471000, 471500])
ra.plot.show(sat_image, ax=ax)
trashcan_data_georeferenced.plot(ax=ax, facecolor='none', edgecolor='green')
Press enter or click to view image in full size

View of the points of interest from Mappillary. Â© F. Poux
And finally, we want to overlay raster, vector, and point cloud modalities in one plot with Numpy:

# Plot the Shapefile and Point Cloud together using matplotlib
vector_data_clipped_pc = vector_data_georeferenced.cx[257000:258000, 471200:472400]
fig, ax = plt.subplots(figsize=(15, 15))

# plot the sattelite imagery
ra.plot.show(sat_image, ax=ax)

# Plot the shapefile
vector_data_clipped_pc.plot(ax=ax, color='blue', edgecolor='blue')

# Plot the point cloud
ax.scatter(coords[0][::100], coords[1][::100], c=coords[2][::100])

# Customize the plot (add labels, titles, legends, etc. if needed)
ax.set_xlabel('X (meters)')
ax.set_ylabel('Y (meters)')
ax.set_title('Shapefile and Point Cloud Visualization')

# Show the plot
plt.show()
This little piece of code (careful on the shortcuts and smart tricks employed to condense the snippet) permits us to put a final note on the data integration of our various modalities.

Press enter or click to view image in full size

Shapefile and point cloud visualization with the DTM. Â© F. Poux
We approach the end of our systematic approach!

By carefully applying these processing techniques, spatial data integration enables us to create a holistic representation of the environment, facilitating better decision-making and insights in a wide range of applications. Still, we must consider the last step: sharing the newly processed data.

Step 7. Data Sharing
Press enter or click to view image in full size

Step 7. Data Sharing. Â© F. Poux
Spatial data export is vital in the geospatial data workflow, allowing us to seamlessly share, visualize, and analyze 2D and 3D data modalities in established software. To this end, we can take a higher, almost aerial view to better situate the extent of data sharing impacts. I chose to relate to academia and publishing proofs of new scientific discoveries. Indeed, this process that I illustrate below is the key to an ethical and robust R&D cycle. As you can see, data export in standard formats, which we cover here, is the central link to data browsing before pushing automated solutions.

Press enter or click to view image in full size
The 3D Data Sharing Workflow. We start with experiments to populate a database. This Database is then used to explore or export results to be filtered for publication. The results are then used to repopulate and update the 3D Database. Â© F. Poux
The 3D Data Sharing Workflow. We start with experiments to populate a database. This Database is then used to explore or export results to be filtered for publication. The results are then used to repopulate and update the 3D Database. Â© F. Poux
Thus, the export process must create various file formats suitable for applications and software environments. Each file format has its specificities, catering to different use cases and previously expressed requirements. For in-depth 3D data export, I propose to relate to these articles:

3D Python Workflows for LiDAR City Models: A Step-by-Step Guide
The Ultimate Guide to unlocking a streamlined workflow for 3D City Modelling Applications. The tutorial covers Pythonâ€¦
towardsdatascience.com

Understanding how we can do the same with vector and raster datasets is essential. As always, the simpler, the better: let us focus on these last exporting steps. To export the raster imagery, you can do the following with rasterio:

with ra.open("../RESULTS/CIR_34FN2_cropped.tiff",'w',**out_meta) as wf:
    wf.write(out_raster)
And concerning vector datasets, geopandas makes it a breeze to export the georeferenced and clipped result from our processing stages:

vector_data_clipped_pc.to_file("../RESULTS/roads.shp")
Finally, you can import these in a software such as QGIS or CloudCompare, which results in the following:

Press enter or click to view image in full size
3D Point Cloud, 3D Voxel, 3D City Model, 3D DTM, Raster and vector dataset overlayed. They are integrated with the proposed methodology.Â© F. Poux
3D Point Cloud, 3D Voxel, 3D City Model, 3D DTM, Raster and vector dataset overlayed. They are integrated with the proposed methodology.Â© F. Poux
This is the perfect layering of 3D, Raster, and Vector datasets!

Conclusion
We have embarked on an exciting journey exploring the world of 3D data integration with Python. Throughout this comprehensive guide, we have uncovered the immense potential of combining various 3D data modalities, such as point clouds, meshes, city models, DSM, DTM, and voxels, to create a unified and holistic representation of the spatial environment.

Press enter or click to view image in full size
The 3D Data Integration Workflow with Python. It is a Seven-Step Process to produce unified data-centric views. Â© F. Poux
The workflow covered in this 3D Data Integration Guide.Â© F. Poux
To summarize, I list below the key takeaways related to the seven steps that we covered:

Setting up a multi-modal coding environment in Python needs to accommodate a minimal number of robust libraries.
When sourcing datasets, it is best to carefully consider available open datasets with clear licensing options through web interfaces that make it easy for you to gather relevant samples.
It is an excellent practice to independently profile each modality and assess its main characteristics (CRS, precision, resolution, â€¦) through quick analysis schemes.
Mastering Coordinate Reference Systems and knowing how to go from one another and what a specific transformation implies is mandatory for scalable workflows with spatial datasets.
Pre-processing algorithms and techniques are often the keys between optimized and organized data assemblies and data warehouses with chaotic management systems.
nD data visualization is paramount to a successful data integration workflow and demands that you carefully consider which dataset/ data modality acts as your canonical anchor
Data Sharing as a final stage permits ensuring a system from A to Z that considers practical and operational considerations, even in academia or R&D actions where production phases can be overlooked.
Press enter or click to view image in full size

As I conclude this guide, I cannot help but be thrilled about the future of 3D data processing. Currently, with Pythonâ€™s versatility and the growing landscape of geospatial technologies, we have a large opening for new ways to better understand complex spatial phenomena (and act on them).

Therefore, you can expect an even deeper guide to efficient algorithms, innovative visualization techniques, and seamless integration with cutting-edge technologies. By exploring what we can accomplish with integrated 3D data workflows, we pave the way for new applications, some of which coming soon to your laps. This makes me say that you are on a good track to shape the future of spatial analysis and visualization, transforming how we perceive and interact with the world around us.

References
CÃ¡rdenas, Ivan L., Morales, Luis RodrigoandrÃ©s, Koeva, Mila, Atun, Funda, & Pfeffer, Karin. (2023, August 31). Digital Twins for Physiological Equivalent Temperature Calculation Guide. Zenodo. https://doi.org/10.5281/zenodo.83064562.
Kumalasari, D.; Koeva, M.; Vahdatikhaki, F.; Petrova Antonova, D.; Kuffer, M. Planning Walkable Cities: Generative Design Approach towards Digital Twin Implementation. Remote Sens. 2023, 15, 1088. https://doi.org/10.3390/rs150410883.
Rajan, V.; Koeva, M.; Kuffer, M.; Da Silva Mano, A.; Mishra, S. Three-Dimensional Modelling of Past and Present Shahjahanabadthrough Multi-Temporal Remotely Sensed Data. Remote Sens. 2023, 15, 2924. https://doi.org/10.3390/rs151129244.
Ying, Y.; Koeva, M.; Kuffer, M.; Zevenbergen, J. Toward 3D Property Valuation â€” A Review of Urban 3D Modelling Methods for Digital Twin Creation. ISPRS Int. J. Geo-Inf. 2023, 12, 2. https://doi.org/10.3390/ijgi120100025.
La Guardia, M.; Koeva, M. Towards Digital Twinning on the Web: Heterogeneous 3D Data Fusion Based on Open-Source Structure.Remote Sens. 2023, 15, 721. https://doi.org/10.3390/rs150307216.
Khawte, S. S., Koeva, M. N., Gevaert, C. M., Oude Elberink, S., and Pedro, A. A.: Digital Twin Creation For Slums In Brazil Based OnUAV Data, Int. Arch. Photogramm. Remote Sens. Spatial Inf. Sci., XLVIII-4/W4â€“2022, 75â€“81, https://doi.org/10.5194/isprs-archives-XLVIII-4-W4-2022-75-2022, 2022
3d
Geospatial Data
Point Cloud
Data Science
Deep Dives
1K


8




TDS Archive
Published in TDS Archive
829K followers
Â·
Last published Feb 3, 2025
An archive of data science, data analytics, data engineering, machine learning, and artificial intelligence writing from the former Towards Data Science Medium publication.


Follow
Florent Poux, Ph.D.
Written by Florent Poux, Ph.D.
4.7K followers
Â·
28 following
ğŸ† Director of Science | 3D Data + Spatial AI. https://learngeodata.eu (ğŸ’» + ğŸ“¦ + ğŸ“™ + â–¶ï¸)


Following
Responses (8)
Simon Ducournau
Simon Ducournau
ï»¿

Cancel
Respond
Shu-Yu Huang
Shu-Yu Huang

Nov 3, 2024


numpy

Need the version `numpy==1.26.4` or there will be problem in using `open3d`
17

Reply

Holyaka D M
Holyaka D M

Nov 11, 2023


Cool the article!
2


1 reply

Reply

Mark Brown
Mark Brown

Nov 10, 2023


Great in-depth article.
1

Reply

See all responses
More from Florent Poux, Ph.D. and TDS Archive
The Blender Handbook for 3D Point Cloud Visualization and Rendering
TDS Archive
In

TDS Archive

by

Florent Poux, Ph.D.

The Blender Handbook for 3D Point Cloud Visualization and Rendering
Complete guide to create 3D experiences with large point clouds in Blender

Feb 28, 2024
263
1


Recommender Systemsâ€Šâ€”â€ŠA Complete Guide to Machine Learning Models
TDS Archive
In

TDS Archive

by

Francesco Casalegno

Recommender Systemsâ€Šâ€”â€ŠA Complete Guide to Machine Learning Models
Leveraging data to help users discovering new contents
Nov 25, 2022
542
5


Transformers Explained Visually (Part 3): Multi-head Attention, deep dive
TDS Archive
In

TDS Archive

by

Ketan Doshi

Transformers Explained Visually (Part 3): Multi-head Attention, deep dive
A Gentle Guide to the inner workings of Self-Attention, Encoder-Decoder Attention, Attention Score and Masking, in Plain English.
Jan 17, 2021
3K
35


3D Point Cloud Shape Detection for Indoor Modelling
TDS Archive
In

TDS Archive

by

Florent Poux, Ph.D.

3D Point Cloud Shape Detection for Indoor Modelling
A 10-step Python Guide to Automate 3D Shape Detection, Segmentation, Clustering, and Voxelization for Space Occupancy 3D Modeling of Indoorâ€¦

Sep 7, 2023
468
2


See all from Florent Poux, Ph.D.
See all from TDS Archive
Recommended from Medium
5 Different Ways to Track Objects in Python
siromer
siromer

5 Different Ways to Track Objects in Python
5 different object tracking methods, both deep learning and classical computer vision approaches, implemented in Python and C++.
Oct 13
63


Python Map Algebra Cookbook: Raster Operations for Spatial Analysis
Stacy Mwangi
Stacy Mwangi

Python Map Algebra Cookbook: Raster Operations for Spatial Analysis
Essential recipes for transforming, combining, and analyzing gridded spatial data

6d ago
52


Bridging Worlds: Bringing Google Earth Engine to Desktop GIS Users!
Google Earth and Earth Engine
In

Google Earth and Earth Engine

by

Google Earth

Bridging Worlds: Bringing Google Earth Engine to Desktop GIS Users!
By Alicia Sullivan, Earth Engine Product Manager; Kel Market, Cloud Geographer; and Gena Donchyts, Cloud Geographer
Jun 17
109
2


Finding Groundwater Using Google Earth Engine and Gemini
Google Cloud - Community
In

Google Cloud - Community

by

Greg Sommerville

Finding Groundwater Using Google Earth Engine and Gemini
Remote Sensing and Infrared images make it possible
Jul 16
16
2


AlphaEarth Foundations: Implications for Cities and Urban Planners
Urban AI
Urban AI

AlphaEarth Foundations: Implications for Cities and Urban Planners
How Embeddings And GeoAI Are Transforming Urban Planning
Oct 14
22


A Python-Based Workflow for Land Cover Classification Using Geemap, Rasterio, Geopandas, Numpyâ€¦
Dr.Preethi Balaji
Dr.Preethi Balaji

A Python-Based Workflow for Land Cover Classification Using Geemap, Rasterio, Geopandas, Numpyâ€¦
If youâ€™ve read my previous articles, youâ€™ll know Iâ€™m a long-time connoisseur of Google Earth Engine (GEE)â€Šâ€”â€Šespecially its JavaScript APIâ€¦

Jul 23
105
1


See more recommendations
Help

Status

About

Careers

Press

Blog

Privacy

Rules

Terms

Text to speech

All your favorite parts of Medium are now in one sidebar for easy access.
Okay, got it

