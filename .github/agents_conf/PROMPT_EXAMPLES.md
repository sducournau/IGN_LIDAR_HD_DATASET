# Exemples de Prompts Optimis√©s pour LiDAR Trainer Agent

> Collection de prompts test√©s et optimis√©s pour obtenir les meilleurs r√©sultats avec l'agent

---

## üéØ Cat√©gories de Prompts

1. [Architecture & Design](#architecture--design)
2. [Feature Engineering](#feature-engineering)
3. [Entra√Ænement & Optimisation](#entra√Ænement--optimisation)
4. [Debugging & Troubleshooting](#debugging--troubleshooting)
5. [√âvaluation & M√©triques](#√©valuation--m√©triques)
6. [Production & D√©ploiement](#production--d√©ploiement)

---

## 1. Architecture & Design

### Prompt : Choix d'Architecture

```
@lidarTrainer Mon dataset IGN a [X]M points avec [N] classes
([liste des classes avec distribution]).

Je veux atteindre mIoU > [target] avec un temps d'entra√Ænement
< [X] heures sur [GPU model].

Quelle architecture recommandes-tu entre PointNet++ SSG, MSG,
et Point Transformer ? Justifie ton choix avec des m√©triques concr√®tes.
```

**Exemple concret :**

```
@lidarTrainer Mon dataset IGN a 3.4M points avec 3 classes
(Ground 45%, Vegetation 35%, Buildings 20%).

Je veux atteindre mIoU > 0.85 avec un temps d'entra√Ænement
< 3 heures sur RTX 3090.

Quelle architecture recommandes-tu entre PointNet++ SSG, MSG,
et Point Transformer ? Justifie ton choix avec des m√©triques concr√®tes.
```

---

### Prompt : Architecture Personnalis√©e

```
@lidarTrainer Con√ßois une architecture hybride qui combine :
- PointNet++ pour extraction features locales
- Attention mechanisms pour capturer d√©pendances long-range
- Multi-scale processing pour g√©rer densit√© variable LiDAR a√©rien

Target : Buildings segmentation avec F1 > 0.90
Dataset : IGN LiDAR HD, 10-15 pts/m¬≤, sc√®nes urbaines
```

---

### Prompt : Comparaison Architectures

```
@lidarTrainer G√©n√®re un benchmark comparant :
1. PointNet++ SSG
2. PointNet++ MSG
3. Point Transformer
4. KPConv (si pertinent)

Sur mon dataset [path], avec m√©triques :
- mIoU, F1 per class
- Training time, GPU memory
- Inference speed

Format : Tableau markdown + recommandation argument√©e
```

---

## 2. Feature Engineering

### Prompt : Analyse Features Existantes

```
@lidarTrainer Analyse mes features actuelles :
[liste des features : X, Y, Z, R, G, B, ...]

Dataset : [caract√©ristiques]
Classes cibles : [liste]

Identifie :
1. Features redondantes (forte corr√©lation)
2. Features peu discriminantes
3. Features manquantes recommand√©es

Propose une feature selection optimis√©e.
```

---

### Prompt : G√©n√©ration Features G√©om√©triques

```
@lidarTrainer G√©n√®re le code pour calculer ces features g√©om√©triques
sur mon nuage de points :

1. Verticality (priorit√© haute)
2. Planarity (priorit√© haute)
3. Omnivariance (priorit√© moyenne)
4. Normal change rate multi-√©chelle k=[10,30,50]
5. Height above ground (DTM-based)

Framework : Open3D + NumPy
Optimisation : GPU avec CuPy si possible
Format output : Compatible avec ign_lidar FeatureOrchestrator
```

---

### Prompt : Features pour Cas Sp√©cifique

```
@lidarTrainer Mes pr√©dictions confondent syst√©matiquement :
- V√©g√©tation verticale (arbres) ‚Üî Fa√ßades de b√¢timents
- Sol ‚Üî Toits plats

Quelles features g√©om√©triques discriminantes recommandes-tu ?
G√©n√®re le code de calcul + visualisation pour validation.
```

---

## 3. Entra√Ænement & Optimisation

### Prompt : Setup Complet Entra√Ænement

```
@lidarTrainer Configure un pipeline d'entra√Ænement complet pour :

**Dataset**
- Train : [path], [X]M points
- Val : [path], [Y]M points (distribution diff√©rente !)
- Classes : [liste + distribution]

**Target**
- mIoU : > [target]
- F1 buildings : > [target]
- Temps : < [X] heures

**Hardware**
- GPU : [model], [X]GB RAM
- CPU : [cores], [X]GB RAM

G√©n√®re :
1. Configuration YAML compl√®te
2. Script d'entra√Ænement Python
3. Strat√©gie augmentation donn√©es
4. Monitoring (TensorBoard)
```

---

### Prompt : Hyperparam√®tres Tuning

```
@lidarTrainer Optimise les hyperparam√®tres de mon PointNet++ :

**Contexte**
- Baseline : mIoU=0.78, Gap train/val=15%
- Classes d√©s√©quilibr√©es (voir distribution ci-dessous)
- GPU RAM limit√©e : 8GB

**√Ä optimiser**
- Learning rate + scheduler
- Batch size (actuellement 16)
- Dropout rate (actuellement 0.3)
- Weight decay
- Loss function (weighted ? focal ?)

Propose 3 configurations (conservative, balanced, aggressive)
avec justification et gains attendus.
```

---

### Prompt : Transfer Learning

```
@lidarTrainer Configure un fine-tuning √† partir d'un mod√®le
pr√©-entra√Æn√© sur ShapeNet :

**Checkpoint**
- Architecture : PointNet++ MSG
- Pr√©-entra√Æn√© sur : ShapeNet Part (50 objets, 16 classes)
- Path : [checkpoint_path]

**Mon dataset**
- Domain : LiDAR a√©rien IGN
- Classes : Ground, Vegetation, Buildings

**Strat√©gie**
- Frozen encoder : combien d'epochs ?
- Learning rate : quelle valeur ?
- Unfreeze progressif : comment ?

G√©n√®re le code complet avec monitoring du fine-tuning.
```

---

### Prompt : Optimisation GPU

```
@lidarTrainer Mon dataset de [X]M points d√©passe la RAM GPU ([Y]GB).

Impl√©mente une strat√©gie de chunking avec :
- Batch processing intelligent
- Gradient accumulation
- Mixed precision (FP16) si b√©n√©fique
- Optimal chunk size calcul√© dynamiquement

Maintenir : mIoU > [target]
Framework : PyTorch + RAPIDS cuML
```

---

## 4. Debugging & Troubleshooting

### Prompt : Diagnostic Overfitting

```
@lidarTrainer Debug mon overfitting :

**Sympt√¥mes**
- Train accuracy : [X]%
- Val accuracy : [Y]%
- Gap : [Z]%
- Val loss augmente apr√®s epoch [N]

**Configuration actuelle**
[coller config YAML]

Diagnostic complet avec :
1. Causes probables (class√©es par priorit√©)
2. Solutions concr√®tes avec code
3. Gains attendus par solution
4. Ordre d'impl√©mentation recommand√©
```

---

### Prompt : Analyse Convergence

```
@lidarTrainer Ma loss ne converge pas :

**Comportement observ√©**
- Loss oscille entre [X] et [Y]
- Pas d'am√©lioration apr√®s [N] epochs
- Gradient norm : [observations]

**Config**
- Learning rate : [lr]
- Optimizer : [optimizer]
- Batch size : [batch_size]

Analyse le probl√®me et propose solutions (avec code).
```

---

### Prompt : Classes Probl√©matiques

```
@lidarTrainer Une classe a des performances catastrophiques :

**Classe probl√©matique : [nom]**
- F1-score : [X] (target : [Y])
- Recall : [X]%
- Precision : [X]%

**Confusion matrix**
[coller matrix ou d√©crire confusions principales]

Diagnostique :
1. Pourquoi cette classe pose probl√®me ?
2. Features manquantes/insuffisantes ?
3. Strat√©gies de data augmentation cibl√©es ?
4. Architecture adaptation ?

Propose un plan d'action chiffr√©.
```

---

## 5. √âvaluation & M√©triques

### Prompt : Analyse Compl√®te R√©sultats

```
@lidarTrainer Analyse mes r√©sultats d'entra√Ænement :

**M√©triques finales**
[coller classification report ou tableau m√©triques]

**Confusion matrix**
[coller ou d√©crire]

**Objectifs vs R√©alis√©**
- mIoU target : [X], obtenu : [Y]
- F1 classes : [targets vs obtenus]

Fournis :
1. Analyse d√©taill√©e (forces/faiblesses)
2. Comparaison avec state-of-art
3. Recommandations d'am√©lioration prioritaires
4. Estimation gains attendus
```

---

### Prompt : G√©n√©rer Rapport √âvaluation

```
@lidarTrainer G√©n√®re un rapport d'√©valuation complet pour :

**Mod√®le** : [architecture]
**Checkpoint** : [path]
**Datasets** : Train, Val, Test (+ validation externe)

**Contenu rapport**
1. M√©triques globales et per-class
2. Confusion matrices
3. Visualisations pr√©dictions (5 samples)
4. Analyse erreurs (cas d'√©chec typiques)
5. Comparaison avec baseline
6. Recommandations production

Format : Markdown + visualisations PNG
```

---

### Prompt : Benchmark Multi-Datasets

```
@lidarTrainer √âvalue mon mod√®le sur plusieurs datasets pour
tester la g√©n√©ralisation :

**Mod√®le entra√Æn√© sur** : Louhans (IGN)

**√âvaluer sur**
1. Manosque (IGN, urbain diff√©rent)
2. Paris-Lille-3D (urbain dense)
3. [custom dataset] (rural)

G√©n√®re :
- Tableau comparatif m√©triques
- Analyse des pertes de performance
- Caract√©risation du domain gap
- Strat√©gies pour am√©liorer g√©n√©ralisation
```

---

## 6. Production & D√©ploiement

### Prompt : Optimisation Inference

```
@lidarTrainer Optimise mon mod√®le pour l'inf√©rence production :

**Contraintes**
- Target latency : < [X]ms par tile
- Hardware : [CPU/GPU model]
- Batch inference : [tiles par batch]

**Optimisations √† explorer**
1. TorchScript compilation
2. ONNX export + TensorRT
3. Quantization (INT8)
4. Pruning (si gain significatif)

G√©n√®re code + benchmark avant/apr√®s pour chaque optimisation.
```

---

### Prompt : Pipeline Inference Complet

```
@lidarTrainer Cr√©e un pipeline d'inf√©rence production pour :

**Input** : Tiles LiDAR .las (10-50M points)
**Output** : Tiles classifi√©es + m√©triques confidence

**√âtapes**
1. Chargement + preprocessing
2. Chunking adaptatif (selon RAM disponible)
3. Inference batch
4. Post-processing (stitching, filtering)
5. Export r√©sultats

**Requis**
- Logging complet
- Gestion erreurs robuste
- Monitoring performances
- API simple (CLI + Python)

Framework : ign_lidar compatible
```

---

### Prompt : Docker Containerization

```
@lidarTrainer Containerise mon mod√®le entra√Æn√© pour d√©ploiement :

**Mod√®le**
- Architecture : [architecture]
- Checkpoint : [path]
- Dependencies : [requirements.txt]

**Container specs**
- Base image : nvidia/cuda:[version]
- Inference API : FastAPI
- GPU support : CUDA [version]

G√©n√®re :
1. Dockerfile optimis√©
2. docker-compose.yml
3. API endpoint examples
4. Documentation d√©ploiement
```

---

## üí° Tips pour Prompts Efficaces

### ‚úÖ Bonnes Pratiques

1. **Contexte pr√©cis**

   ```
   ‚ùå "Entra√Æne un mod√®le"
   ‚úÖ "Entra√Æne PointNet++ MSG sur dataset IGN (3.4M pts, 3 classes)
       avec target mIoU > 0.85"
   ```

2. **M√©triques chiffr√©es**

   ```
   ‚ùå "Am√©liore les performances"
   ‚úÖ "Augmente F1 buildings de 0.78 ‚Üí 0.90"
   ```

3. **Hardware explicite**

   ```
   ‚ùå "Optimise pour GPU"
   ‚úÖ "Optimise pour RTX 3090 (24GB RAM), batch_size max ?"
   ```

4. **Distribution classes**

   ```
   ‚ùå "3 classes"
   ‚úÖ "Ground 45%, Vegetation 35%, Buildings 20%"
   ```

5. **Contraintes claires**
   ```
   ‚ùå "Rapide"
   ‚úÖ "< 2h entra√Ænement, < 100ms inference par tile"
   ```

### ‚ùå Erreurs √† √âviter

1. **Trop vague**

   ```
   ‚ùå "Aide-moi avec mon mod√®le"
   ```

2. **Sans contexte**

   ```
   ‚ùå "Impl√©mente PointNet++"
   (Manque : dataset, classes, target, hardware)
   ```

3. **Multiples demandes non li√©es**

   ```
   ‚ùå "Entra√Æne un mod√®le ET optimise features ET d√©bugge overfitting"
   (S√©parer en 3 prompts)
   ```

4. **Jargon ambigu**
   ```
   ‚ùå "Rends-le meilleur"
   ‚úÖ "Augmente mIoU de [X] ‚Üí [Y]"
   ```

---

## üéì Templates R√©utilisables

### Template : Nouveau Projet

```
@lidarTrainer Je d√©marre un nouveau projet de classification LiDAR :

**Dataset**
- Source : [IGN / custom / autre]
- Taille : [X]M points
- Format : [.las / .laz / .xyz]
- Classes : [liste avec distribution]

**Objectifs**
- mIoU : > [target]
- F1 per class : [targets]
- Contraintes : [temps / hardware / autre]

**Hardware**
- GPU : [model], [X]GB
- CPU : [cores], [X]GB RAM

Guide-moi pas-√†-pas :
1. Feature engineering
2. Choix architecture
3. Configuration entra√Ænement
4. Strat√©gie validation
```

### Template : Am√©lioration Existant

```
@lidarTrainer Am√©liore mon mod√®le existant :

**Baseline actuelle**
- Architecture : [architecture]
- M√©triques : [coller classification report]
- Config : [path ou coller YAML]

**Probl√®mes identifi√©s**
1. [probl√®me 1 avec m√©triques]
2. [probl√®me 2 avec m√©triques]

**Nouvelles contraintes**
- [contrainte 1]
- [contrainte 2]

Propose un plan d'am√©lioration avec gains estim√©s.
```

---

**Derni√®re mise √† jour** : Novembre 2025  
**Maintenu par** : LiDAR Trainer Agent  
**Contributeurs** : Simon Ducournau, communaut√© IGN LiDAR HD
