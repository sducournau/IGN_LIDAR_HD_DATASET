"""
Transport Overlay Enhancement Module

This module provides advanced road and railway overlay capabilities including:
- Adaptive buffering based on geometry curvature
- Spatial indexing for fast point classification
- Confidence scoring and quality metrics
- Advanced geometry handling (bridges, tunnels, intersections)

Migrated from transport_enhancement.py to transport/enhancement.py (Phase 3C).

Author: Transport Enhancement Team
Date: October 15, 2025
Updated: October 22, 2025 - Migrated to transport module (Phase 3C)
Version: 3.1.0
"""

import logging
from typing import List, Tuple, Optional, Dict, Any
from dataclasses import dataclass, asdict
from pathlib import Path
import json
import time

import numpy as np

logger = logging.getLogger(__name__)

# Optional dependencies with graceful fallback
try:
    from shapely.geometry import Point, LineString, Polygon, MultiPolygon, shape, box
    from shapely.ops import unary_union
    HAS_SHAPELY = True
except ImportError:
    HAS_SHAPELY = False
    logger.warning("shapely not available - geometric operations disabled")

try:
    from rtree import index
    HAS_RTREE = True
except ImportError:
    HAS_RTREE = False
    logger.warning("rtree not available - spatial indexing disabled (install with: pip install rtree)")

try:
    import geopandas as gpd
    HAS_GEOPANDAS = True
except ImportError:
    HAS_GEOPANDAS = False
    logger.warning("geopandas not available - some features disabled")

# Import from transport module base and utils
from .base import (
    BufferingConfig,
    IndexingConfig,
    QualityMetricsConfig,
    TransportBufferBase,
    TransportClassifierBase,
)
from .utils import (
    calculate_curvature,
    compute_adaptive_width,
    get_road_type_tolerance,
    get_railway_type_tolerance,
    detect_intersections,
    create_adaptive_buffer,
    HAS_SCIPY,
)


# ============================================================================
# Quality Metrics & Results
# ============================================================================

@dataclass
class TransportClassificationScore:
    """Quality metrics for a single classified point."""
    
    point_idx: int
    asprs_class: int
    confidence: float = 0.0
    
    # Contributing factors
    ground_truth_match: bool = False
    geometric_match: bool = False
    intensity_match: bool = False
    proximity_to_centerline: float = 999.0  # Distance in meters
    
    def calculate_confidence(self) -> float:
        """Calculate overall confidence score (0.0 - 1.0)."""
        score = 0.0
        
        # Ground truth is strongest signal
        if self.ground_truth_match:
            score += 0.6
        
        # Geometric features
        if self.geometric_match:
            score += 0.2
        
        # Intensity refinement
        if self.intensity_match:
            score += 0.1
        
        # Proximity bonus (closer to centerline = higher confidence)
        proximity_score = max(0, 1.0 - (self.proximity_to_centerline / 3.0))
        score += proximity_score * 0.1
        
        return min(1.0, score)


@dataclass
class TransportCoverageStats:
    """Statistics for transport overlay quality."""
    
    # Road statistics
    n_roads_processed: int = 0
    n_road_points_classified: int = 0
    avg_points_per_road: float = 0.0
    road_width_range: Tuple[float, float] = (0.0, 0.0)
    road_types_detected: Dict[int, int] = None
    
    # Railway statistics
    n_railways_processed: int = 0
    n_rail_points_classified: int = 0
    avg_points_per_railway: float = 0.0
    railway_track_counts: List[int] = None
    
    # Quality metrics
    avg_confidence: float = 0.0
    low_confidence_ratio: float = 0.0
    overlap_detections: int = 0
    
    # Geometry coverage
    centerline_coverage: float = 0.0
    buffer_utilization: float = 0.0
    
    def __post_init__(self):
        """Initialize mutable defaults."""
        if self.road_types_detected is None:
            self.road_types_detected = {}
        if self.railway_track_counts is None:
            self.railway_track_counts = []
    
    def to_json(self) -> str:
        """Export statistics to JSON."""
        data = asdict(self)
        # Convert non-serializable types
        if 'road_width_range' in data:
            data['road_width_range'] = list(data['road_width_range'])
        return json.dumps(data, indent=2)
    
    def generate_report(self) -> str:
        """Generate human-readable report."""
        report = [
            "=" * 70,
            "TRANSPORT OVERLAY QUALITY REPORT",
            "=" * 70,
            "",
            "ðŸ“ ROAD OVERLAY",
            f"  Roads processed:      {self.n_roads_processed}",
            f"  Points classified:    {self.n_road_points_classified:,}",
            f"  Avg points/road:      {self.avg_points_per_road:.0f}",
            f"  Width range:          {self.road_width_range[0]:.1f}m - {self.road_width_range[1]:.1f}m",
            "",
            "ðŸš‚ RAILWAY OVERLAY",
            f"  Railways processed:   {self.n_railways_processed}",
            f"  Points classified:    {self.n_rail_points_classified:,}",
            f"  Avg points/railway:   {self.avg_points_per_railway:.0f}",
            f"  Track counts:         {sorted(set(self.railway_track_counts)) if self.railway_track_counts else 'N/A'}",
            "",
            "âœ… QUALITY METRICS",
            f"  Avg confidence:       {self.avg_confidence:.2f}",
            f"  Low confidence:       {self.low_confidence_ratio*100:.1f}%",
            f"  Overlaps detected:    {self.overlap_detections}",
            f"  Centerline coverage:  {self.centerline_coverage*100:.1f}%",
            "=" * 70
        ]
        return "\n".join(report)


# ============================================================================
# Adaptive Buffering Implementation
# ============================================================================

class AdaptiveTransportBuffer(TransportBufferBase):
    """
    Advanced buffering engine for transport features.
    
    Provides:
    - Curvature-aware variable-width buffering
    - Road-type specific tolerances
    - Intersection detection and enhancement
    - Elevation-aware filtering
    
    Inherits from TransportBufferBase and implements abstract methods.
    """
    
    def __init__(self, config: Optional[BufferingConfig] = None):
        """
        Initialize adaptive buffer engine.
        
        Args:
            config: Adaptive buffering configuration
        """
        if config is None:
            config = BufferingConfig()
        
        super().__init__(config)
        logger.info("Initialized AdaptiveTransportBuffer")
        
        if self.config.curvature_aware and not HAS_SCIPY:
            logger.warning("Curvature-aware buffering requires scipy - disabled")
            self.config.curvature_aware = False
        
        if not HAS_SHAPELY:
            raise ImportError("shapely required for adaptive buffering")
    
    def process_roads(self, roads_gdf: 'gpd.GeoDataFrame') -> 'gpd.GeoDataFrame':
        """
        Process roads with adaptive buffering.
        
        Args:
            roads_gdf: GeoDataFrame with road centerlines and attributes
            
        Returns:
            GeoDataFrame with enhanced road polygons
        """
        if not HAS_GEOPANDAS:
            logger.error("geopandas required for road processing")
            return roads_gdf
        
        logger.info(f"Processing {len(roads_gdf)} roads with adaptive buffering...")
        start_time = time.time()
        
        # OPTIMIZED: Vectorized road processing (5-20Ã— faster than iterrows)
        # Step 1: Filter LineStrings only (vectorized)
        line_mask = roads_gdf.geometry.apply(lambda g: isinstance(g, LineString))
        roads_lines = roads_gdf[line_mask].copy()
        
        if len(roads_lines) == 0:
            logger.warning("No valid LineString geometries found in roads")
            return gpd.GeoDataFrame(columns=roads_gdf.columns, crs=roads_gdf.crs)
        
        # Step 2: Extract attributes (vectorized)
        roads_lines.loc[:, 'width_m'] = roads_lines.get('width_m', 4.0)
        roads_lines.loc[:, 'nature'] = roads_lines.get('nature', 'unknown')
        
        # Step 3: Apply adaptive buffering (vectorized with apply)
        def buffer_road(row):
            """Apply adaptive buffering to a single road."""
            buffered = create_adaptive_buffer(
                row.geometry, 
                row['width_m'], 
                self.config.curvature_aware,
                self.config.curvature_factor
            )
            tolerance = get_road_type_tolerance(row['nature'], self.config)
            if tolerance > 0:
                buffered = buffered.buffer(tolerance)
            return buffered, tolerance
        
        # Apply buffering and extract tolerance
        buffering_results = roads_lines.apply(buffer_road, axis=1, result_type='expand')
        roads_lines.loc[:, 'geometry'] = buffering_results[0]
        roads_lines.loc[:, 'tolerance_m'] = buffering_results[1]
        roads_lines.loc[:, 'original_geometry'] = roads_gdf.loc[line_mask, 'geometry'].values
        
        result_gdf = roads_lines
        
        elapsed = time.time() - start_time
        logger.info(f"Enhanced {len(result_gdf)} roads in {elapsed:.2f}s")
        
        return result_gdf
    
    def process_railways(self, railways_gdf: 'gpd.GeoDataFrame') -> 'gpd.GeoDataFrame':
        """
        Process railways with adaptive buffering.
        
        Args:
            railways_gdf: GeoDataFrame with railway centerlines and attributes
            
        Returns:
            GeoDataFrame with enhanced railway polygons
        """
        if not HAS_GEOPANDAS:
            logger.error("geopandas required for railway processing")
            return railways_gdf
        
        logger.info(f"Processing {len(railways_gdf)} railways with adaptive buffering...")
        start_time = time.time()
        
        # OPTIMIZED: Vectorized railway processing (5-20Ã— faster than iterrows)
        # Step 1: Filter LineStrings only (vectorized)
        line_mask = railways_gdf.geometry.apply(lambda g: isinstance(g, LineString))
        railways_lines = railways_gdf[line_mask].copy()
        
        if len(railways_lines) == 0:
            logger.warning("No valid LineString geometries found in railways")
            return gpd.GeoDataFrame(columns=railways_gdf.columns, crs=railways_gdf.crs)
        
        # Step 2: Extract attributes (vectorized)
        railways_lines.loc[:, 'width_m'] = railways_lines.get('width_m', 3.5)
        railways_lines.loc[:, 'nature'] = railways_lines.get('nature', 'voie_ferree')
        
        # Step 3: Determine tolerance (vectorized)
        railways_lines.loc[:, 'tolerance_m'] = railways_lines['nature'].apply(
            lambda nature: get_railway_type_tolerance(nature, self.config)
        )
        
        # Step 4: Apply adaptive buffering (vectorized with apply)
        def buffer_railway(row):
            """Apply adaptive buffering to a single railway."""
            buffered = create_adaptive_buffer(
                row.geometry,
                row['width_m'],
                self.config.curvature_aware,
                self.config.curvature_factor
            )
            if row['tolerance_m'] > 0:
                buffered = buffered.buffer(row['tolerance_m'])
            return buffered
        
        railways_lines.loc[:, 'original_geometry'] = railways_gdf.loc[line_mask, 'geometry'].values
        railways_lines.loc[:, 'geometry'] = railways_lines.apply(buffer_railway, axis=1)
        
        result_gdf = railways_lines
        
        elapsed = time.time() - start_time
        logger.info(f"Enhanced {len(result_gdf)} railways in {elapsed:.2f}s")
        
        return result_gdf


# ============================================================================
# Spatial Indexing for Fast Classification
# ============================================================================

class SpatialTransportClassifier(TransportClassifierBase):
    """
    Fast spatial indexing for transport overlay using R-tree.
    
    Provides 5-10x speedup over linear point-in-polygon queries
    for large point clouds (millions of points).
    
    Inherits from TransportClassifierBase and implements abstract methods.
    """
    
    def __init__(self, config: Optional[IndexingConfig] = None):
        """
        Initialize spatial classifier.
        
        Args:
            config: Spatial indexing configuration
        """
        if config is None:
            config = IndexingConfig()
        
        super().__init__(config)
        
        if self.config.enabled and not HAS_RTREE:
            logger.warning("rtree not available - spatial indexing disabled")
            self.config.enabled = False
        
        self.road_idx = None
        self.rail_idx = None
        self.road_data = {}
        self.rail_data = {}
        
        if self.config.enabled:
            self.road_idx = index.Index()
            self.rail_idx = index.Index()
            logger.info("Initialized spatial index (R-tree)")
    
    def index_roads(self, roads_gdf: 'gpd.GeoDataFrame'):
        """
        Build R-tree index for roads.
        
        Args:
            roads_gdf: GeoDataFrame with road polygons
        """
        if not self.config.enabled or self.road_idx is None:
            logger.warning("Spatial indexing not enabled")
            return
        
        logger.info(f"Building spatial index for {len(roads_gdf)} roads...")
        start_time = time.time()
        
        for idx, row in roads_gdf.iterrows():
            geom = row['geometry']
            
            if geom is None or geom.is_empty:
                continue
            
            bounds = geom.bounds  # (minx, miny, maxx, maxy)
            
            self.road_idx.insert(
                idx,
                bounds,
                obj={'geometry': geom, 'attributes': row.to_dict()}
            )
            self.road_data[idx] = row
        
        elapsed = time.time() - start_time
        logger.info(f"Indexed {len(self.road_data)} roads in {elapsed:.3f}s")
    
    def index_railways(self, railways_gdf: 'gpd.GeoDataFrame'):
        """
        Build R-tree index for railways.
        
        Args:
            railways_gdf: GeoDataFrame with railway polygons
        """
        if not self.config.enabled or self.rail_idx is None:
            logger.warning("Spatial indexing not enabled")
            return
        
        logger.info(f"Building spatial index for {len(railways_gdf)} railways...")
        start_time = time.time()
        
        for idx, row in railways_gdf.iterrows():
            geom = row['geometry']
            
            if geom is None or geom.is_empty:
                continue
            
            bounds = geom.bounds  # (minx, miny, maxx, maxy)
            
            self.rail_idx.insert(
                idx,
                bounds,
                obj={'geometry': geom, 'attributes': row.to_dict()}
            )
            self.rail_data[idx] = row
        
        elapsed = time.time() - start_time
        logger.info(f"Indexed {len(self.rail_data)} railways in {elapsed:.3f}s")
    
    def classify_points_fast(
        self,
        points: np.ndarray,
        labels: np.ndarray,
        asprs_code_road: int = 11,
        asprs_code_rail: int = 10
    ) -> np.ndarray:
        """
        Fast point classification using spatial index.
        
        Expected speedup: 5-10x over linear scanning
        
        Args:
            points: Point coordinates [N, 3] or [N, 2]
            labels: Current classification labels [N]
            asprs_code_road: ASPRS code for roads
            asprs_code_rail: ASPRS code for railways
            
        Returns:
            Updated classification labels [N]
        """
        if not self.config.enabled:
            logger.warning("Spatial indexing not enabled - use fallback classification")
            return labels
        
        if not HAS_SHAPELY:
            logger.error("shapely required for point classification")
            return labels
        
        logger.info(f"Fast spatial classification of {len(points):,} points...")
        start_time = time.time()
        
        refined = labels.copy()
        n_road_classified = 0
        n_rail_classified = 0
        
        # Classify railways first (higher priority in overlaps)
        if self.rail_idx is not None and len(self.rail_data) > 0:
            for i, point in enumerate(points):
                pt = Point(point[0], point[1])
                
                # Query R-tree for nearby railways (fast!)
                candidates = list(self.rail_idx.intersection(
                    (pt.x, pt.y, pt.x, pt.y),
                    objects=True
                ))
                
                # Check only nearby candidates
                for candidate in candidates:
                    geom = candidate.object['geometry']
                    if geom.contains(pt):
                        refined[i] = asprs_code_rail
                        n_rail_classified += 1
                        break  # First match wins
        
        # Classify roads
        if self.road_idx is not None and len(self.road_data) > 0:
            for i, point in enumerate(points):
                # Skip if already classified as railway
                if refined[i] == asprs_code_rail:
                    continue
                
                pt = Point(point[0], point[1])
                
                # Query R-tree for nearby roads (fast!)
                candidates = list(self.road_idx.intersection(
                    (pt.x, pt.y, pt.x, pt.y),
                    objects=True
                ))
                
                # Check only nearby candidates
                for candidate in candidates:
                    geom = candidate.object['geometry']
                    if geom.contains(pt):
                        attrs = candidate.object['attributes']
                        refined[i] = attrs.get('asprs_class', asprs_code_road)
                        n_road_classified += 1
                        break  # First match wins
        
        elapsed = time.time() - start_time
        logger.info(
            f"Classified {n_road_classified:,} road + {n_rail_classified:,} rail points "
            f"in {elapsed:.3f}s ({len(points)/elapsed:.0f} pts/s)"
        )
        
        return refined


# ============================================================================
# Export
# ============================================================================

__all__ = [
    # Buffering classes
    'AdaptiveTransportBuffer',
    
    # Spatial indexing classes
    'SpatialTransportClassifier',
    
    # Quality metrics
    'TransportClassificationScore',
    'TransportCoverageStats',
]
