# ============================================================================
# IGN LiDAR HD - Preset: ASPRS CPU - Multi-Worker Optimization
# ============================================================================
# Based on: asprs.yaml
#
# HARDWARE: CPU-only systems with multi-core processors
# OPTIMIZATION: Maximized multi-worker parallelism and memory efficiency
#
# KEY OPTIMIZATIONS:
#   - Disabled GPU processing (CPU-only)
#   - Multi-worker parallel processing (auto-detects CPU cores)
#   - Optimized batch sizes for CPU memory hierarchy
#   - Efficient STRtree spatial indexing for ground truth
#   - Memory-conscious chunking strategy
#   - Parallel feature computation across workers
#
# RECOMMENDED HARDWARE:
#   - CPU: 8+ cores (16+ threads recommended)
#   - RAM: 32GB+ (64GB recommended for large tiles)
#   - Storage: Fast SSD for I/O performance
#
# EXPECTED PERFORMANCE:
#   - Scales linearly with CPU cores (up to 8-12 workers)
#   - ~20-40 million points per minute (8-core system)
#   - Memory-efficient chunking prevents OOM errors
#   - Optimal for systems without GPU or batch processing
#
# USAGE:
#   ign-lidar-hd process --preset asprs_cpu input/ output/
#
# Version: 5.1.0 CPU
# Date: October 18, 2025
# ============================================================================

# Inherit from base configuration
defaults:
  - ../base
  - _self_

# Preset metadata
config_version: "5.1.0"
preset_name: "asprs_cpu"

# ============================================================================
# CPU MULTI-WORKER OPTIMIZATIONS
# ============================================================================

# Processor: CPU-optimized settings
processor:
  # Classification scheme
  lod_level: "ASPRS" # Use ASPRS LAS 1.4 classification
  processing_mode: "enriched_only" # Generate enriched LAZ output only (no patches)

  # ============================================================================
  # CPU SETTINGS - MULTI-WORKER PARALLELISM
  # ============================================================================
  use_gpu: false # DISABLED - Force CPU-only processing

  # CPU batch/chunk size: Controls tile-level chunking
  # - For 18.6M point tiles: Use 5M for memory-efficient chunking (4 chunks)
  # - Memory: ~600MB per 5M points (XYZ float32 + features)
  # - CPU: Can handle multiple workers processing 5M chunks in parallel
  gpu_batch_size: 5_000_000 # 5M points (memory-efficient for CPU)

  # Multi-worker settings (CRITICAL for CPU performance)
  # Auto-detection recommendations:
  #   - 4-core CPU: 4-6 workers
  #   - 8-core CPU: 8-10 workers
  #   - 16-core CPU: 12-16 workers
  #   - 32+ core CPU: 16-24 workers (diminishing returns beyond 16)
  num_workers: -1 # -1 = Auto-detect (uses CPU count)

  # CPU-specific optimizations
  use_cuda_streams: false # N/A for CPU
  enable_memory_pooling: false # N/A for CPU
  enable_pipeline_optimization: false # N/A for CPU
  auto_optimize: true # Enable automatic parameter tuning
  chunk_size: null # Auto-determined based on available RAM
  vram_limit_gb: null # N/A for CPU
  cleanup_frequency: 10 # Cleanup every 10 iterations

  # Strategy pattern (Week 2 improvement)
  use_strategy_pattern: true # Use new Strategy Pattern

  # Optimization flags
  use_optimized_ground_truth: true # Use optimized ground truth classifier
  enable_async_transfers: false # N/A for CPU
  adaptive_chunk_sizing: true # Dynamic chunk sizing based on RAM

  # Processing settings
  skip_existing: true # Skip existing outputs
  output_format: "laz" # Output format
  use_stitching: false # Tile stitching disabled by default

  # Patch extraction (DISABLED for enriched_only mode)
  # Note: These parameters are unused when save_patches=false
  patch_size: 50.0 # Patch size in meters (not used in enriched_only mode)
  patch_overlap: 0.1 # 10% overlap (not used in enriched_only mode)
  num_points: 24576 # Points per patch (not used in enriched_only mode)
  architecture: "direct" # Direct patch extraction (not used in enriched_only mode)
  augment: false # No augmentation for enriched-only mode
  num_augmentations: 3 # Augmentations if enabled (not used in enriched_only mode)

  # Ground truth settings - CPU-OPTIMIZED
  ground_truth_method: "strtree" # STRtree for CPU (efficient spatial indexing)
  ground_truth_chunk_size: 5_000_000 # 5M points per chunk - memory-efficient

  # Reclassification
  reclassification:
    enabled: true
    use_geometric_rules: true # Height, planarity for refinement
    use_ndvi_classification: true # Enable if NIR available
    min_confidence: 0.8 # High confidence for ASPRS compliance

# Features: ASPRS-optimized feature set with CPU tuning
features:
  mode: "asprs_classes" # ASPRS feature mode
  include_extra: true # Include extra features for classification

  # Geometric parameters
  k_neighbors: 20 # Standard neighborhood
  search_radius: 1.0 # 1 meter radius

  # CPU settings - MULTI-WORKER PARALLEL PROCESSING
  use_gpu_chunked: false # DISABLED - Use CPU computation
  gpu_batch_size: 5_000_000 # CPU chunk size (aligned with processor)

  # ============================================================================
  # CPU OPTIMIZATION: Neighbor Query & Feature Batching
  # ============================================================================
  # These parameters control memory allocation and processing granularity:
  #
  # neighbor_query_batch_size: Controls KNN query batching
  #   - For CPU: Use 2M for memory-efficient processing
  #   - Memory impact: ~2M × 20 neighbors × 4 bytes = 160MB per worker
  #   - Multiple workers can process chunks in parallel
  #
  # feature_batch_size: Controls normal/curvature computation batching
  #   - For CPU: Use 1M for cache-friendly processing
  #   - Memory: ~1M × 20 × 3 × 4 bytes = 240MB per worker
  #   - L3 cache-friendly size for most modern CPUs
  #
  # MULTI-WORKER SCALING:
  #   - 8 workers × 5M chunks = 40M points processed concurrently
  #   - Total memory: ~5GB (manageable on 32GB RAM systems)
  #   - Linear speedup up to 8-12 workers (depends on CPU cores)
  # ============================================================================

  neighbor_query_batch_size: 2_000_000 # 2M points (memory-efficient for CPU)
  feature_batch_size: 1_000_000 # 1M points (cache-friendly for CPU)

  # Essential features for ASPRS
  compute_normals: true
  compute_curvature: true
  compute_height: true # Critical for vegetation height
  compute_geometric: true # Planarity, verticality

  # Architectural features not critical for ASPRS
  compute_architectural: false

  # Spectral features for vegetation/ground distinction
  use_rgb: true # Recommended for better vegetation classification
  use_nir: true # NIR (near-infrared) - enable if available
  use_infrared: true # Infrared - enable if NIR available (alias for use_nir)
  compute_ndvi: true # NDVI (requires RGB + NIR) - will auto-disable if NIR unavailable

# Ground Truth: CPU-optimized ground truth
ground_truth:
  enabled: true # Enable ground truth classification
  method: "strtree" # Use STRtree for CPU (efficient spatial indexing)
  chunk_size: 5_000_000 # 5M points per chunk (aligned with gpu_batch_size)
  cache_dir: null # Auto-set to {input_dir}/cache/ground_truth
  cache_ttl_days: 30 # 30 days cache validity
  preclassify: true # Pre-classify with BD TOPO
  use_gpu: false # Force CPU processing

  # BD TOPO classification settings
  bd_topo:
    enabled: true
    road_buffer: 2.5
    building_buffer: 0.3
    road_width_fallback: 4.0

# Data Sources: Full BD TOPO for ASPRS ground truth
data_sources:
  # BD TOPO: Essential for ASPRS ground truth
  bd_topo:
    enabled: true
    features:
      buildings: true # ASPRS Class 6
      roads: true # ASPRS Class 11
      water: true # ASPRS Class 9
      vegetation: false # ASPRS Classes 3/4/5 (low/medium/high vegetation)

  # Additional BD TOPO layers for ASPRS
  bd_topo_bridges: true # Enable for ASPRS Class 17
  bd_topo_power_lines: true # Enable for ASPRS Class 14

  # Orthophotos for spectral features
  orthophoto_rgb: true # Recommended for vegetation
  orthophoto_nir: true # Enable for NDVI computation

# Output: Standard ASPRS outputs
output:
  format: "laz" # Output format (required by CLI)
  save_enriched: true # Enriched LAZ with ASPRS classes
  save_patches: false # DISABLED - No patch generation for enriched-only mode
  save_metadata: true # Save metadata
  save_stats: true # Save ASPRS classification statistics

# Preprocessing: Enable for quality control
preprocess:
  enabled: false # Disabled by default for ASPRS

# Tile Stitching: Disabled for ASPRS
stitching:
  enabled: false # No stitching by default
  buffer_size: 10.0 # Buffer size in meters if enabled

# ============================================================================
# EXPECTED PERFORMANCE vs GPU (Multi-Worker CPU)
# ============================================================================
# Processing speed:
#   - 8-core CPU: ~30-50 million points per minute
#   - 16-core CPU: ~50-80 million points per minute
#   - Scales linearly up to 8-12 workers (then diminishing returns)
#   - 3-5× slower than RTX 4080 GPU but cost-effective
#   - Suitable for batch processing and systems without GPU
#
# Memory usage:
#   - RAM: 4-8GB per worker (32GB RAM = 4-6 workers comfortably)
#   - Peak allocations per worker:
#     * Points: ~600MB (5M × 3 × 4 bytes)
#     * KNN indices: ~400MB (5M × 20 × 4 bytes)
#     * Neighbor points: ~1.2GB (5M × 20 × 3 × 4 bytes)
#     * Features: ~60MB (5M × 3 × 4 bytes)
#     * Total per worker: ~2.3GB
#   - 8 workers: ~18GB total (fits in 32GB RAM)
#   - 16 workers: ~36GB total (requires 64GB RAM)
#
# Throughput (8-core system):
#   - ~30-50 million points per minute
#   - Depends on feature complexity and I/O speed
#   - SSD storage highly recommended
#
# Tile handling (Multi-worker parallel processing):
#   - 18M point tiles: 4 chunks × 5M points
#   - Each chunk processed by separate worker
#   - 4 tiles can be processed simultaneously (8 workers)
#   - Total throughput: 72M points processed at once
#
# SCALING RECOMMENDATIONS:
#   - 4-core CPU: Set num_workers: 4-6
#   - 8-core CPU: Set num_workers: 8-10 (optimal)
#   - 16-core CPU: Set num_workers: 12-16
#   - 32+ cores: Set num_workers: 16-24 (diminishing returns)
#   - RAM requirement: 4GB per worker + 8GB base
#
# WHEN TO USE CPU vs GPU:
#   ✓ No GPU available
#   ✓ Batch processing (overnight jobs)
#   ✓ Multiple tiles processed simultaneously
#   ✓ Cost-sensitive deployments
#   ✓ Development/testing environments
#   × Real-time processing requirements
#   × Single large tile processing (GPU is faster)
# ============================================================================
