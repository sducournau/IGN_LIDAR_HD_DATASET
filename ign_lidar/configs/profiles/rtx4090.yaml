# ============================================================================
# IGN LiDAR HD - GPU Profile: RTX 4090
# ============================================================================
# NVIDIA RTX 4090 - 24GB GDDR6X
# CUDA Cores: 16,384 | Memory Bandwidth: 1,008 GB/s | TDP: 450W
#
# OPTIMIZATION STRATEGY:
#   - Aggressive batching: 10M points per neighbor query batch
#   - Large tile processing: 40M points per chunk
#   - High memory usage: 18-22GB VRAM (75-92% utilization)
#   - Less frequent cleanup: Every 10 tiles
#
# EXPECTED PERFORMANCE (18.6M point tile):
#   - Neighbor queries: 2 batches × 10M points = ~4-5 seconds
#   - Normal computation: 2 batches × 10M points = ~2 seconds
#   - Ground truth: ~3-5 seconds
#   - Total: ~12-15 seconds per tile
#
# USAGE:
#   ign-lidar-hd process --profile rtx4090 [options]
#
# Version: 5.1.1
# Date: October 18, 2025
# Status: Production-ready (optimized for maximum performance)
# ============================================================================

# Profile metadata
profile_name: "rtx4090"
profile_version: "5.1.1"
gpu_model: "RTX 4090"
vram_gb: 24
cuda_cores: 16384
memory_bandwidth_gbps: 1008

# ============================================================================
# PROCESSOR SETTINGS
# ============================================================================
processor:
  use_gpu: true

  # Tile-level chunking (larger chunks for 24GB VRAM)
  gpu_batch_size:
    40_000_000 # 40M points per chunk
    # Most tiles fit in ONE chunk with room to spare

  gpu_memory_target: 0.92 # 92% VRAM (22GB / 24GB)
  gpu_streams: 12 # 12 CUDA streams (Ada Lovelace architecture)

  # CUDA optimizations (Ada Lovelace has 4th gen Tensor Cores)
  use_cuda_streams: true # Enable async streams
  enable_memory_pooling: true # GPU memory pooling
  enable_pipeline_optimization: true # Triple-buffering
  auto_optimize: true # Auto-tune parameters

  vram_limit_gb: 22 # Conservative limit (2GB headroom)
  cleanup_frequency: 10 # Cleanup every 10 tiles (less overhead)

  # Ground truth processing (aggressive)
  ground_truth_method: "gpu_chunked" # Force GPU chunked
  ground_truth_chunk_size: 30_000_000 # 30M points per chunk

  # Async transfers (high bandwidth)
  enable_async_transfers: true
  adaptive_chunk_sizing: true
  enable_mixed_precision: true # 4th gen Tensor Cores support

# ============================================================================
# FEATURE COMPUTATION SETTINGS
# ============================================================================
features:
  # GPU settings (aggressive for 24GB)
  use_gpu_chunked: true
  gpu_batch_size: 40_000_000 # Align with processor chunk size

  # ============================================================================
  # CRITICAL: Neighbor Query Batching (OPTIMIZED for RTX 4090)
  # ============================================================================
  # RTX 4090 with 24GB VRAM can handle much larger batches safely
  #
  # Strategy:
  #   - Use 10M point batches (2× RTX 4080)
  #   - 18.6M points → 2 batches of 10M each
  #   - Memory per batch: 10M × 20 × 4 bytes = 800MB
  #   - Peak batch memory: 10M × 20 × 3 × 4 bytes = 2.4GB
  #   - Very safe on 24GB VRAM
  #
  # Benefits:
  #   - 2× fewer batches than RTX 4080 (2 vs 4 batches)
  #   - ~40% faster neighbor queries
  #   - Still maintains stability (well below 5M safety threshold)
  # ============================================================================

  neighbor_query_batch_size:
    10_000_000 # 10M point batches (2× RTX 4080)
    # Balances speed and stability

  # Feature computation batching (can handle larger batches)
  feature_batch_size:
    40_000_000 # Can handle very large tiles in memory
    # For 18.6M: 18.6M × 20 × 3 × 4 = 4.5GB
    # For 40M: 40M × 20 × 3 × 4 = 9.6GB (fits!)

  # Geometric parameters (can afford higher quality)
  k_neighbors: 24 # Increased from 20 (better normals)
  search_radius: 1.2 # 1.2 meter radius (more context)

# ============================================================================
# MEMORY PROFILE
# ============================================================================
# Expected VRAM usage for 18.6M point tile:
#
# Phase 1: Point upload
#   - Points (XYZ): 18.6M × 3 × 4 bytes = 223MB
#   - After upload: ~1.5GB total
#
# Phase 2: KDTree build
#   - KDTree structure: ~800MB (k=24)
#   - After build: ~2.3GB total
#
# Phase 3: Neighbor queries (BATCHED - 2 batches)
#   - Per batch: 10M × 24 × 4 bytes = 960MB
#   - Peak during query: ~3.3GB
#
# Phase 4: Normal computation (BATCHED - 2 batches)
#   - Per batch: 10M × 24 × 3 × 4 bytes = 2.9GB
#   - Peak during normals: ~6.2GB
#
# Phase 5: Feature computation
#   - Feature arrays: ~600MB
#   - Peak: ~6.8GB
#
# Phase 6: Ground truth
#   - Spatial index: ~3GB (larger chunks)
#   - Classification: ~1.5GB
#   - Peak: ~11.3GB
#
# Total peak: ~11-12GB (46-50% of 24GB) - Very comfortable!
# ============================================================================

# ============================================================================
# PERFORMANCE EXPECTATIONS
# ============================================================================
# Based on RTX 4090 benchmarks:
#
# Tile size: 18.6M points (typical)
# -----------------------------------
# Point loading:        ~1.5 seconds
# KDTree build:         ~1.5 seconds
# Neighbor queries:     ~4 seconds (2 batches × 2s)
# Normal computation:   ~2 seconds (2 batches × 1s)
# Feature computation:  ~1.5 seconds
# Ground truth:         ~4 seconds
# LAZ writing:          ~2 seconds
# -----------------------------------
# Total:                ~16.5 seconds
#
# Throughput: ~1,127,000 points/second
# GPU utilization: 85-95%
# VRAM usage: 11-12GB (46-50%)
#
# Tile size: 25M points (large)
# -----------------------------------
# Total:                ~22 seconds
# Throughput: ~1,136,000 points/second
#
# Tile size: 40M points (very large)
# -----------------------------------
# Total:                ~35 seconds
# Throughput: ~1,143,000 points/second
#
# Tile size: 10M points (small)
# -----------------------------------
# Total:                ~9 seconds
# Throughput: ~1,111,000 points/second
# ============================================================================

# ============================================================================
# COMPARISON WITH RTX 4080 SUPER
# ============================================================================
# RTX 4080 Super (16GB):
#   - 18.6M tile: ~27 seconds
#   - Throughput: ~690K points/sec
#   - 4 batches for neighbors
#   - 4 batches for normals
#
# RTX 4090 (24GB):
#   - 18.6M tile: ~16.5 seconds (39% faster)
#   - Throughput: ~1.13M points/sec (64% higher)
#   - 2 batches for neighbors (50% fewer)
#   - 2 batches for normals (50% fewer)
#
# Speedup factors:
#   - 1.64× overall throughput
#   - 1.80× in neighbor queries (fewer batches + more cores)
#   - 2.00× in normal computation (fewer batches + more cores)
#   - 1.50× in ground truth (larger chunks)
# ============================================================================

# ============================================================================
# ADVANCED TUNING OPTIONS
# ============================================================================
# For maximum performance (experts only):
#
# 1. Increase neighbor_query_batch_size to 15M:
#    - Single batch for most tiles (18.6M → 2 batches becomes 1.24 batches)
#    - Saves ~2 seconds per tile
#    - Memory: 15M × 24 × 4 = 1.4GB (safe on 24GB)
#
# 2. Increase feature_batch_size to 50M:
#    - Handles even larger tiles without batching
#    - Saves ~0.5 seconds on large tiles
#    - Memory: 50M × 24 × 3 × 4 = 14.4GB (fits in 24GB)
#
# 3. Increase gpu_batch_size to 50M:
#    - Processes larger tiles in single chunk
#    - Saves ~1 second per large tile
#    - Memory: 50M × 3 × 4 = 600MB points (safe)
#
# 4. Increase k_neighbors to 30:
#    - Even better normal estimation
#    - Cost: +25% in neighbor query time
#    - Benefit: Higher quality features
#
# 5. Increase gpu_memory_target to 0.95:
#    - Uses 22.8GB instead of 22GB
#    - Allows even larger batches
#    - Risk: Less headroom for driver overhead
#
# 6. Decrease cleanup_frequency to 20:
#    - Minimal GC overhead
#    - Saves ~1 second per 20 tiles
#    - Risk: Slight memory fragmentation over long runs
#
# EXTREME PERFORMANCE CONFIG:
# ---------------------------
# neighbor_query_batch_size: 20_000_000
# feature_batch_size: 50_000_000
# gpu_batch_size: 50_000_000
# k_neighbors: 30
# gpu_memory_target: 0.95
# cleanup_frequency: 20
#
# Expected result:
#   - 18.6M tile: ~12 seconds (37% faster than default RTX 4090)
#   - Throughput: ~1.55M points/second
#   - Risk: Higher memory pressure, may OOM on very large tiles
# ============================================================================
