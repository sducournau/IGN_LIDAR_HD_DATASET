# Investigation Summary: Workers and GPU Support

## Quick Reference

This investigation analyzed the multiprocessing (workers) and GPU acceleration systems in response to the OOM (Out Of Memory) issue encountered during augmented processing.

## Key Findings

### 1. Workers (Multiprocessing)

**Status:** ‚úÖ Fully functional with intelligent memory management

- **Automatic scaling:** System adjusts worker count based on:

  - Available RAM (5GB per worker for full mode)
  - File sizes (max 3 workers for files >500MB)
  - Swap usage (reduces to 1 worker if swap >50%)

- **Batch processing:** Limits concurrent tasks to prevent memory spikes
  - Large files (>300MB) in full mode: 1 file at a time
  - Medium files: Uses half the worker count
  - Small files: Full parallelization

**Current command uses 1 worker** (safe for large augmented files)

### 2. GPU Acceleration

**Status:** üü° Partially functional - **NOT compatible with chunking**

**Critical Finding:**

```python
if chunk_size is None:
    # GPU works (files < 10M points)
    compute_all_features_with_gpu(use_gpu=use_gpu)
else:
    # Chunking required (files > 10M points or augmentation)
    if use_gpu:
        warning("GPU not supported with chunking, using CPU")
    compute_all_features_optimized(chunk_size=chunk_size)
```

**Impact on your command:**

```bash
--augment --num-augmentations 2
```

- ‚úÖ Triggers chunked processing (5M chunks for 17.2M points)
- ‚ùå Automatically disables GPU (even if --use-gpu specified)
- ‚úÖ Uses CPU with memory-efficient chunking

### 3. Memory Optimization Integration

The v1.6.0 fix implemented:

1. **Aggressive chunking for augmentation:**
   - Before: 15M chunk size ‚Üí OOM crash
   - After: 5M chunk size ‚Üí Success
2. **Enhanced cleanup between versions:**

   ```python
   del las_out, normals, curvature
   del height_above_ground, geometric_features
   del points_ver, classification_ver
   gc.collect()  # Force memory release
   ```

3. **Chunk size logic:**
   ```python
   if augment and num_augmentations > 0:
       if n_points > 20_000_000:
           chunk_size = 3_000_000  # 3M chunks
       elif n_points > 10_000_000:
           chunk_size = 5_000_000  # 5M chunks (your case)
   ```

## Your Specific Case

### Command Analysis

```bash
ign-lidar-hd enrich \
  --input LHD_FXX_0479_6904_PTS_C_LAMB93_IGN69.laz \
  --output /mnt/c/Users/Simon/ign/test_full_enrich_output \
  --mode full \
  --k-neighbors 30 \
  --add-rgb \
  --add-infrared \
  --preprocess \
  --augment --num-augmentations 2
```

**System specs:**

- RAM: 27.3GB available (WSL2)
- File: 18,055,426 points ‚Üí 17,231,344 after preprocessing (4.6% reduction)
- Augmentation: 3 total versions (1 original + 2 augmented)

**Processing path taken:**

1. ‚úÖ **Workers:** 1 (explicit, safe for augmentation)
2. ‚ùå **GPU:** Disabled (chunking required)
3. ‚úÖ **Chunking:** Enabled (5M chunks = 4 chunks for 17.2M points)
4. ‚úÖ **Memory per version:** ~4GB (within 27.3GB / 3 = 9GB budget)

### Why It Now Works

**Before v1.6.0:**

- Chunk size: 15M points
- Memory per chunk: ~8GB
- With 3 versions + overhead: 24GB+ ‚Üí **OOM (Exit 137)**

**After v1.6.0:**

- Chunk size: 5M points (3x smaller)
- Memory per chunk: ~3GB
- With 3 versions + overhead: 12GB total ‚Üí **Success**

## Performance Expectations

### Current Run

- **Processing time:** ~20-30 minutes for full pipeline
  - Preprocessing (SOR/ROR): ~2 minutes ‚úÖ (already completed)
  - Augmentation generation: ~2 seconds ‚úÖ (already completed)
  - Feature computation: ~15-20 minutes (in progress)
  - RGB/Infrared augmentation: ~5-8 minutes per version

### Breakdown by Version

Each of the 3 versions processes:

1. KDTree building: ~30-45 seconds
2. Feature computation (4 chunks √ó 5M): ~5-7 minutes
3. RGB fetching: ~2-3 minutes
4. Infrared fetching: ~2-3 minutes
5. LAZ writing: ~30-45 seconds

**Total: ~10-12 minutes per version √ó 3 = 30-36 minutes**

## Optimization Opportunities

### For Your Workflow

#### Option 1: Skip Augmentation for Initial Tests

```bash
# Faster processing without augmentation
ign-lidar-hd enrich \
  --input tile.laz \
  --output output/ \
  --mode full \
  --add-rgb --add-infrared \
  --preprocess
  # No --augment flag
```

**Time saved:** ~66% faster (only 1 version instead of 3)

#### Option 2: Use Core Mode

```bash
# Fewer geometric features
ign-lidar-hd enrich \
  --input tile.laz \
  --output output/ \
  --mode core \
  --augment --num-augmentations 2
```

**Time saved:** ~40% faster (fewer features to compute)

#### Option 3: Multiple Workers for Multiple Files

```bash
# If you have multiple tiles to process
ign-lidar-hd enrich \
  --input tiles_directory/ \
  --output output/ \
  --workers 2 \
  --mode full
```

**Throughput:** 2x with 2 workers (if you have 40GB+ RAM)

### Future: GPU-Enabled Chunking

**Once implemented:**

```bash
ign-lidar-hd enrich \
  --input tile.laz \
  --output output/ \
  --mode full \
  --augment --num-augmentations 2 \
  --use-gpu \
  --gpu-memory 8192
```

**Expected speedup:** 10-15x faster feature computation  
**Time reduction:** 30 minutes ‚Üí 5-7 minutes

## Configuration Recommendations

### Your Current System (27GB RAM, No GPU)

**Best configuration for large augmented files:**

```bash
ign-lidar-hd enrich \
  --input large_tile.laz \
  --output output/ \
  --workers 1 \
  --mode full \
  --augment --num-augmentations 2
```

**Best configuration for multiple small files:**

```bash
ign-lidar-hd enrich \
  --input tiles_dir/ \
  --output output/ \
  --workers 3 \
  --mode full
  # No augmentation or process separately
```

**Best configuration for maximum throughput:**

```bash
# Process multiple tiles with moderate augmentation
ign-lidar-hd enrich \
  --input tiles_dir/ \
  --output output/ \
  --workers 2 \
  --mode core \
  --augment --num-augmentations 1
```

## Monitoring Current Run

### Check Progress

```bash
# Watch terminal output for chunk progress
# Look for: "Chunk X/4" messages

# Monitor memory usage
watch -n 1 free -h

# Check output files being created
ls -lh /mnt/c/Users/Simon/ign/test_full_enrich_output/
```

### Expected Log Output

```
Processing 17,231,344 points in 4 chunks of ~5,000,000 points each
Building KDTree for 17,231,344 points...          # ~30-45s
  Chunk 1/4 (0-5,000,000)...                      # ~90-120s
  Chunk 2/4 (5,000,000-10,000,000)...             # ~90-120s
  Chunk 3/4 (10,000,000-15,000,000)...            # ~90-120s
  Chunk 4/4 (15,000,000-17,231,344)...            # ~60-80s
Fetching RGB from IGN orthophotos...              # ~2-3 min
Fetching infrared from IGN orthophotos...         # ~2-3 min
‚úì Saved to LHD_FXX_0479_6904_PTS_C_LAMB93_IGN69.laz
                                                   # Repeat 2 more times for augmented versions
‚úì Completed LHD_FXX_0479_6904_PTS_C_LAMB93_IGN69.laz
Created 3 total files
```

## Related Documentation

- **`MEMORY_OPTIMIZATION_OOM_FIX.md`** - Details on the OOM fix and chunk sizing
- **`WORKERS_AND_GPU_ANALYSIS.md`** - Comprehensive workers/GPU analysis
- **`ign_lidar/cli.py`** - Implementation code (lines 420-770)
- **`ign_lidar/features.py`** - Chunked processing implementation
- **`ign_lidar/features_gpu.py`** - GPU implementation (not used with chunking)

## Next Steps

1. ‚úÖ **Monitor current run** - Should complete successfully with v1.6.0 fixes
2. üìù **Document results** - Verify 3 output files created
3. üî¨ **Validate output** - Check feature quality with visualization
4. üöÄ **Consider GPU implementation** - For future performance improvements
5. üìä **Benchmark** - Compare processing times with/without augmentation

---

**Investigation Date:** October 4, 2025  
**Version:** v1.6.0  
**Status:** ‚úÖ Fix implemented and deployed
