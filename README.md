<div align="center">

# IGN LiDAR HD Processing Library

[![PyPI version](https://badge.fury.io/py/ign-lidar-hd.svg)](https://badge.fury.io/py/ign-lidar-hd)
[![PyPI - Downloads](https://img.shields.io/pypi/dm/ign-lidar-hd)](https://pypi.org/project/ign-lidar-hd/)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Documentation](https://img.shields.io/badge/docs-online-blue)](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/)

**Version 5.1.0** | [üìö Full Documentation](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/) | [‚öôÔ∏è Configuration Guide](docs/guides/CONFIG_GUIDE.md)

![LoD3 Building Model](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/blob/main/docs/static/img/lod3.png?raw=true)

**Transform IGN LiDAR HD point clouds into ML-ready datasets for building classification**

[Quick Start](#-quick-start) ‚Ä¢ [What's New](#-whats-new-in-v510) ‚Ä¢ [Features](#-key-features) ‚Ä¢ [Documentation](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/) ‚Ä¢ [Examples](#-usage-examples)

</div>

---

## üìä Overview

A comprehensive Python library for processing French IGN LiDAR HD data into machine learning-ready datasets. Features include GPU acceleration, rich geometric features, RGB/NIR augmentation, and flexible YAML-based configuration.

**Key Capabilities:**

- üöÄ **GPU Acceleration**: 16√ó faster processing with optimized batching
- ‚ö° **Optimized Pipeline**: 8√ó overall speedup (80min ‚Üí 10min per large tile)
- üéØ **Smart Ground Truth**: 10√ó faster classification with auto-method selection
- üé® **Multi-modal Data**: Geometry + RGB + Infrared (NDVI-ready)
- üèóÔ∏è **Building Classification**: LOD2/LOD3 schemas with 15-30+ classes
- üì¶ **Flexible Output**: NPZ, HDF5, PyTorch, LAZ formats
- ‚öôÔ∏è **YAML Configuration**: Reproducible workflows with example configs

---

## üöÄ Performance (October 2025 Optimizations)

**Latest Update (Oct 17):** Performance optimization sprint with +30-45% throughput gains!

### Quick Wins Implemented

| Optimization          | Impact      | Status |
| --------------------- | ----------- | ------ |
| Batched GPU transfers | +15-25%     | ‚úÖ     |
| CPU worker scaling    | +2-4√ó (CPU) | ‚úÖ     |
| Reduced cleanup freq  | +3-5%       | ‚úÖ     |
| **Combined Impact**   | **+30-45%** | ‚úÖ     |

**Latest Performance (10M points):**

- Before optimizations: 2.9s
- After quick wins: **2.0-2.2s** (+30-45% faster)
- Projected (all fixes): 1.5-1.8s (+60-90% faster)

üìä See [PERFORMANCE_BOTTLENECK_ANALYSIS.md](PERFORMANCE_BOTTLENECK_ANALYSIS.md) for detailed analysis

### Week 1 Refactoring Complete

**Week 1 Refactoring Complete!** All performance targets met or exceeded:

| Metric                | Before | After  | Speedup |
| --------------------- | ------ | ------ | ------- |
| GPU chunk processing  | 353s   | 22s    | **16√ó** |
| Ground truth labeling | 20min  | ~2min  | **10√ó** |
| Overall pipeline      | 80min  | ~10min | **8√ó**  |

**Key Optimizations:**

- ‚úÖ GPU neighbor lookup batch size tuned (500K ‚Üí 250K points)
- ‚úÖ `GroundTruthOptimizer` with auto-method selection (GPU/CPU)
- ‚úÖ Reclassification enabled with geometric refinement
- ‚úÖ Optimized batch size (8M ‚Üí 1M points) for responsiveness

**Annual Impact:** Saves ~1,140 hours for 100 jobs/year üéØ

üìñ See [WEEK_1_IMPLEMENTATION_COMPLETE.md](WEEK_1_IMPLEMENTATION_COMPLETE.md) for details

---

## ‚ú® What's New in v5.1.0

### ü§ñ **UnifiedFeatureComputer with Automatic Mode Selection (Phase 4)**

**NEW (October 2025):** Intelligent automatic computation mode selection!

- **Automatic GPU/CPU selection** - No manual configuration needed
- **Simplified config** - One flag instead of multiple GPU settings
- **Expert recommendations** - System logs optimal configuration
- **Backward compatible** - Existing configs work unchanged
- **Opt-in design** - Enable with `use_unified_computer: true`

#### Before vs After

```yaml
# Before: Manual GPU configuration
processor:
  use_gpu: true
  use_gpu_chunked: true
  gpu_batch_size: 5000000

# After: Automatic mode selection
processor:
  use_unified_computer: true  # That's it!
```

**Benefits:**

- ‚ö° **Automatic** - Selects CPU/GPU/GPU_CHUNKED based on workload
- üéØ **Smart** - Considers tile size, GPU availability, memory
- üìä **Transparent** - Logs mode selection decisions
- üîß **Flexible** - Can force specific mode if needed

See [Migration Guide](docs/guides/migration-unified-computer.md) for details.

---

### üéØ **Preset-Based Configuration System (Week 3)**

**v5.1.0 introduces a revolutionary preset-based configuration system!**

- **71% fewer lines** in config files (914 ‚Üí 261 lines across examples)
- **5 clear presets** for common use cases (minimal, lod2, lod3, asprs, full)
- **Single source of truth** (`base.yaml` with smart defaults)
- **Simple inheritance** chain: base ‚Üí preset ‚Üí custom ‚Üí CLI
- **Zero duplication** - specify only what's different

#### Quick Start with Presets

```bash
# List available presets
ign-lidar-hd presets

# Use a preset directly
ign-lidar-hd process --preset lod2 input/ output/

# Create custom config using preset
cat > my_config.yaml << EOF
preset: lod2
input_dir: /data/tiles
output_dir: /data/output
EOF

ign-lidar-hd process --config my_config.yaml
```

#### Available Presets

| Preset         | Use Case                   | Speed       | Classes             |
| -------------- | -------------------------- | ----------- | ------------------- |
| üöÄ **minimal** | Quick preview, testing     | ‚ö° Fastest  | ASPRS (standard)    |
| üèÉ **lod2**    | Building modeling, facades | üöÄ Fast     | 15 building classes |
| üèóÔ∏è **lod3**    | Detailed architecture      | üèÉ Moderate | 30 detailed classes |
| üìê **asprs**   | Standard classification    | üöÄ Fast     | ASPRS LAS 1.4       |
| üî¨ **full**    | ML training, research      | üê¢ Slow     | LOD3 + all features |

#### Configuration Comparison

**Before v5.1** (188 lines):

```yaml
defaults:
  - ../ign_lidar/configs/config
  - _self_

input_dir: /data/tiles
output_dir: /data/output

processor:
  lod_level: LOD2
  architecture: hybrid
  use_gpu: true
  num_workers: 4
  patch_size: 150.0
  patch_overlap: 0.1
  # ... 170 more lines
```

**After v5.1** (43 lines):

```yaml
preset: lod2

input_dir: /data/tiles
output_dir: /data/output
# Everything else inherited from lod2 preset!
```

**Reduction**: 188 ‚Üí 43 lines (**-77%** ‚ú®)

#### Benefits

‚úÖ **Simpler**: Only specify what's different  
‚úÖ **Clearer**: Presets document best practices  
‚úÖ **Maintainable**: Update presets once, all configs benefit  
‚úÖ **Discoverable**: `ign-lidar-hd presets` shows all options  
‚úÖ **Flexible**: Easy to experiment and switch presets

üìñ See [Configuration Guide](docs/guides/CONFIG_GUIDE.md) for complete documentation

---

## ‚ú® What's New in v3.0.0

### üéØ **Unified Configuration System**

**v3.0.0 introduces a completely redesigned configuration architecture!**

- **Unified Schema**: Single, coherent configuration system replacing fragmented v2.x/v3.0 configs
- **GPU Optimized**: Default configurations deliver >80% GPU utilization (vs 17% in legacy)
- **Smart Presets**: Ready-to-use configs for common scenarios
- **Hardware Profiles**: Optimized settings for RTX 4080, RTX 3080, CPU fallback
- **Migration Tools**: Automatic conversion from legacy configurations

```bash
# New simplified usage with presets
./scripts/run_processing.sh --preset gpu_optimized --input /data/tiles

# Hardware-specific optimization
./scripts/run_processing.sh --preset asprs_classification --hardware rtx4080

# Migration from legacy configs
python scripts/migrate_config_v4.py --input old_config.yaml --output new_config.yaml
```

**Performance Improvements:**

- ‚ö° **10-100√ó faster** ground truth processing with forced GPU acceleration
- üéÆ **>80% GPU utilization** (vs 17% with CPU fallback in legacy configs)
- üîß **<10 CLI parameters** needed (vs 50+ in legacy scripts)
- üì¶ **90 config files ‚Üí 6** consolidated presets

### üÜï Optional Reclassification in Main Pipeline

**v2.5.4 adds reclassification as an optional feature in the main processing pipeline!**

You can now enable optimized ground truth reclassification directly in your processing config:

```yaml
processor:
  reclassification:
    enabled: true # Optional - disabled by default
    acceleration_mode: "auto" # CPU, GPU, or GPU+cuML
    use_geometric_rules: true
```

**Benefits:**

- ‚úÖ **Flexible**: Enable/disable without separate runs
- ‚úÖ **Fast**: GPU-accelerated spatial indexing
- ‚úÖ **Accurate**: Ground truth from BD TOPO¬Æ
- ‚úÖ **Backward compatible**: Existing configs work unchanged

üìñ See [`docs/RECLASSIFICATION_INTEGRATION.md`](docs/RECLASSIFICATION_INTEGRATION.md) and [`docs/RECLASSIFICATION_QUICKSTART.md`](docs/RECLASSIFICATION_QUICKSTART.md) for details

---

## ‚ú® What's New in v2.5.3

### üîß Critical Fix: Ground Truth Classification

**v2.5.3 fixes critical issues with BD TOPO¬Æ ground truth classification.**

#### What Was Fixed

Ground truth classification from IGN BD TOPO¬Æ wasn't working - no points were being classified to roads, cemeteries, power lines, etc.

**Root Causes:**

- Incorrect class imports (`MultiSourceDataFetcher` ‚Üí `DataFetcher`)
- Missing BD TOPO feature parameters (cemeteries, power_lines, sports)
- Missing buffer parameters (road_width_fallback, etc.)
- Wrong method call (`fetch_data()` ‚Üí `fetch_all()`)

**Impact:** Ground truth now works correctly for all ASPRS codes:

- ‚úÖ ASPRS 11: Roads
- ‚úÖ ASPRS 40: Parking
- ‚úÖ ASPRS 41: Sports Facilities
- ‚úÖ ASPRS 42: Cemeteries
- ‚úÖ ASPRS 43: Power Lines

#### What Was Added

**New BD TOPO¬Æ Configuration Directory** (`ign_lidar/configs/data_sources/`)

Pre-configured Hydra configs for different use cases:

- `default.yaml` - General purpose with core features
- `asprs_full.yaml` - Complete ASPRS classification
- `lod2_buildings.yaml` - Building-focused for LOD2
- `lod3_architecture.yaml` - Architectural focus for LOD3
- `disabled.yaml` - Pure geometric features

**Usage:**

```yaml
defaults:
  - data_sources: asprs_full # or lod2_buildings, lod3_architecture
  - _self_
```

üìñ See `ign_lidar/configs/data_sources/README.md` for complete documentation

---

### üì¶ Previous Updates (v2.5.0-2.5.2)

**v2.5.0 represented a complete internal modernization while maintaining 100% backward compatibility!**

#### Unified Feature System ‚ú®

- **FeatureOrchestrator**: New unified class replaces FeatureManager + FeatureComputer
- **Simpler API**: One class handles all feature computation with automatic strategy selection
- **Better organized**: Clear separation of concerns with strategy pattern
- **Fully compatible**: All existing code works without changes

#### Improved Code Quality

- **67% reduction** in feature orchestration code complexity
- **Optimized error messages** and validation throughout
- **Complete type hints** for better IDE support
- **Modular architecture** for easier maintenance and extension

#### Migration Made Easy

- **Zero breaking changes**: Your v1.x code continues to work
- **Deprecation warnings**: Clear guidance for future-proofing your code
- **Migration guide**: Step-by-step instructions in [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md)
- **Backward compatible**: Legacy APIs will be maintained through v2.x series

```python
# NEW (v2.0) - Recommended unified API
from ign_lidar import LiDARProcessor

processor = LiDARProcessor(
    config_path="config.yaml",
    feature_mode="lod3"  # Clearer mode specification
)

# Access unified orchestrator
orchestrator = processor.feature_orchestrator
print(f"Feature mode: {orchestrator.mode}")
print(f"Has RGB: {orchestrator.has_rgb}")
print(f"Available features: {orchestrator.get_feature_list('lod3')}")

# OLD (v1.x) - Still works with deprecation warnings
# feature_manager = processor.feature_manager  # Deprecated but functional
# feature_computer = processor.feature_computer  # Deprecated but functional
```

**Why upgrade?**

- Future-proof your code for v3.0
- Access to new features and improvements
- Better performance and error handling
- Professional, maintainable codebase

üìñ See [MIGRATION_GUIDE.md](MIGRATION_GUIDE.md) for complete upgrade instructions  
üìñ [Full Release History](CHANGELOG.md)

---

## üöÄ Quick Start

### Installation

```bash
# Standard installation (CPU)
pip install ign-lidar-hd

# Optional: GPU acceleration (6-20x speedup)
./install_cuml.sh  # or follow GPU_SETUP.md
```

### Basic Usage

```bash
# Download sample data
ign-lidar-hd download --bbox 2.3,48.8,2.4,48.9 --output data/ --max-tiles 5

# Enrich with features (GPU accelerated if available)
ign-lidar-hd enrich --input-dir data/ --output enriched/ --use-gpu

# Create training patches
ign-lidar-hd patch --input-dir enriched/ --output patches/ --lod-level LOD2
```

### Python API

```python
from ign_lidar import LiDARProcessor

# Initialize and process
processor = LiDARProcessor(lod_level="LOD2")
patches = processor.process_tile("data.laz", "output/")
```

---

## üìã Key Features

### Core Processing

- **üéØ Complete Feature Export** - All 35-45 computed geometric features saved to disk (v2.4.2+)
- **üèóÔ∏è Multi-level Classification** - LOD2 (12 features), LOD3 (38 features), Full (43+ features) modes
- **üìä Rich Geometry** - Normals, curvature, eigenvalues, shape descriptors, architectural features, building scores
- **üé® Optional Augmentation** - RGB from orthophotos, NIR, NDVI for vegetation analysis
- **‚öôÔ∏è Auto-parameters** - Intelligent tile analysis for optimal settings
- **üìù Feature Tracking** - Metadata includes feature names and counts for reproducibility

### Performance

- **üöÄ GPU Acceleration** - RAPIDS cuML support (6-20x faster)
- **‚ö° Parallel Processing** - Multi-worker with automatic CPU detection
- **üß† Memory Optimized** - Chunked processing, 50-60% reduction
- **üíæ Smart Skip** - Resume interrupted workflows automatically (~1800x faster)

### Flexibility

- **üìÅ Processing Modes** - Three clear modes: patches only, both, or LAZ only
- **üìã YAML Configs** - Declarative workflows with example templates
- **üì¶ Multiple Formats** - NPZ, HDF5, PyTorch, LAZ (single or multi-format)
- **üîß CLI & API** - Command-line tool and Python library

---

## üí° Usage Examples

### Mode 1: Create Training Patches (Default)

```bash
# Using example config
ign-lidar-hd process \
  --config-file examples/config_training_dataset.yaml \
  input_dir=data/raw \
  output_dir=data/patches

# Or with CLI parameters
ign-lidar-hd process \
  input_dir=data/raw \
  output_dir=data/patches \
  processor.processing_mode=patches_only
```

### Mode 2: Both Patches & Enriched LAZ

```bash
ign-lidar-hd process \
  --config-file examples/config_complete.yaml \
  input_dir=data/raw \
  output_dir=data/both
```

### Mode 3: LAZ Enrichment Only

```bash
ign-lidar-hd process \
  --config-file examples/config_quick_enrich.yaml \
  input_dir=data/raw \
  output_dir=data/enriched
```

> **‚ö†Ô∏è Note on Enriched LAZ Files:** When generating enriched LAZ tile files, geometric features (normals, curvature, planarity, etc.) may show artifacts at tile boundaries due to the nature of the source data. These artifacts are inherent to tile-based processing and **do not appear in patch exports**, which provide the best results for machine learning applications. For optimal quality, use `patches_only` or `both` modes.

### GPU-Accelerated Processing

```bash
ign-lidar-hd process \
  --config-file examples/config_gpu_processing.yaml \
  input_dir=data/raw \
  output_dir=data/output
```

### Preview Configuration

```bash
ign-lidar-hd process \
  --config-file examples/config_training_dataset.yaml \
  --show-config \
  input_dir=data/raw
```

### Python API Examples

```python
from ign_lidar import LiDARProcessor, IGNLiDARDownloader

# Download tiles
downloader = IGNLiDARDownloader("downloads/")
tiles = downloader.download_by_bbox(bbox=(2.3, 48.8, 2.4, 48.9), max_tiles=5)

# Process with custom config
processor = LiDARProcessor(
    lod_level="LOD3",
    patch_size=150.0,
    num_points=16384,
    use_gpu=True
)

# Single tile
patches = processor.process_tile("input.laz", "output/")

# Batch processing
patches = processor.process_directory("input_dir/", "output_dir/", num_workers=4)

# PyTorch integration
from torch.utils.data import DataLoader
dataset = LiDARPatchDataset("patches/")
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
```

---

## üéì Feature Modes

IGN LiDAR HD supports multiple feature computation modes optimized for different use cases:

### Minimal Mode (4 features) - Ultra-Fast

**Best for:** Quick processing, classification updates, minimal computation

**Features:** normal_z, planarity, height_above_ground, density

**Performance:** ‚ö°‚ö°‚ö°‚ö°‚ö° Fastest (~5s per 1M points)

### LOD2 Mode (12 features) - Fast Training

**Best for:** Basic building classification, quick prototyping, baseline models

**Features:** XYZ (3), normal_z, planarity, linearity, height, verticality, RGB (3), NDVI

**Performance:** ~15s per 1M points (CPU), fast convergence

### LOD3 Mode (37 features) - Detailed Modeling

**Best for:** Architectural modeling, fine structure detection, research

**Features:** Complete normals (3), eigenvalues (5), curvature (2), shape descriptors (6), height features (2), building scores (3), density features (4), architectural features (4), spectral (5)

**Performance:** ~45s per 1M points (CPU), best accuracy

### Full Mode (37+ features) - Complete Feature Set

**Best for:** Research, feature analysis, maximum information extraction

**All Features:** All LOD3 features plus any additional computed features

**Performance:** ~50s per 1M points (CPU), complete geometric description

**Usage:**

```yaml
features:
  mode: minimal # or lod2, lod3, full, custom
  k_neighbors: 10
```

**Output Format:**

- NPZ/HDF5/PyTorch: Full feature matrix with all features
- LAZ: All features as extra dimensions for GIS tools
- Metadata: `feature_names` and `num_features` for tracking

üìñ See [Feature Modes Documentation](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/features/feature-modes) for complete details.

---

## üì¶ Output Format

### NPZ Structure

Each patch is saved as NPZ with:

```python
{
    'points': np.ndarray,        # [N, 3] XYZ coordinates
    'normals': np.ndarray,       # [N, 3] surface normals
    'curvature': np.ndarray,     # [N] principal curvature
    'intensity': np.ndarray,     # [N] normalized intensity
    'planarity': np.ndarray,     # [N] planarity measure
    'verticality': np.ndarray,   # [N] verticality measure
    'density': np.ndarray,       # [N] local point density
    'labels': np.ndarray,        # [N] building class labels
    # Facultative features:
    'wall_score': np.ndarray,    # [N] wall likelihood (planarity * verticality)
    'roof_score': np.ndarray,    # [N] roof likelihood (planarity * horizontality)
    # Optional with augmentation:
    'red': np.ndarray,           # [N] RGB red
    'green': np.ndarray,         # [N] RGB green
    'blue': np.ndarray,          # [N] RGB blue
    'infrared': np.ndarray,      # [N] NIR values
}
```

### Available Formats

- **NPZ** - Default NumPy format (recommended for ML)
- **HDF5** - Hierarchical data format
- **PyTorch** - `.pt` files for PyTorch
- **LAZ** - Point cloud format for visualization (may show boundary artifacts in tile mode)
- **Multi-format** - Save in multiple formats: `hdf5,laz`, `npz,torch`

> **üí° Tip:** For machine learning applications, NPZ/HDF5/PyTorch patch formats provide cleaner geometric features than enriched LAZ tiles.

---

## üìö Documentation

### Quick Links

- **[üìñ Complete Documentation Index](DOCUMENTATION.md)** - Full documentation navigation
- [üìñ Full Documentation](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/) - Online documentation site
- [üöÄ Installation Guide](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/installation/quick-start)
- [üìã Testing Guide](TESTING.md) - Test suite and development testing
- [üìù Changelog](CHANGELOG.md) - Version history and release notes

### User Guides

Located in **[docs/guides/](docs/guides/)**:

- [ASPRS Classification Guide](docs/guides/ASPRS_CLASSIFICATION_GUIDE.md) - Complete ASPRS standards
- [Building Classification Guide](docs/guides/BUILDING_CLASSIFICATION_QUICK_REFERENCE.md) - Building class reference
- [Vegetation Classification Guide](docs/guides/VEGETATION_CLASSIFICATION_GUIDE.md) - Vegetation analysis

### Examples & Configuration

Located in **[examples/](examples/)**:

- [Example Configurations](examples/) - YAML configuration templates
- [Versailles Configs](examples/) - LOD2, LOD3, and ASPRS examples
- [Architectural Analysis](examples/ARCHITECTURAL_STYLES_README.md) - Style detection
- [Multi-scale Training](examples/MULTI_SCALE_TRAINING_STRATEGY.md) - Advanced training

### Architecture & API

- [System Architecture](docs/architecture/) - Design documentation
- [Geometric Features Reference](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/features/geometric-features)
- [Feature Modes Guide](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/features/feature-modes)
- [CLI Reference](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/api/cli)
- [Python API](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/api/features)
- [Configuration Schema](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/api/configuration)

---

## üõ†Ô∏è Development

```bash
# Clone and install in development mode
git clone https://github.com/sducournau/IGN_LIDAR_HD_DATASET
cd IGN_LIDAR_HD_DATASET
pip install -e ".[dev]"

# Run tests
pytest tests/

# Format code
black ign_lidar/
```

---

## üìã Requirements

**Core:**

- Python 3.8+
- NumPy >= 1.21.0
- laspy >= 2.3.0
- scikit-learn >= 1.0.0

**Optional GPU Acceleration:**

- CUDA >= 12.0
- CuPy >= 12.0.0
- RAPIDS cuML >= 24.10 (recommended)

---

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details.

---

## ü§ù Support & Contributing

- üêõ [Report Issues](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/issues)
- üí° [Feature Requests](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/issues)
- üìñ [Contributing Guide](CONTRIBUTING.md)

---

## üìù Cite Me

If you use this library in your research or projects, please cite:

```bibtex
@software{ign_lidar_hd,
  author       = {Ducournau, Simon},
  title        = {IGN LiDAR HD Processing Library},
  year         = {2025},
  publisher    = {GitHub},
  url          = {https://github.com/sducournau/IGN_LIDAR_HD_DATASET},
  version      = {3.0.0}
}
```

**Project maintained by:** [ImagoData](https://github.com/sducournau)

---

<div align="center">

**Made with ‚ù§Ô∏è for the LiDAR and Machine Learning communities**

[‚¨Ü Back to top](#ign-lidar-hd-processing-library)

</div>
