# R√©sum√© du Plan d'Entra√Ænement LOD2 - Configuration Actuelle

**Date:** 15 Octobre 2025  
**Projet:** Classification LOD2 Auto-Supervis√©e  
**Architecture:** Hybrid PointNet++ + Point Transformer

---

## üìã Ce Qui A √ât√© Cr√©√©

### 1. Configuration d'Exp√©rience

**Fichier:** `ign_lidar/configs/experiment/lod2_selfsupervised.yaml`

Configuration optimis√©e pour :

- Patches 50m (24,576 points)
- Splits train/val/test : 70/15/15
- Architecture hybride
- Augmentation 5√ó
- Features compl√®tes (RGB, NIR, g√©om√©triques)

### 2. Script d'Entra√Ænement

**Fichier:** `scripts/train_lod2_selfsupervised.py`

Impl√©mente :

- **Phase 1** : Pr√©-entra√Ænement auto-supervis√© (150 epochs)
  - Masked Point Modeling
  - Rotation Prediction
  - Contrastive Learning
- **Phase 2** : Fine-tuning supervis√© (50 epochs)
  - Classification 6 classes LOD2
  - Weighted Cross-Entropy

### 3. Documentation Compl√®te

#### Plan D√©taill√©

**Fichier:** `docs/TRAINING_PLAN_LOD2_SELF_SUPERVISED.md`

- Architecture compl√®te
- Strat√©gie auto-supervis√©e
- Estimation des ressources
- Planning 4 semaines

#### Guide Rapide

**Fichier:** `docs/LOD2_TRAINING_QUICK_START.md`

- Commandes TL;DR
- Configuration rapide
- D√©pannage

---

## üéØ Votre Configuration Actuelle

### Analyse de Votre Setup

D'apr√®s vos configurations existantes (`config_lod3_training_*.yaml`), vous avez :

```yaml
Configuration actuelle d√©tect√©e:
  - LOD Level: LOD3 (peut √™tre adapt√© √† LOD2)
  - Architecture: hybrid ‚úÖ
  - Patch sizes: 50m, 100m, 150m ‚úÖ
  - GPU: Activ√© ‚úÖ
  - Features: Full (RGB, NIR, g√©om√©triques) ‚úÖ
  - Augmentation: 3-5√ó ‚úÖ
```

### Adaptations Recommand√©es pour LOD2

```yaml
# Changements pour LOD2:
processor:
  lod_level: LOD2 # ‚Üê Chang√© de LOD3 √† LOD2
  patch_size: 50.0 # ‚úÖ Optimal pour b√¢timents individuels
  num_points: 24576 # ‚úÖ D√©j√† bon
  num_augmentations: 5 # ‚úÖ D√©j√† optimal

features:
  k_neighbors: 20 # ‚úÖ Bon pour d√©tails fins
  compute_curvature: true # ‚Üê Ajouter pour LOD2
  compute_eigenfeatures: true # ‚Üê Ajouter pour complexit√© toit
```

---

## üöÄ Plan d'Action Imm√©diat

### Option A : Test Rapide (Recommand√© pour d√©marrer)

```bash
# 1. Tester sur 5 tuiles (2h de g√©n√©ration)
ign-lidar-hd process \
  experiment=lod2_selfsupervised \
  input_dir=/path/to/5_test_tiles \
  output_dir=data/lod2_test \
  processor.num_workers=4

# 2. Pr√©-entra√Ænement court (30 epochs, ~15min)
python scripts/train_lod2_selfsupervised.py \
  --mode pretrain \
  --data_dir data/lod2_test/train \
  --output_dir models/lod2_test \
  --epochs 30 \
  --batch_size 32 \
  --gpu 0

# 3. V√©rifier que tout fonctionne
ls -lh models/lod2_test/
```

**R√©sultat attendu :**

- Dataset : ~5,000 patches (5 tuiles √ó 540 patches/tuile √ó 6 avec aug)
- Temps total : ~2.5 heures
- Permet de valider le pipeline complet

### Option B : Production Compl√®te

```bash
# 1. G√©n√©ration dataset complet (50 tuiles, 12h)
ign-lidar-hd process \
  experiment=lod2_selfsupervised \
  input_dir=/path/to/ign_tiles_50 \
  output_dir=data/lod2_production

# 2. Pr√©-entra√Ænement (150 epochs, 1.25h)
python scripts/train_lod2_selfsupervised.py \
  --mode pretrain \
  --data_dir data/lod2_production/train \
  --output_dir models/lod2_pretrained \
  --epochs 150 \
  --batch_size 32 \
  --gpu 0 \
  --use_wandb \
  --project_name lod2-production

# 3. Fine-tuning (50 epochs, 4min)
python scripts/train_lod2_selfsupervised.py \
  --mode finetune \
  --pretrained_model models/lod2_pretrained/best_model.pth \
  --data_dir data/lod2_production/train \
  --val_dir data/lod2_production/val \
  --output_dir models/lod2_finetuned \
  --epochs 50 \
  --batch_size 16 \
  --gpu 0 \
  --use_wandb
```

**R√©sultat attendu :**

- Dataset : ~100,000 patches
- Temps total : ~14 heures
- Mod√®le production-ready

---

## üìä Nombre de Tuiles Recommand√©

### Calcul pour Votre Cas

```python
# Param√®tres
patch_size = 50  # m√®tres
tile_size = 1000  # m√®tres (1km√ó1km)
overlap = 0.15
augmentation = 5

# Calcul patches par tuile
patches_per_tile_base = (1000 / 50) ** 2  # 400
patches_with_overlap = patches_per_tile_base * 1.35  # ~540
patches_with_aug = patches_with_overlap * (1 + augmentation)  # ~3,240

# Pour dataset complet
target_patches = 100000
tiles_needed = target_patches / patches_with_aug
# ‚âà 31 tuiles minimum

print(f"Tuiles n√©cessaires : {tiles_needed:.0f}")
print(f"Recommand√© : 50-100 tuiles")
```

### Recommandations par Objectif

| Objectif                | Tuiles | Patches | Temps | Use Case          |
| ----------------------- | ------ | ------- | ----- | ----------------- |
| **Test Pipeline**       | 5      | ~16K    | 2.5h  | Validation rapide |
| **Proof of Concept**    | 15-20  | ~50K    | 6h    | D√©mo faisabilit√©  |
| **Production Minimum**  | 30-50  | ~100K   | 14h   | Mod√®le utilisable |
| **Production Optimale** | 80-100 | ~300K   | 36h   | Haute performance |
| **Recherche**           | 150+   | ~500K+  | 60h+  | SOTA performance  |

---

## üéì Classes LOD2 et Distribution

### D√©finition des 6 Classes

```python
LOD2_CLASSES = {
    0: {
        'name': 'LOD2.0',
        'description': 'Blocs simples (pav√©s)',
        'features': [
            'Aucun toit d√©tectable',
            'Forme rectangulaire simple',
            'Faible variance des normales'
        ],
        'distribution': '15-20%'
    },
    1: {
        'name': 'LOD2.1',
        'description': 'Toits simples (1-2 pans)',
        'features': [
            '1-2 plans de toit',
            'Ar√™te fa√Æti√®re claire',
            'G√©om√©trie simple'
        ],
        'distribution': '40-45%'  # Classe majoritaire
    },
    2: {
        'name': 'LOD2.2',
        'description': 'Toits complexes (3-4 pans)',
        'features': [
            '3-4 plans de toit',
            'Ar√™tes multiples',
            'G√©om√©trie mod√©r√©e'
        ],
        'distribution': '25-30%'
    },
    3: {
        'name': 'LOD2.3',
        'description': 'Toits tr√®s complexes (5+ pans)',
        'features': [
            '5+ plans de toit',
            'Intersections complexes',
            'Haute variance g√©om√©trique'
        ],
        'distribution': '8-10%'
    },
    4: {
        'name': 'LOD2.4',
        'description': 'Structures sp√©ciales (d√¥mes, courbes)',
        'features': [
            'Surfaces courbes',
            'D√¥mes, vo√ªtes',
            'Haute courbure'
        ],
        'distribution': '2-3%'  # Classe rare
    },
    5: {
        'name': 'LOD2.5',
        'description': 'Structures industrielles complexes',
        'features': [
            'G√©om√©trie irr√©guli√®re',
            'Structures m√©talliques',
            'Multi-niveaux'
        ],
        'distribution': '1-2%'  # Classe tr√®s rare
    }
}
```

### Gestion du D√©s√©quilibre de Classes

Le script d'entra√Ænement inclut d√©j√† :

```python
# Poids pour cross-entropy
class_weights = torch.tensor([
    1.0,  # LOD2.0 (commun)
    1.0,  # LOD2.1 (tr√®s commun - classe majoritaire)
    1.2,  # LOD2.2 (moins commun)
    1.5,  # LOD2.3 (rare)
    2.0,  # LOD2.4 (tr√®s rare)
    2.5   # LOD2.5 (extr√™mement rare)
])
```

---

## üíæ Ressources GPU Requises

### Configuration Minimale

```yaml
GPU: NVIDIA RTX 3060 (12GB)
Adjustments:
  batch_size: 16
  num_points: 16384
  num_workers: 2
Temps: +50% par rapport √† RTX 3090
```

### Configuration Recommand√©e

```yaml
GPU: NVIDIA RTX 3090 (24GB) ou A100 (40GB)
Settings:
  batch_size: 32
  num_points: 24576
  num_workers: 4
Temps: Baseline (comme document√©)
```

### Configuration Optimale

```yaml
GPU: 2√ó NVIDIA A100 (80GB)
Settings:
  batch_size: 64
  num_points: 32768
  num_workers: 8
  distributed: true
Temps: -60% par rapport √† RTX 3090
```

---

## üìà M√©triques de Succ√®s Attendues

### Phase 1 : Pr√©-entra√Ænement (apr√®s 150 epochs)

```yaml
Masked Point Reconstruction:
  chamfer_distance: < 0.05m
  earth_mover_distance: < 0.08m

Rotation Prediction:
  accuracy: > 90%
  confidence: High on all 4 rotations

Contrastive Learning:
  contrastive_accuracy: > 80%
  embedding_quality: Good separation in t-SNE
```

### Phase 2 : Fine-tuning (apr√®s 50 epochs)

```yaml
Global Metrics:
  overall_accuracy: > 75%
  macro_f1_score: > 70%
  weighted_f1_score: > 75%

Per-Class Performance:
  LOD2.0: {precision: >0.80, recall: >0.75}
  LOD2.1: {precision: >0.75, recall: >0.80}  # Classe majoritaire
  LOD2.2: {precision: >0.70, recall: >0.70}
  LOD2.3: {precision: >0.65, recall: >0.60}
  LOD2.4: {precision: >0.60, recall: >0.50}  # Classe rare
  LOD2.5: {precision: >0.55, recall: >0.45}  # Classe tr√®s rare
```

---

## üîç Checklist Avant de D√©marrer

### Pr√©requis Syst√®me

- [ ] GPU NVIDIA avec CUDA 11.0+ install√©
- [ ] Python 3.8+ avec PyTorch 1.12+
- [ ] Espace disque : 250 GB disponible
- [ ] RAM : 32 GB minimum
- [ ] Package IGN LiDAR HD install√© : `pip install -e .`

### Pr√©requis Donn√©es

- [ ] Acc√®s aux tuiles IGN LiDAR HD
- [ ] Tuiles t√©l√©charg√©es localement (ou acc√®s API)
- [ ] V√©rification qualit√© : densit√© > 10 points/m¬≤
- [ ] Distribution g√©ographique : urban + suburban + rural

### Pr√©requis Logiciels

```bash
# V√©rifier les d√©pendances
pip install torch torchvision torchaudio  # PyTorch
pip install numpy scipy scikit-learn      # ML utilities
pip install tqdm wandb                    # Training utilities
pip install laspy pdal                    # Point cloud processing
```

---

## üö¶ Prochaines √âtapes

### Aujourd'hui

1. **V√©rifier** que tous les fichiers sont cr√©√©s :

   ```bash
   ls -l ign_lidar/configs/experiment/lod2_selfsupervised.yaml
   ls -l scripts/train_lod2_selfsupervised.py
   ls -l docs/TRAINING_PLAN_LOD2_SELF_SUPERVISED.md
   ls -l docs/LOD2_TRAINING_QUICK_START.md
   ```

2. **Installer** les d√©pendances manquantes :

   ```bash
   pip install -e .
   pip install torch wandb tqdm
   ```

3. **Tester** sur 1 tuile :
   ```bash
   # Test unitaire
   ign-lidar-hd process \
     experiment=lod2_selfsupervised \
     input_dir=/path/to/single_tile \
     output_dir=data/test_single
   ```

### Cette Semaine

1. **Lancer** test sur 5 tuiles (Option A)
2. **Valider** que le pipeline fonctionne
3. **Analyser** les r√©sultats du pr√©-entra√Ænement

### Prochaines 2 Semaines

1. **D√©ployer** sur 50 tuiles (Option B)
2. **Entra√Æner** le mod√®le complet
3. **√âvaluer** les performances

### Mois Prochain

1. **Optimiser** hyperparam√®tres
2. **Affiner** avec annotations expertes
3. **D√©ployer** en production

---

## üìû Support et Documentation

### Documentation Cr√©√©e

1. **Plan complet** : `docs/TRAINING_PLAN_LOD2_SELF_SUPERVISED.md`

   - Architecture d√©taill√©e
   - Strat√©gie auto-supervis√©e
   - Timeline 4 semaines

2. **Guide rapide** : `docs/LOD2_TRAINING_QUICK_START.md`

   - TL;DR commandes
   - D√©pannage
   - Configuration GPU

3. **Configuration** : `ign_lidar/configs/experiment/lod2_selfsupervised.yaml`

   - Pr√™t √† l'emploi
   - Param√®tres optimis√©s

4. **Script entra√Ænement** : `scripts/train_lod2_selfsupervised.py`
   - Pr√©-entra√Ænement auto-supervis√©
   - Fine-tuning supervis√©
   - Checkpointing automatique

### Ressources Existantes

- Dataset ML : `docs/ML_DATASET_CREATION.md`
- Multi-√©chelle : `examples/MULTI_SCALE_TRAINING_STRATEGY.md`
- Configuration : `examples/README.md`

---

## üéâ R√©sum√©

Vous avez maintenant :

- ‚úÖ Configuration compl√®te pour LOD2 auto-supervis√©
- ‚úÖ Script d'entra√Ænement hybride PointNet++ + Transformer
- ‚úÖ Documentation d√©taill√©e (plan + guide rapide)
- ‚úÖ Estimation pr√©cise des ressources (32-50 tuiles, ~14h)
- ‚úÖ Plan d'action √©tape par √©tape

**Pr√™t √† commencer !** üöÄ

Lancez le test rapide (Option A) pour valider le pipeline :

```bash
ign-lidar-hd process \
  experiment=lod2_selfsupervised \
  input_dir=/path/to/5_test_tiles \
  output_dir=data/lod2_test
```

Bonne chance avec votre entra√Ænement ! üí™
