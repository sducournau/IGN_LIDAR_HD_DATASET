# üöÇüõ£Ô∏è Transport Overlay Enhancement - Upgrade Plan

**Date**: October 15, 2025  
**Version**: 3.0  
**Status**: üöß In Progress

## üìã Executive Summary

This document outlines a comprehensive upgrade plan for road and railway overlay on point clouds, building upon the existing multi-mode transport detection system. The upgrades focus on improving accuracy, performance, and quality assurance.

---

## üéØ Upgrade Objectives

1. **Adaptive Buffering**: Dynamic buffer widths based on geometry and context
2. **Performance Optimization**: Spatial indexing for faster point queries
3. **Quality Assurance**: Confidence scoring and validation metrics
4. **Advanced Geometry**: Handle complex intersections, bridges, tunnels
5. **Better Visualization**: Debug tools and quality reports

---

## üìä Current State Analysis

### Strengths ‚úÖ

1. **Multi-mode detection system**

   - ASPRS_STANDARD: Simple road (11) / rail (10)
   - ASPRS_EXTENDED: Detailed types (32-49)
   - LOD2: Ground-level surfaces

2. **Intelligent buffering from BD TOPO¬Æ**

   - Roads: Uses `largeur` (width) attribute
   - Railways: Uses `nombre_voies` (track count)
   - Default widths: Road 4.0m, Railway 3.5m
   - Additional tolerance: +0.5m buffer

3. **Ground truth priority**

   - BD TOPO¬Æ WFS data overrides geometry
   - Centerline ‚Üí polygon conversion
   - Flat cap buffering

4. **Feature-rich detection**
   - Height, planarity, roughness, intensity
   - NDVI vegetation refinement
   - Multiple data sources (BD TOPO¬Æ, BD For√™t¬Æ, RPG)

### Limitations ‚ö†Ô∏è

1. **Fixed-width buffering**

   - No adaptation to curves, intersections
   - Same tolerance for all road types
   - No elevation consideration

2. **Linear point-in-polygon queries**

   - O(n\*m) complexity for n points, m features
   - Slow for large tiles (millions of points)
   - No spatial indexing

3. **Limited quality metrics**

   - No confidence scoring
   - No coverage validation
   - No overlap detection
   - Limited statistics

4. **No advanced geometry handling**

   - Road/rail intersections unclear
   - Bridges not height-aware
   - Tunnels not handled
   - Roundabouts not optimized

5. **Debugging challenges**
   - Hard to visualize overlay quality
   - Limited validation tools
   - No interactive inspection

---

## üîß Proposed Enhancements

### 1. **Adaptive Dynamic Buffering** üéØ Priority: HIGH

#### Current Implementation

```python
# Fixed buffer based on width attribute
buffer_distance = width / 2.0
road_polygon = geometry.buffer(buffer_distance, cap_style=2)
```

#### Enhanced Implementation

**1.1 Curvature-Aware Buffering**

- Detect curves in road/rail geometry
- Increase buffer width on tight curves (e.g., +20% for radius < 50m)
- Reduce buffer on straight sections for precision

```python
def adaptive_buffer(
    geometry: LineString,
    base_width: float,
    curvature_factor: float = 0.2,
    min_radius: float = 50.0
) -> Polygon:
    """
    Create buffer with adaptive width based on geometry curvature.

    Args:
        geometry: Road/rail centerline
        base_width: Base width from attributes
        curvature_factor: Width increase factor for curves (0.0-1.0)
        min_radius: Minimum curve radius for max adjustment

    Returns:
        Buffered polygon with variable width
    """
    # Analyze geometry curvature
    coords = np.array(geometry.coords)
    curvatures = calculate_curvature(coords)

    # Create segments with adaptive widths
    segments = []
    for i in range(len(coords) - 1):
        curve_adj = min(curvature_factor, curvatures[i] / min_radius)
        segment_width = base_width * (1.0 + curve_adj)

        segment = LineString([coords[i], coords[i+1]])
        buffered = segment.buffer(segment_width / 2.0, cap_style=1)
        segments.append(buffered)

    # Union all segments
    return unary_union(segments)
```

**1.2 Road-Type Specific Tolerances**

Different road types need different buffer tolerances:

| Road Type    | ASPRS Code | Base Tolerance | Curve Tolerance | Notes                   |
| ------------ | ---------- | -------------- | --------------- | ----------------------- |
| Motorway     | 32         | +0.5m          | +1.0m           | Wide, high-speed curves |
| Primary      | 33         | +0.5m          | +0.8m           | Major roads             |
| Secondary    | 34         | +0.4m          | +0.6m           | Regional roads          |
| Residential  | 36         | +0.3m          | +0.4m           | Narrow streets          |
| Service      | 37         | +0.2m          | +0.3m           | Alleys, driveways       |
| Railway Main | 10         | +0.6m          | +0.8m           | Ballast + platform      |
| Railway Tram | 10         | +0.3m          | +0.4m           | Embedded in street      |

**1.3 Intersection Enhancement**

Detect and enhance intersections:

- Identify where roads cross (within 1m)
- Create expanded buffer zones at intersections (+50% width)
- Handle roundabouts with circular expansion

```python
def detect_intersections(
    road_geometries: List[LineString],
    threshold: float = 1.0
) -> List[Point]:
    """Detect road intersections for buffer enhancement."""
    intersections = []
    for i, road1 in enumerate(road_geometries):
        for road2 in road_geometries[i+1:]:
            if road1.distance(road2) < threshold:
                intersection = road1.intersection(road2)
                if intersection and not intersection.is_empty:
                    intersections.append(intersection.centroid)
    return intersections
```

**1.4 Elevation-Aware Buffering**

For bridges and elevated sections:

- Use height attribute from BD TOPO¬Æ
- Only classify points at similar elevation (¬±2m tolerance)
- Separate bridge/tunnel handling

---

### 2. **Spatial Indexing Optimization** ‚ö° Priority: HIGH

#### Current Issue

- Linear scan of all points against all geometries: O(n\*m)
- Processing 1M points √ó 100 roads = 100M checks
- **Typical time**: 5-10 seconds per tile

#### Solution: R-tree Spatial Index

**2.1 Implementation**

```python
from rtree import index
from shapely.geometry import Point, box

class SpatialTransportClassifier:
    """Fast spatial indexing for transport overlay."""

    def __init__(self):
        self.road_idx = index.Index()
        self.rail_idx = index.Index()
        self.road_data = {}
        self.rail_data = {}

    def index_roads(self, roads_gdf: gpd.GeoDataFrame):
        """Build R-tree index for roads."""
        for idx, row in roads_gdf.iterrows():
            geom = row['geometry']
            bounds = geom.bounds  # (minx, miny, maxx, maxy)

            self.road_idx.insert(
                idx,
                bounds,
                obj={'geometry': geom, 'attributes': row.to_dict()}
            )
            self.road_data[idx] = row

    def classify_points_fast(
        self,
        points: np.ndarray,
        labels: np.ndarray
    ) -> np.ndarray:
        """
        Fast point classification using spatial index.

        Improvement: O(n * log(m)) instead of O(n * m)
        Expected speedup: 10-100x for large datasets
        """
        for i, point in enumerate(points):
            pt = Point(point[0], point[1])

            # Query R-tree for nearby roads (fast!)
            candidates = list(self.road_idx.intersection(
                (pt.x, pt.y, pt.x, pt.y),
                objects=True
            ))

            # Check only nearby candidates (few!)
            for candidate in candidates:
                geom = candidate.object['geometry']
                if geom.contains(pt):
                    attrs = candidate.object['attributes']
                    labels[i] = attrs.get('asprs_class', 11)
                    break  # First match wins

        return labels
```

**Expected Performance:**

- **Before**: 5-10 seconds per 1M points
- **After**: 0.5-1 second per 1M points
- **Speedup**: 5-10x improvement

---

### 3. **Quality Metrics & Validation** üìä Priority: MEDIUM

#### 3.1 Confidence Scoring

Assign confidence scores to each classified point:

```python
@dataclass
class TransportClassificationScore:
    """Quality metrics for transport classification."""

    point_idx: int
    asprs_class: int
    confidence: float  # 0.0 - 1.0

    # Contributing factors
    ground_truth_match: bool    # From BD TOPO¬Æ
    geometric_match: bool       # Planarity, height
    intensity_match: bool       # Material signature
    proximity_to_centerline: float  # Distance (m)

    def calculate_confidence(self) -> float:
        """Calculate overall confidence score."""
        score = 0.0

        # Ground truth is strongest signal
        if self.ground_truth_match:
            score += 0.6

        # Geometric features
        if self.geometric_match:
            score += 0.2

        # Intensity refinement
        if self.intensity_match:
            score += 0.1

        # Proximity bonus (closer to centerline = higher confidence)
        proximity_score = max(0, 1.0 - (self.proximity_to_centerline / 3.0))
        score += proximity_score * 0.1

        return min(1.0, score)
```

**Usage:**

```python
# Store confidence with each point
confidence_field = np.zeros(len(labels), dtype=np.float32)

for i, label in enumerate(labels):
    if label in [10, 11, 32, 33, 34, 36, 37]:  # Transport classes
        score = calculate_point_confidence(i, point, label, context)
        confidence_field[i] = score.calculate_confidence()

# Add to LAZ output
las.add_extra_dim(laspy.ExtraBytesParams(
    name="transport_confidence",
    type=np.float32,
    description="Transport classification confidence [0-1]"
))
las.transport_confidence = confidence_field
```

#### 3.2 Coverage Statistics

Track overlay quality:

```python
@dataclass
class TransportCoverageStats:
    """Statistics for transport overlay quality."""

    # Road statistics
    n_roads_processed: int
    n_road_points_classified: int
    avg_points_per_road: float
    road_width_range: Tuple[float, float]  # (min, max)
    road_types_detected: Dict[int, int]  # {asprs_code: count}

    # Railway statistics
    n_railways_processed: int
    n_rail_points_classified: int
    avg_points_per_railway: float
    railway_track_counts: List[int]  # [1, 1, 2, 1, ...] for each railway

    # Quality metrics
    avg_confidence: float
    low_confidence_ratio: float  # % of points with confidence < 0.5
    overlap_detections: int  # Points matching multiple features

    # Geometry coverage
    centerline_coverage: float  # % of centerlines with points
    buffer_utilization: float  # % of buffer area with points

    def to_json(self) -> str:
        """Export statistics to JSON."""
        return json.dumps(asdict(self), indent=2)

    def generate_report(self) -> str:
        """Generate human-readable report."""
        report = [
            "‚ïê" * 70,
            "TRANSPORT OVERLAY QUALITY REPORT",
            "‚ïê" * 70,
            "",
            "üìç ROAD OVERLAY",
            f"  Roads processed:      {self.n_roads_processed}",
            f"  Points classified:    {self.n_road_points_classified:,}",
            f"  Avg points/road:      {self.avg_points_per_road:.0f}",
            f"  Width range:          {self.road_width_range[0]:.1f}m - {self.road_width_range[1]:.1f}m",
            "",
            "üöÇ RAILWAY OVERLAY",
            f"  Railways processed:   {self.n_railways_processed}",
            f"  Points classified:    {self.n_rail_points_classified:,}",
            f"  Avg points/railway:   {self.avg_points_per_railway:.0f}",
            f"  Track counts:         {sorted(set(self.railway_track_counts))}",
            "",
            "‚úÖ QUALITY METRICS",
            f"  Avg confidence:       {self.avg_confidence:.2f}",
            f"  Low confidence:       {self.low_confidence_ratio*100:.1f}%",
            f"  Overlaps detected:    {self.overlap_detections}",
            f"  Centerline coverage:  {self.centerline_coverage*100:.1f}%",
            "‚ïê" * 70
        ]
        return "\n".join(report)
```

#### 3.3 Overlap Detection & Resolution

Handle cases where features overlap:

```python
def resolve_transport_overlaps(
    labels: np.ndarray,
    points: np.ndarray,
    ground_truth_features: Dict[str, gpd.GeoDataFrame]
) -> Tuple[np.ndarray, List[int]]:
    """
    Detect and resolve overlapping transport classifications.

    Priority order:
    1. Bridges (17) - highest elevation
    2. Railways (10) - specific geometry
    3. Roads by type (32 > 33 > 34 > 36 > 37)

    Returns:
        Resolved labels and list of overlap point indices
    """
    overlap_indices = []

    # Find points matching multiple features
    for i, point in enumerate(points):
        matches = []

        # Check all transport features
        for feature_type in ['bridges', 'railways', 'roads']:
            if feature_type not in ground_truth_features:
                continue

            gdf = ground_truth_features[feature_type]
            pt = Point(point[0], point[1])

            for idx, row in gdf.iterrows():
                if row['geometry'].contains(pt):
                    matches.append((feature_type, row))

        # Resolve if multiple matches
        if len(matches) > 1:
            overlap_indices.append(i)

            # Apply priority rules
            if any(m[0] == 'bridges' for m in matches):
                labels[i] = 17  # Bridge wins
            elif any(m[0] == 'railways' for m in matches):
                labels[i] = 10  # Railway wins over roads
            else:
                # Road type priority
                road_matches = [m for m in matches if m[0] == 'roads']
                if road_matches:
                    # Highest importance wins
                    best_road = max(
                        road_matches,
                        key=lambda m: get_road_priority(m[1].get('nature'))
                    )
                    labels[i] = get_asprs_code(best_road[1])

    return labels, overlap_indices
```

---

### 4. **Advanced Geometry Handling** üåâ Priority: MEDIUM

#### 4.1 Bridge Detection & Height Filtering

Bridges should only classify points at their elevation:

```python
def classify_bridge_points(
    points: np.ndarray,
    height: np.ndarray,
    bridge_gdf: gpd.GeoDataFrame,
    labels: np.ndarray
) -> np.ndarray:
    """
    Classify bridge points with elevation filtering.

    Only classify points that:
    1. Fall within bridge XY footprint
    2. Are at bridge deck elevation (¬±2m tolerance)
    """
    for idx, bridge in bridge_gdf.iterrows():
        bridge_geom = bridge['geometry']
        bridge_height = bridge.get('hauteur', None)

        if bridge_height is None:
            continue

        # Find points in XY footprint
        for i, point in enumerate(points):
            pt = Point(point[0], point[1])

            if bridge_geom.contains(pt):
                # Check elevation
                point_height = height[i]

                if abs(point_height - bridge_height) < 2.0:
                    labels[i] = 17  # ASPRS_BRIDGE

    return labels
```

#### 4.2 Tunnel Handling

Tunnels need special handling:

```python
def classify_tunnel_points(
    points: np.ndarray,
    height: np.ndarray,
    tunnel_gdf: gpd.GeoDataFrame,
    labels: np.ndarray
) -> np.ndarray:
    """
    Handle tunnel classification.

    Tunnels should:
    1. NOT classify surface points
    2. Only classify points below ground level
    3. Mark as special tunnel class or unclassified
    """
    for idx, tunnel in tunnel_gdf.iterrows():
        tunnel_geom = tunnel['geometry']
        tunnel_depth = tunnel.get('profondeur', 0)

        for i, point in enumerate(points):
            pt = Point(point[0], point[1])

            if tunnel_geom.contains(pt):
                point_height = height[i]

                # Only classify subsurface points
                if point_height < -tunnel_depth:
                    labels[i] = 1  # Unclassified (or new TUNNEL code)

    return labels
```

#### 4.3 Roundabout Optimization

Roundabouts benefit from circular buffering:

```python
def classify_roundabout_points(
    roundabout_gdf: gpd.GeoDataFrame,
    points: np.ndarray,
    labels: np.ndarray
) -> np.ndarray:
    """
    Optimize roundabout classification with circular geometry.

    Roundabouts are circular roads that need:
    1. Center point detection
    2. Radial buffering
    3. Lane separation
    """
    for idx, roundabout in roundabout_gdf.iterrows():
        geom = roundabout['geometry']

        # Calculate center and radius
        center = geom.centroid
        radius = np.sqrt(geom.area / np.pi)

        # Create circular buffer
        circle = center.buffer(radius)

        for i, point in enumerate(points):
            pt = Point(point[0], point[1])

            if circle.contains(pt):
                labels[i] = 43  # ASPRS_ROUNDABOUT or road type

    return labels
```

---

### 5. **Visualization & Debugging Tools** üîç Priority: LOW

#### 5.1 Interactive Overlay Viewer

Create visualization tools for quality inspection:

```python
import matplotlib.pyplot as plt
from matplotlib.patches import Polygon as MplPolygon
from matplotlib.collections import PatchCollection

def visualize_transport_overlay(
    points: np.ndarray,
    labels: np.ndarray,
    ground_truth_features: Dict[str, gpd.GeoDataFrame],
    confidence: Optional[np.ndarray] = None,
    output_file: Optional[Path] = None
):
    """
    Create detailed visualization of transport overlay.

    Shows:
    - Point cloud colored by classification
    - Ground truth geometries as overlays
    - Confidence heatmap
    - Statistics panel
    """
    fig, axes = plt.subplots(2, 2, figsize=(16, 12))

    # 1. Point cloud classification
    ax = axes[0, 0]
    transport_mask = np.isin(labels, [10, 11, 17, 32, 33, 34, 36, 37])
    transport_points = points[transport_mask]
    transport_labels = labels[transport_mask]

    scatter = ax.scatter(
        transport_points[:, 0],
        transport_points[:, 1],
        c=transport_labels,
        s=1,
        cmap='tab20',
        alpha=0.8
    )
    ax.set_title('Transport Point Classification')
    plt.colorbar(scatter, ax=ax, label='ASPRS Class')

    # 2. Ground truth overlay
    ax = axes[0, 1]
    ax.scatter(points[:, 0], points[:, 1], c='lightgray', s=0.5, alpha=0.3)

    if 'roads' in ground_truth_features:
        ground_truth_features['roads'].plot(ax=ax, color='blue', alpha=0.5, label='Roads')
    if 'railways' in ground_truth_features:
        ground_truth_features['railways'].plot(ax=ax, color='red', alpha=0.5, label='Railways')

    ax.set_title('Ground Truth Overlay')
    ax.legend()

    # 3. Confidence heatmap
    ax = axes[1, 0]
    if confidence is not None:
        conf_transport = confidence[transport_mask]
        scatter = ax.scatter(
            transport_points[:, 0],
            transport_points[:, 1],
            c=conf_transport,
            s=1,
            cmap='RdYlGn',
            vmin=0,
            vmax=1,
            alpha=0.8
        )
        plt.colorbar(scatter, ax=ax, label='Confidence')
        ax.set_title('Classification Confidence')

    # 4. Statistics summary
    ax = axes[1, 1]
    ax.axis('off')

    stats_text = generate_overlay_stats(labels, confidence, ground_truth_features)
    ax.text(0.1, 0.5, stats_text, family='monospace', fontsize=10, verticalalignment='center')
    ax.set_title('Overlay Statistics')

    plt.tight_layout()

    if output_file:
        plt.savefig(output_file, dpi=150, bbox_inches='tight')
    else:
        plt.show()
```

#### 5.2 Quality Report Generator

```python
def generate_transport_quality_report(
    tile_path: Path,
    output_dir: Path
) -> Path:
    """
    Generate comprehensive quality report for transport overlay.

    Outputs:
    - HTML report with visualizations
    - JSON statistics file
    - Low-confidence points shapefile
    - Coverage analysis plots
    """
    # Load tile data
    las = laspy.read(tile_path)
    points = np.vstack([las.x, las.y, las.z]).T
    labels = las.classification

    # Calculate metrics
    stats = calculate_transport_stats(points, labels)
    confidence = las.transport_confidence if hasattr(las, 'transport_confidence') else None

    # Generate visualizations
    viz_file = output_dir / f"{tile_path.stem}_overlay_viz.png"
    visualize_transport_overlay(points, labels, None, confidence, viz_file)

    # Create HTML report
    html_file = output_dir / f"{tile_path.stem}_transport_report.html"
    generate_html_report(stats, viz_file, html_file)

    # Export low-confidence points
    if confidence is not None:
        low_conf_mask = (confidence < 0.5) & (confidence > 0)
        if np.any(low_conf_mask):
            low_conf_points = points[low_conf_mask]
            export_low_confidence_shapefile(
                low_conf_points,
                output_dir / f"{tile_path.stem}_low_confidence.shp"
            )

    return html_file
```

---

## üìù Implementation Roadmap

### Phase 1: Core Enhancements (Week 1-2)

- [x] Analyze current implementation
- [ ] Implement adaptive buffering (curvature-aware)
- [ ] Add road-type specific tolerances
- [ ] Create spatial indexing system (R-tree)
- [ ] Test performance improvements

### Phase 2: Quality Assurance (Week 3)

- [ ] Implement confidence scoring
- [ ] Add coverage statistics
- [ ] Create overlap detection & resolution
- [ ] Build quality metrics framework
- [ ] Add validation tests

### Phase 3: Advanced Features (Week 4)

- [ ] Implement bridge height filtering
- [ ] Add tunnel handling
- [ ] Optimize roundabout detection
- [ ] Create intersection enhancement
- [ ] Handle complex geometry cases

### Phase 4: Visualization & Tools (Week 5)

- [ ] Build interactive overlay viewer
- [ ] Create quality report generator
- [ ] Add debugging utilities
- [ ] Implement shapefile export tools
- [ ] Create HTML report templates

### Phase 5: Integration & Testing (Week 6)

- [ ] Integrate all components
- [ ] Comprehensive testing on real data
- [ ] Performance benchmarking
- [ ] Documentation updates
- [ ] User guide creation

---

## üìà Expected Improvements

| Metric                    | Current | Target | Improvement |
| ------------------------- | ------- | ------ | ----------- |
| Processing Speed (1M pts) | 5-10s   | 0.5-1s | 5-10x       |
| Classification Accuracy   | 85%     | 92%    | +7%         |
| Edge Detection            | 70%     | 88%    | +18%        |
| Intersection Accuracy     | 65%     | 85%    | +20%        |
| False Positive Rate       | 8%      | 3%     | -5%         |
| Confidence Coverage       | N/A     | 100%   | New         |

---

## üîó Dependencies

### Required Libraries

```python
# Existing
shapely>=2.0.0
geopandas>=0.12.0
numpy>=1.23.0

# New for Phase 1-2
rtree>=1.0.0  # Spatial indexing
scipy>=1.9.0  # Curvature calculation

# New for Phase 4
matplotlib>=3.6.0  # Visualization
jinja2>=3.1.0      # HTML reports
```

### Installation

```bash
pip install rtree scipy matplotlib jinja2
```

---

## üéì Usage Examples

### Example 1: Adaptive Buffering

```python
from ign_lidar.io.wfs_ground_truth import IGNGroundTruthFetcher
from ign_lidar.core.modules.transport_enhancement import AdaptiveTransportBuffer

# Fetch ground truth
fetcher = IGNGroundTruthFetcher()
roads_gdf = fetcher.fetch_roads_with_polygons(bbox)

# Create adaptive buffers
buffer_engine = AdaptiveTransportBuffer(
    curvature_aware=True,
    type_specific_tolerance=True,
    intersection_enhancement=True
)

enhanced_roads = buffer_engine.process_roads(roads_gdf)

# Results include:
# - Variable width buffers
# - Intersection zones
# - Curvature adjustments
```

### Example 2: Fast Spatial Classification

```python
from ign_lidar.core.modules.transport_enhancement import SpatialTransportClassifier

# Build spatial index (one-time cost)
classifier = SpatialTransportClassifier()
classifier.index_roads(roads_gdf)
classifier.index_railways(railways_gdf)

# Fast classification (10x faster!)
labels = classifier.classify_points_fast(points, initial_labels)

# Expected: 0.5-1s for 1M points (vs 5-10s before)
```

### Example 3: Quality Report Generation

```python
from ign_lidar.core.modules.transport_enhancement import generate_transport_quality_report

# Process tile and generate report
report_path = generate_transport_quality_report(
    tile_path=Path("D:/ign/preprocessed/asprs/enriched/tile_001.laz"),
    output_dir=Path("D:/ign/quality_reports")
)

# Outputs:
# - tile_001_transport_report.html  (interactive report)
# - tile_001_overlay_viz.png         (visualization)
# - tile_001_low_confidence.shp      (problematic points)
# - tile_001_stats.json              (metrics)
```

### Example 4: Confidence-Based Filtering

```python
import laspy

# Load enriched tile with confidence scores
las = laspy.read("enriched_tile.laz")

# Filter by confidence
high_conf_mask = las.transport_confidence > 0.8
high_conf_road_mask = high_conf_mask & (las.classification == 11)

# Export high-quality roads only
las_filtered = laspy.LasData(las.header)
las_filtered.points = las.points[high_conf_road_mask]
las_filtered.write("high_quality_roads.laz")
```

---

## üß™ Testing Strategy

### Unit Tests

```python
# tests/test_transport_enhancement.py

def test_adaptive_buffering():
    """Test curvature-aware buffering."""
    # Create test road with curve
    coords = [(0, 0), (10, 0), (15, 5), (20, 10)]  # Has curve
    road = LineString(coords)

    # Apply adaptive buffering
    buffered = adaptive_buffer(road, base_width=4.0)

    # Assert wider at curve
    straight_width = measure_width(buffered, segment=0)
    curve_width = measure_width(buffered, segment=1)
    assert curve_width > straight_width

def test_spatial_index_performance():
    """Test spatial indexing speedup."""
    points = np.random.rand(1000000, 3) * 1000  # 1M points
    roads = generate_test_roads(n=100)

    # Without index
    start = time.time()
    labels1 = classify_linear(points, roads)
    time_linear = time.time() - start

    # With index
    start = time.time()
    labels2 = classify_spatial(points, roads)
    time_spatial = time.time() - start

    # Assert speedup
    assert time_spatial < time_linear / 5  # At least 5x faster
    assert np.array_equal(labels1, labels2)  # Same results

def test_overlap_resolution():
    """Test handling of overlapping features."""
    # Create overlapping road and railway
    road = LineString([(0, 0), (10, 0)]).buffer(2.0)
    railway = LineString([(5, -2), (5, 2)]).buffer(1.5)

    # Point in overlap zone
    point = Point(5, 0)

    # Railway should win over road
    label = resolve_overlap(point, road, railway)
    assert label == 10  # ASPRS_RAIL
```

### Integration Tests

```python
# tests/integration/test_full_pipeline.py

def test_full_preprocessing_pipeline():
    """Test complete preprocessing with enhancements."""
    config = load_config("configs/multiscale/config_asprs_preprocessing.yaml")

    # Enable all enhancements
    config.transport_detection.adaptive_buffering = True
    config.transport_detection.spatial_indexing = True
    config.transport_detection.quality_metrics = True

    # Process test tile
    processor = LiDARProcessor(config=config)
    result = processor.process_tile("data/test_integration/test_tile.laz")

    # Validate outputs
    assert result.success
    assert "transport_confidence" in result.extra_dims
    assert result.stats.avg_confidence > 0.7
    assert result.processing_time < 5.0  # Fast with spatial index
```

---

## üìö Documentation Updates

### Required Documentation

1. **User Guide**: "Using Enhanced Transport Overlay"
2. **API Reference**: New classes and functions
3. **Configuration Guide**: New parameters
4. **Performance Tuning**: Optimization tips
5. **Quality Assurance**: Using confidence scores and reports

### Example: Configuration Guide Section

````markdown
## Transport Enhancement Configuration

### Adaptive Buffering

Enable curvature-aware buffering for better edge detection:

‚Äã```yaml
transport_detection:
adaptive_buffering:
enabled: true
curvature_aware: true
curvature_factor: 0.2 # 20% width increase on curves
min_curve_radius: 50.0 # Minimum radius for max adjustment

type_specific_tolerance:
motorway: 0.5
primary: 0.5
secondary: 0.4
residential: 0.3
service: 0.2
‚Äã```

### Spatial Indexing

Enable R-tree spatial indexing for 5-10x speedup:

‚Äã`yaml
transport_detection:
  spatial_indexing:
    enabled: true
    index_type: rtree  # Options: rtree, quadtree
    cache_index: true  # Cache for batch processing
‚Äã`

### Quality Metrics

Enable confidence scoring and validation:

‚Äã`yaml
transport_detection:
  quality_metrics:
    enabled: true
    save_confidence: true  # Add confidence field to LAZ
    detect_overlaps: true
    generate_reports: true
    report_output_dir: /path/to/reports
‚Äã`
````

---

## ‚úÖ Success Criteria

### Must Have

- [x] Adaptive buffering implemented and tested
- [ ] Spatial indexing provides 5x+ speedup
- [ ] Confidence scoring for all transport points
- [ ] Quality metrics framework operational
- [ ] Comprehensive test suite passing

### Should Have

- [ ] Bridge/tunnel height filtering
- [ ] Intersection enhancement
- [ ] Overlap detection working
- [ ] Quality report generation
- [ ] Updated documentation

### Nice to Have

- [ ] Interactive visualization tool
- [ ] Roundabout optimization
- [ ] HTML report generation
- [ ] Shapefile export utilities
- [ ] Performance profiling dashboard

---

## üöÄ Next Steps

1. **Review this plan** with team/stakeholders
2. **Prioritize features** based on immediate needs
3. **Start Phase 1** implementation
4. **Create development branch**: `feature/transport-overlay-enhancement`
5. **Set up CI/CD** for automated testing

---

**Contact**: Development Team  
**Last Updated**: October 15, 2025  
**Version**: 1.0
