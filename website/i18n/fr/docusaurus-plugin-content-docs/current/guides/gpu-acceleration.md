---
sidebar_position: 4
title: Acc√©l√©ration GPU
description: Utiliser l'acc√©l√©ration GPU pour un traitement plus rapide
keywords: [gpu, cuda, performance, acc√©l√©ration, cupy, rapids]
---

Ce guide explique comment utiliser l'acc√©l√©ration GPU avec IGN LiDAR HD Dataset pour un calcul de caract√©ristiques significativement plus rapide.

## Vue d'Ensemble

L'acc√©l√©ration GPU peut fournir une **acc√©l√©ration de 4-10x** pour le calcul des caract√©ristiques par rapport au traitement CPU, particuli√®rement utile pour les grands jeux de donn√©es LiDAR.

### Avantages

- ‚ö° **4-10x plus rapide** calcul des caract√©ristiques
- üîÑ **Basculement automatique vers CPU** quand GPU indisponible
- üì¶ **Aucune modification de code** requise - ajoutez simplement un flag
- üéØ **Pr√™t pour la production** avec gestion compl√®te des erreurs

### Pr√©requis

- **Mat√©riel:** GPU NVIDIA avec support CUDA
- **Logiciel:** CUDA Toolkit 11.0 ou sup√©rieur
- **Paquets Python:** CuPy (et optionnellement RAPIDS cuML)

## Installation

### √âtape 1 : V√©rifier la Disponibilit√© CUDA

D'abord, v√©rifiez que vous avez un GPU NVIDIA et CUDA install√© :

```bash
# V√©rifier si vous avez un GPU NVIDIA
nvidia-smi

# Devrait afficher les infos de votre GPU et la version CUDA
```

Si `nvidia-smi` n'est pas trouv√©, vous devez d'abord installer les pilotes NVIDIA et le CUDA Toolkit.

### √âtape 2 : Installer CUDA Toolkit

Visitez [NVIDIA CUDA Downloads](https://developer.nvidia.com/cuda-downloads) et suivez les instructions pour votre OS.

**Versions recommand√©es :**

- CUDA 11.8 (plus compatible)
- CUDA 12.x (derni√®res fonctionnalit√©s)

### √âtape 3 : Installer les D√©pendances GPU Python

:::warning Installation CuPy
CuPy doit √™tre install√© s√©par√©ment car il n√©cessite une version sp√©cifique correspondant √† votre CUDA Toolkit. L'installation via `pip install ign-lidar-hd[gpu]` ne fonctionnera **pas** car elle tenterait de compiler CuPy depuis les sources.
:::

```bash
# Option 1 : Support GPU basique avec CuPy (recommand√© pour la plupart des utilisateurs)
pip install ign-lidar-hd
pip install cupy-cuda11x  # Pour CUDA 11.x
# OU
pip install cupy-cuda12x  # Pour CUDA 12.x

# Option 2 : GPU avanc√© avec RAPIDS cuML (meilleures performances)
pip install ign-lidar-hd
pip install cupy-cuda12x  # Choisir selon votre version CUDA
conda install -c rapidsai -c conda-forge -c nvidia cuml

# Option 3 : RAPIDS via pip (peut n√©cessiter plus de configuration)
pip install ign-lidar-hd
pip install cupy-cuda11x  # Pour CUDA 11.x
pip install cuml-cu11     # Pour CUDA 11.x
# OU
pip install cupy-cuda12x  # Pour CUDA 12.x
pip install cuml-cu12     # Pour CUDA 12.x
```

**Recommandations d'Installation :**

- **Installer CuPy s√©par√©ment** : Toujours choisir `cupy-cuda11x` ou `cupy-cuda12x` selon votre CUDA
- **CuPy uniquement** : Installation la plus simple, acc√©l√©ration 5-6x
- **CuPy + RAPIDS** : Meilleures performances, jusqu'√† 10x d'acc√©l√©ration
- **Conda pour RAPIDS** : Plus fiable pour les d√©pendances RAPIDS cuML

### √âtape 4 : V√©rifier l'Installation

```python
from ign_lidar.features_gpu import GPU_AVAILABLE, CUML_AVAILABLE

print(f"GPU (CuPy) disponible: {GPU_AVAILABLE}")
print(f"RAPIDS cuML disponible: {CUML_AVAILABLE}")
```

Sortie attendue :

```text
GPU (CuPy) disponible: True
RAPIDS cuML disponible: True
```

## Utilisation

### Interface en Ligne de Commande

Ajoutez simplement le flag `--use-gpu` √† n'importe quelle commande `enrich` :

```bash
# Utilisation basique
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu

# Avec plusieurs workers
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
  --num-workers 4

# Mode complet avec GPU
ign-lidar-hd enrich \
  --input raw_tiles/ \
  --output pre_tiles/ \
  --mode full \
  --use-gpu \
  --num-workers 6
```

### API Python

```python
from ign_lidar import LiDARProcessor
from pathlib import Path

# Initialiser le processeur avec support GPU
processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True  # Active l'acc√©l√©ration GPU
)

# Traiter une dalle avec GPU
patches = processor.process_tile(
    Path("data/tile.laz"),
    Path("output/")
)

# Traitement par lots avec GPU
patches = processor.process_directory(
    Path("data/tiles/"),
    Path("output/patches/"),
    num_workers=4  # GPU + traitement parall√®le
)
```

## Performances Attendues

### Benchmarks

Tests effectu√©s sur un syst√®me avec :

- **GPU:** NVIDIA RTX 3080 (10GB VRAM)
- **CPU:** Intel i9-10900K (10 cores, 20 threads)
- **Dalle test:** 1.2 million de points

| Configuration             | Temps de Traitement | Acc√©l√©ration    |
| ------------------------- | ------------------- | --------------- |
| CPU uniquement (1 worker) | 45.2s               | 1.0x (baseline) |
| CPU (4 workers)           | 18.8s               | 2.4x            |
| GPU (CuPy uniquement)     | 8.1s                | 5.6x            |
| GPU (CuPy + RAPIDS)       | 4.7s                | 9.6x            |

### Facteurs de Performance

**Quand le GPU est plus rapide :**

- üöÄ Grandes dalles (>500K points)
- üî¢ Calculs intensifs de caract√©ristiques
- üìä Nombreuses it√©rations (lots de dalles)

**Quand le CPU peut √™tre comp√©titif :**

- üìÅ Petites dalles (&lt;100K points)
- üíæ Traitement limit√© par I/O
- ‚ö° Surcharge de transfert GPU

## Configuration YAML

```yaml
global:
  use_gpu: true # Active GPU pour toutes les √©tapes

enrich:
  input_dir: "data/raw"
  output: "data/enriched"
  mode: "full"
  num_workers: 4 # GPU + traitement parall√®le
```

## D√©pannage

### GPU Non D√©tect√©

```python
# V√©rifier la disponibilit√© CUDA
import cupy as cp
print(cp.cuda.is_available())  # Devrait √™tre True

# V√©rifier la version CUDA
print(cp.cuda.runtime.runtimeGetVersion())
```

**Solutions :**

1. V√©rifier que les pilotes NVIDIA sont install√©s : `nvidia-smi`
2. R√©installer CuPy pour votre version CUDA
3. V√©rifier les variables d'environnement CUDA

### Erreurs de M√©moire GPU

```text
cupy.cuda.memory.OutOfMemoryError: Out of memory
```

**Solutions :**

1. R√©duire le nombre de workers : `--num-workers 1`
2. Traiter des dalles plus petites
3. Utiliser un GPU avec plus de VRAM
4. Basculer vers CPU : enlever `--use-gpu`

### Basculement vers CPU

La biblioth√®que bascule automatiquement vers CPU si :

- GPU non disponible
- CUDA non install√©
- CuPy non install√©
- Erreurs de m√©moire GPU

```text
‚ö†Ô∏è  GPU non disponible, utilisation du CPU
```

## Meilleures Pratiques

### 1. Optimiser l'Utilisation de la M√©moire

```python
# Traiter par lots pour les grands ensembles de donn√©es
processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True,
    batch_size=10  # Traiter 10 dalles √† la fois
)
```

### 2. Combiner GPU et Traitement Parall√®le

```bash
# Utiliser plusieurs workers avec GPU
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
  --num-workers 4  # 4 processus GPU en parall√®le
```

### 3. Surveiller l'Utilisation GPU

```bash
# Dans un terminal s√©par√©
watch -n 1 nvidia-smi

# Ou utiliser
gpustat -i 1
```

### 4. Profiler les Performances

```python
import time
from ign_lidar import LiDARProcessor

# Comparer CPU vs GPU
for use_gpu in [False, True]:
    processor = LiDARProcessor(lod_level="LOD2", use_gpu=use_gpu)

    start = time.time()
    processor.process_tile("data/tile.laz", "output/")
    elapsed = time.time() - start

    backend = "GPU" if use_gpu else "CPU"
    print(f"{backend}: {elapsed:.2f}s")
```

## Configuration Avanc√©e

### Variables d'Environnement

```bash
# Forcer l'utilisation CPU m√™me avec GPU disponible
export IGN_LIDAR_FORCE_CPU=1

# D√©finir le device GPU
export CUDA_VISIBLE_DEVICES=0  # Utiliser le GPU 0

# Limiter la m√©moire GPU
export CUPY_GPU_MEMORY_LIMIT=8GB
```

### S√©lection du Device

```python
from ign_lidar import LiDARProcessor
import cupy as cp

# S√©lectionner un GPU sp√©cifique
cp.cuda.Device(0).use()  # Utiliser le GPU 0

processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True
)
```

## Prochaines √âtapes

- üìñ Voir [Guide d'Utilisation de Base](basic-usage.md) pour plus d'exemples
- üîß Voir [Commandes CLI](cli-commands.md) pour toutes les options
- üé® Voir [Augmentation RGB](rgb-augmentation.md) pour l'enrichissement couleur
- üìã Voir [Configuration Pipeline](pipeline-configuration.md) pour les workflows YAML

## Ressources

- [Documentation CuPy](https://docs.cupy.dev/)
- [Documentation RAPIDS](https://docs.rapids.ai/)
- [Guide d'Installation CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)
