---
sidebar_position: 4
title: AccÃ©lÃ©ration GPU
description: Utiliser l'accÃ©lÃ©ration GPU pour un traitement plus rapide
keywords: [gpu, cuda, performance, accÃ©lÃ©ration, cupy, rapids]
---

Ce guide explique comment utiliser l'accÃ©lÃ©ration GPU avec IGN LiDAR HD Dataset pour un calcul de caractÃ©ristiques significativement plus rapide.

## Vue d'Ensemble

L'accÃ©lÃ©ration GPU peut fournir une **accÃ©lÃ©ration de 4-10x** pour le calcul des caractÃ©ristiques par rapport au traitement CPU, particuliÃ¨rement utile pour les grands jeux de donnÃ©es LiDAR.

### Avantages

- âš¡ **4-10x plus rapide** calcul des caractÃ©ristiques
- ğŸ”„ **Basculement automatique vers CPU** quand GPU indisponible
- ğŸ“¦ **Aucune modification de code** requise - ajoutez simplement un flag
- ğŸ¯ **PrÃªt pour la production** avec gestion complÃ¨te des erreurs

### PrÃ©requis

- **MatÃ©riel:** GPU NVIDIA avec support CUDA
- **Logiciel:** CUDA Toolkit 11.0 ou supÃ©rieur
- **Paquets Python:** CuPy (et optionnellement RAPIDS cuML)

## Installation

### Ã‰tape 1 : VÃ©rifier la DisponibilitÃ© CUDA

D'abord, vÃ©rifiez que vous avez un GPU NVIDIA et CUDA installÃ© :

```bash
# VÃ©rifier si vous avez un GPU NVIDIA
nvidia-smi

# Devrait afficher les infos de votre GPU et la version CUDA
```

Si `nvidia-smi` n'est pas trouvÃ©, vous devez d'abord installer les pilotes NVIDIA et le CUDA Toolkit.

### Ã‰tape 2 : Installer CUDA Toolkit

Visitez [NVIDIA CUDA Downloads](https://developer.nvidia.com/cuda-downloads) et suivez les instructions pour votre OS.

**Versions recommandÃ©es :**

- CUDA 11.8 (plus compatible)
- CUDA 12.x (derniÃ¨res fonctionnalitÃ©s)

### Ã‰tape 3 : Installer les DÃ©pendances GPU Python

```bash
# Option 1 : Support GPU basique avec CuPy (recommandÃ© pour la plupart des utilisateurs)
pip install ign-lidar-hd[gpu]

# Option 2 : GPU avancÃ© avec RAPIDS cuML (meilleures performances)
pip install ign-lidar-hd[gpu-full]

# Option 3 : RAPIDS via conda (recommandÃ© pour RAPIDS cuML)
conda install -c rapidsai -c conda-forge -c nvidia cuml
pip install ign-lidar-hd[gpu]

# Option 4 : Installation manuelle
# Pour CUDA 11.x
pip install cupy-cuda11x
pip install cuml-cu11  # Optionnel : RAPIDS cuML

# Pour CUDA 12.x
pip install cupy-cuda12x
pip install cuml-cu12  # Optionnel : RAPIDS cuML
```

**Recommandations d'Installation :**

- **CuPy uniquement** (`[gpu]`): Installation la plus facile, accÃ©lÃ©ration 5-6x
- **CuPy + RAPIDS** (`[gpu-full]`): Meilleures performances, jusqu'Ã  10x d'accÃ©lÃ©ration
- **Conda pour RAPIDS**: Plus fiable pour les dÃ©pendances RAPIDS cuML

### Ã‰tape 4 : VÃ©rifier l'Installation

```python
from ign_lidar.features_gpu import GPU_AVAILABLE, CUML_AVAILABLE

print(f"GPU (CuPy) disponible: {GPU_AVAILABLE}")
print(f"RAPIDS cuML disponible: {CUML_AVAILABLE}")
```

Sortie attendue :

```text
GPU (CuPy) disponible: True
RAPIDS cuML disponible: True
```

## Utilisation

### Interface en Ligne de Commande

Ajoutez simplement le flag `--use-gpu` Ã  n'importe quelle commande `enrich` :

```bash
# Utilisation basique
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu

# Avec plusieurs workers
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
  --num-workers 4

# Mode bÃ¢timent avec GPU
ign-lidar-hd enrich \
  --input raw_tiles/ \
  --output pre_tiles/ \
  --mode building \
  --use-gpu \
  --num-workers 6
```

### API Python

```python
from ign_lidar import LiDARProcessor
from pathlib import Path

# Initialiser le processeur avec support GPU
processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True  # Active l'accÃ©lÃ©ration GPU
)

# Traiter une dalle avec GPU
patches = processor.process_tile(
    Path("data/tile.laz"),
    Path("output/")
)

# Traitement par lots avec GPU
patches = processor.process_directory(
    Path("data/tiles/"),
    Path("output/patches/"),
    num_workers=4  # GPU + traitement parallÃ¨le
)
```

## Performances Attendues

### Benchmarks

Tests effectuÃ©s sur un systÃ¨me avec :

- **GPU:** NVIDIA RTX 3080 (10GB VRAM)
- **CPU:** Intel i9-10900K (10 cores, 20 threads)
- **Dalle test:** 1.2 million de points

| Configuration             | Temps de Traitement | AccÃ©lÃ©ration    |
| ------------------------- | ------------------- | --------------- |
| CPU uniquement (1 worker) | 45.2s               | 1.0x (baseline) |
| CPU (4 workers)           | 18.8s               | 2.4x            |
| GPU (CuPy uniquement)     | 8.1s                | 5.6x            |
| GPU (CuPy + RAPIDS)       | 4.7s                | 9.6x            |

### Facteurs de Performance

**Quand le GPU est plus rapide :**

- ğŸš€ Grandes dalles (>500K points)
- ğŸ”¢ Calculs intensifs de caractÃ©ristiques
- ğŸ“Š Nombreuses itÃ©rations (lots de dalles)

**Quand le CPU peut Ãªtre compÃ©titif :**

- ğŸ“ Petites dalles (<100K points)
- ğŸ’¾ Traitement limitÃ© par I/O
- âš¡ Surcharge de transfert GPU

## Configuration YAML

```yaml
global:
  use_gpu: true # Active GPU pour toutes les Ã©tapes

enrich:
  input_dir: "data/raw"
  output: "data/enriched"
  mode: "building"
  num_workers: 4 # GPU + traitement parallÃ¨le
```

## DÃ©pannage

### GPU Non DÃ©tectÃ©

```python
# VÃ©rifier la disponibilitÃ© CUDA
import cupy as cp
print(cp.cuda.is_available())  # Devrait Ãªtre True

# VÃ©rifier la version CUDA
print(cp.cuda.runtime.runtimeGetVersion())
```

**Solutions :**

1. VÃ©rifier que les pilotes NVIDIA sont installÃ©s : `nvidia-smi`
2. RÃ©installer CuPy pour votre version CUDA
3. VÃ©rifier les variables d'environnement CUDA

### Erreurs de MÃ©moire GPU

```text
cupy.cuda.memory.OutOfMemoryError: Out of memory
```

**Solutions :**

1. RÃ©duire le nombre de workers : `--num-workers 1`
2. Traiter des dalles plus petites
3. Utiliser un GPU avec plus de VRAM
4. Basculer vers CPU : enlever `--use-gpu`

### Basculement vers CPU

La bibliothÃ¨que bascule automatiquement vers CPU si :

- GPU non disponible
- CUDA non installÃ©
- CuPy non installÃ©
- Erreurs de mÃ©moire GPU

```text
âš ï¸  GPU non disponible, utilisation du CPU
```

## Meilleures Pratiques

### 1. Optimiser l'Utilisation de la MÃ©moire

```python
# Traiter par lots pour les grands ensembles de donnÃ©es
processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True,
    batch_size=10  # Traiter 10 dalles Ã  la fois
)
```

### 2. Combiner GPU et Traitement ParallÃ¨le

```bash
# Utiliser plusieurs workers avec GPU
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
  --num-workers 4  # 4 processus GPU en parallÃ¨le
```

### 3. Surveiller l'Utilisation GPU

```bash
# Dans un terminal sÃ©parÃ©
watch -n 1 nvidia-smi

# Ou utiliser
gpustat -i 1
```

### 4. Profiler les Performances

```python
import time
from ign_lidar import LiDARProcessor

# Comparer CPU vs GPU
for use_gpu in [False, True]:
    processor = LiDARProcessor(lod_level="LOD2", use_gpu=use_gpu)

    start = time.time()
    processor.process_tile("data/tile.laz", "output/")
    elapsed = time.time() - start

    backend = "GPU" if use_gpu else "CPU"
    print(f"{backend}: {elapsed:.2f}s")
```

## Configuration AvancÃ©e

### Variables d'Environnement

```bash
# Forcer l'utilisation CPU mÃªme avec GPU disponible
export IGN_LIDAR_FORCE_CPU=1

# DÃ©finir le device GPU
export CUDA_VISIBLE_DEVICES=0  # Utiliser le GPU 0

# Limiter la mÃ©moire GPU
export CUPY_GPU_MEMORY_LIMIT=8GB
```

### SÃ©lection du Device

```python
from ign_lidar import LiDARProcessor
import cupy as cp

# SÃ©lectionner un GPU spÃ©cifique
cp.cuda.Device(0).use()  # Utiliser le GPU 0

processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True
)
```

## Prochaines Ã‰tapes

- ğŸ“– Voir [Guide d'Utilisation de Base](basic-usage.md) pour plus d'exemples
- ğŸ”§ Voir [Commandes CLI](cli-commands.md) pour toutes les options
- ğŸ¨ Voir [Augmentation RGB](rgb-augmentation.md) pour l'enrichissement couleur
- ğŸ“‹ Voir [Configuration Pipeline](pipeline-configuration.md) pour les workflows YAML

## Ressources

- [Documentation CuPy](https://docs.cupy.dev/)
- [Documentation RAPIDS](https://docs.rapids.ai/)
- [Guide d'Installation CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)
