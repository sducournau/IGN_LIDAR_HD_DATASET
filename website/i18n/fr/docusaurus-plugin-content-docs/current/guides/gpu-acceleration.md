---
sidebar_position: 4
title: Acc√©l√©ration GPU
description: Utiliser l'acc√©l√©ration GPU pour un traitement LiDAR plus rapide
keywords:
  [gpu, cuda, acc√©l√©ration, performance, optimisation, cuml, rapids, cupy]
---

# Acc√©l√©ration GPU

L'acc√©l√©ration GPU acc√©l√®re consid√©rablement les workflows de traitement LiDAR, offrant une **acc√©l√©ration de 6-20x** pour les jeux de donn√©es √† grande √©chelle et les t√¢ches complexes d'extraction de caract√©ristiques.

## Vue d'Ensemble

Le processeur IGN LiDAR HD supporte l'acc√©l√©ration GPU avec trois modes de performance :

1. **CPU Uniquement**: Traitement standard (pas de GPU requis)
2. **Mode Hybride (CuPy)**: Tableaux GPU + algorithmes CPU (acc√©l√©ration 6-8x)
3. **Mode GPU Complet (RAPIDS cuML)**: Pipeline GPU complet (acc√©l√©ration 12-20x)

Le mode hybride utilise une **strat√©gie KDTree per-chunk** intelligente qui √©vite les goulets d'√©tranglement de construction d'arbre global, offrant d'excellentes performances m√™me sans RAPIDS cuML.

### Op√©rations Support√©es

- **Extraction de Caract√©ristiques G√©om√©triques**: Normales de surface, courbure, planarit√©, verticalit√©
- **Recherche KNN**: K plus proches voisins acc√©l√©r√© par GPU (avec RAPIDS cuML)
- **Calcul PCA**: Analyse en composantes principales bas√©e sur GPU (avec RAPIDS cuML)
- **Filtrage de Nuages de Points**: Pr√©traitement parall√®le et r√©duction du bruit
- **Augmentation RGB/NIR**: Int√©gration d'orthophotos optimis√©e par GPU

## üöÄ Benchmarks de Performance

### R√©sultats R√©els (17M points, NVIDIA RTX 4080 16GB)

**Performance v1.7.5 (Optimis√©e)** :

| Mode                      | Temps de Traitement | Acc√©l√©ration | Pr√©requis                |
| ------------------------- | ------------------- | ------------ | ------------------------ |
| CPU Uniquement            | 60 min ‚Üí 12 min     | 5x           | Aucun (optimis√©!)        |
| Hybride (CuPy + sklearn)  | 7-10 min ‚Üí 2 min    | 25-30x       | CuPy + CUDA 12.0+        |
| GPU Complet (RAPIDS cuML) | 3-5 min ‚Üí 1-2 min   | 30-60x       | RAPIDS cuML + CUDA 12.0+ |

:::tip Optimisation v1.7.5
La version v1.7.5 inclut des optimisations majeures de performance qui b√©n√©ficient √† **tous les modes** (CPU, Hybride, GPU Complet). La strat√©gie KDTree per-chunk et des chunks plus petits offrent une acc√©l√©ration 5-10x automatiquement !
:::

### D√©tail des Op√©rations

| Op√©ration                      | CPU     | GPU Hybride | GPU Complet | Meilleure Acc√©l√©ration |
| ------------------------------ | ------- | ----------- | ----------- | ---------------------- |
| Extraction de Caract√©ristiques | 45 min  | 8 min       | 3 min       | 15x                    |
| Recherche KNN                  | 30 min  | 15 min      | 2 min       | 15x                    |
| Calcul PCA                     | 10 min  | 8 min       | 1 min       | 10x                    |
| Traitement par Lots            | 120 min | 20 min      | 8 min       | 15x                    |

## üîß Pr√©requis d'Installation

### Configuration Mat√©rielle Requise

- **GPU**: GPU NVIDIA avec Compute Capability 6.0+ (Pascal ou plus r√©cent)
- **M√©moire**: Minimum 4GB VRAM (8GB+ recommand√©, 16GB pour grandes tuiles)
- **Pilote**: Pilote NVIDIA compatible CUDA 12.0+
- **Syst√®me**: 32GB+ RAM recommand√© pour le traitement de grandes tuiles

### Mat√©riel Recommand√©

- **Budget**: NVIDIA RTX 3060 12GB
- **Optimal**: NVIDIA RTX 4070/4080 16GB
- **Professionnel**: NVIDIA A6000 48GB

## üì¶ Options d'Installation

### Option 1: Mode Hybride (CuPy Uniquement) - D√©marrage Rapide

**Id√©al pour**: Configuration rapide, tests, ou lorsque RAPIDS cuML n'est pas disponible

```bash
# Installer CuPy pour votre version CUDA
pip install cupy-cuda12x  # Pour CUDA 12.x
# OU
pip install cupy-cuda11x  # Pour CUDA 11.x

# V√©rifier la disponibilit√© GPU
python -c "import cupy as cp; print(cp.cuda.runtime.getDeviceCount(), 'GPU(s) d√©tect√©(s)')"
```

**Performance**: Acc√©l√©ration 6-8x (utilise des tableaux GPU avec algorithmes CPU sklearn via optimisation per-chunk)

### Option 2: Mode GPU Complet (RAPIDS cuML) - Performance Maximale

**Id√©al pour**: Charges de travail en production, traitement √† grande √©chelle, vitesse maximale

```bash
# Cr√©er un environnement conda (requis pour RAPIDS)
conda create -n ign_gpu python=3.12 -y
conda activate ign_gpu

# Installer RAPIDS cuML (inclut CuPy)
conda install -c rapidsai -c conda-forge -c nvidia \
    cuml=24.10 cupy cuda-version=12.5 -y

# Installer IGN LiDAR HD
pip install ign-lidar-hd

# V√©rifier l'installation
python scripts/verify_gpu_setup.py
```

**Performance**: Acc√©l√©ration 12-20x (pipeline GPU complet)

### Option 3: Script d'Installation Automatis√©

Pour les syst√®mes WSL2/Linux, utilisez notre script d'installation automatis√© :

```bash
# T√©l√©charger et ex√©cuter le script d'installation
wget https://raw.githubusercontent.com/sducournau/IGN_LIDAR_HD_DATASET/main/install_cuml.sh
chmod +x install_cuml.sh
./install_cuml.sh
```

Le script va :

- Installer Miniconda (si n√©cessaire)
- Cr√©er l'environnement conda `ign_gpu`
- Installer RAPIDS cuML + toutes les d√©pendances
- Configurer les chemins CUDA

### V√©rification de l'Installation

```bash
# V√©rifier la d√©tection GPU
ign-lidar-hd --version

# Tester le traitement GPU (utiliser une petite tuile)
ign-lidar-hd enrich --input test.laz --output test_enriched.laz --use-gpu
```

## üìñ Guide d'Utilisation

### Interface en Ligne de Commande

Le moyen le plus simple d'utiliser l'acc√©l√©ration GPU est via la CLI :

```bash
# Traitement GPU basique
ign-lidar-hd enrich --input-dir data/ --output enriched/ --use-gpu

# Traitement GPU complet avec toutes les options
ign-lidar-hd enrich \
  --input-dir data/ \
  --output enriched/ \
  --use-gpu \
  --auto-params \
  --preprocess \
  --add-rgb \
  --add-infrared \
  --rgb-cache-dir cache/rgb \
  --infrared-cache-dir cache/infrared

# Traiter des tuiles sp√©cifiques
ign-lidar-hd enrich \
  --input tile1.laz tile2.laz \
  --output enriched/ \
  --use-gpu \
  --force  # Retraiter m√™me si les sorties existent
```

### API Python

```python
from ign_lidar import LiDARProcessor

# Initialiser avec support GPU
processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True,
    num_workers=4
)

# Traiter une seule tuile
patches = processor.process_tile(
    "data/tile.laz",
    "output/",
    enable_rgb=True
)

# Traiter un r√©pertoire avec GPU
patches = processor.process_directory(
    "data/",
    "output/",
    num_workers=4
)
```

### Configuration Pipeline (YAML)

```yaml
global:
  num_workers: 4

enrich:
  input_dir: "data/raw"
  output: "data/enriched"
  use_gpu: true
  auto_params: true
  preprocess: true
  add_rgb: true
  add_infrared: true
  rgb_cache_dir: "cache/rgb"
  infrared_cache_dir: "cache/infrared"

patch:
  input_dir: "data/enriched"
  output: "data/patches"
  lod_level: "LOD2"
```

Puis ex√©cuter : `ign-lidar-hd pipeline config.yaml`

## üêõ D√©pannage

### Probl√®mes Courants

#### GPU Non D√©tect√©

**Sympt√¥mes**: Message "GPU non disponible, bascule vers CPU"

**Solutions**:

```bash
# 1. V√©rifier si le GPU est visible
nvidia-smi

# 2. V√©rifier l'installation CUDA
python -c "import cupy as cp; print(cp.cuda.runtime.getDeviceCount())"

# 3. V√©rifier la compatibilit√© de version CUDA
python -c "import cupy; print('Version CUDA CuPy:', cupy.cuda.runtime.runtimeGetVersion())"

# 4. V√©rifier LD_LIBRARY_PATH (Linux/WSL2)
echo $LD_LIBRARY_PATH  # Devrait inclure /usr/local/cuda-XX.X/lib64
```

#### Probl√®mes d'Installation CuPy

**Probl√®me**: CuPy ne trouve pas les biblioth√®ques CUDA

**Solution WSL2**:

```bash
# Installer CUDA Toolkit
wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update
sudo apt-get install cuda-toolkit-13-0

# Ajouter √† ~/.zshrc ou ~/.bashrc
export PATH=/usr/local/cuda-13.0/bin:$PATH
export LD_LIBRARY_PATH=/usr/local/cuda-13.0/lib64:$LD_LIBRARY_PATH

# Recharger et tester
source ~/.zshrc
python -c "import cupy; print('CuPy fonctionne!')"
```

#### Probl√®mes d'Installation RAPIDS cuML

**Probl√®me**: Erreurs TOS conda lors de l'installation

**Solution**:

```bash
# Accepter les Conditions d'Utilisation conda
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/main
conda tos accept --override-channels --channel https://repo.anaconda.com/pkgs/r

# R√©essayer l'installation
conda install -c rapidsai -c conda-forge -c nvidia cuml=24.10 -y
```

#### M√©moire CUDA Insuffisante

**Sympt√¥mes**: RuntimeError: CUDA out of memory

**Solutions**:

1. **Traiter des tuiles plus petites**: Diviser les gros fichiers en morceaux plus petits
2. **R√©duire la taille des chunks**: Le processeur d√©coupe automatiquement les grands nuages de points
3. **Fermer d'autres applications GPU**: Lib√©rer la VRAM
4. **Utiliser un GPU avec plus de m√©moire**: 16GB+ recommand√© pour les grandes tuiles

```bash
# Surveiller l'utilisation de la m√©moire GPU
watch -n 1 nvidia-smi
```

#### Performances Lentes Malgr√© le GPU

**Causes possibles**:

1. **Utilisation du Mode Hybride au lieu du GPU Complet**: Installer RAPIDS cuML pour une vitesse maximale
2. **Limitation thermique**: V√©rifier la temp√©rature GPU avec `nvidia-smi`
3. **Bande passante PCIe**: S'assurer que le GPU est dans un slot x16
4. **Goulot d'√©tranglement CPU**: Utiliser `--num-workers` pour parall√©liser les E/S

**V√©rifier l'utilisation GPU**:

```bash
# Surveiller l'utilisation GPU pendant le traitement
nvidia-smi dmon -s u
```

#### Per-Chunk vs KDTree Global

Le syst√®me s√©lectionne automatiquement la meilleure strat√©gie:

- **Avec RAPIDS cuML**: Utilise KDTree global sur GPU (le plus rapide, acc√©l√©ration 12-20x)
- **Sans cuML**: Utilise KDTree per-chunk avec CPU sklearn (toujours rapide, acc√©l√©ration 6-8x)

Vous verrez diff√©rents messages de log:

```text
# Avec cuML (le plus rapide)
‚úì RAPIDS cuML disponible - algorithmes GPU activ√©s
Calcul des normales avec KDTree acc√©l√©r√© GPU (global)

# Sans cuML (toujours rapide)
‚ö† RAPIDS cuML non disponible - utilise KDTree per-chunk CPU
Calcul des normales avec KDTree per-chunk (chevauchement 5%)
```

### Basculement Automatique vers CPU

Le syst√®me bascule automatiquement vers le traitement CPU si le GPU n'est pas disponible:

- √âchec d'import CuPy ‚Üí mode CPU
- Erreur d'ex√©cution CUDA ‚Üí mode CPU
- M√©moire GPU insuffisante ‚Üí mode CPU (avec avertissement)

**D√©sactiver le GPU** (forcer CPU):

```bash
ign-lidar-hd enrich --input-dir data/ --output enriched/  # Pas de flag --use-gpu
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
```

## üìã Benchmarks D√©taill√©s

### Environnement de Test

- **GPU**: NVIDIA RTX 4080 (16GB VRAM)
- **CPU**: AMD Ryzen 9 / Intel i7 √©quivalent
- **Syst√®me**: WSL2 Ubuntu 24.04, 32GB RAM
- **CUDA**: 13.0
- **Tuile Test**: 17M points (tuile IGN LiDAR HD typique)

### Comparaison des Temps de Traitement

| Configuration             | Temps de Traitement | Acc√©l√©ration | Notes                                 |
| ------------------------- | ------------------- | ------------ | ------------------------------------- |
| CPU Uniquement (sklearn)  | 60 min              | 1x           | Ligne de base                         |
| Hybride (CuPy + sklearn)  | 7-10 min            | 6-8x         | Optimisation KDTree per-chunk         |
| GPU Complet (RAPIDS cuML) | 3-5 min             | 12-20x       | KDTree GPU global + PCA/KNN acc√©l√©r√©s |

### D√©tail de l'Extraction de Caract√©ristiques

| Op√©ration               | CPU    | GPU Hybride | GPU Complet | Meilleure Acc√©l√©ration |
| ----------------------- | ------ | ----------- | ----------- | ---------------------- |
| Calcul des Normales     | 25 min | 4 min       | 1.5 min     | 16x                    |
| Recherche KNN           | 20 min | 12 min      | 1 min       | 20x                    |
| PCA (valeurs propres)   | 8 min  | 6 min       | 0.5 min     | 16x                    |
| Calcul de Courbure      | 5 min  | 2 min       | 0.5 min     | 10x                    |
| Autres Caract√©ristiques | 2 min  | 1 min       | 0.5 min     | 4x                     |

### Utilisation M√©moire

| Mode                      | M√©moire GPU | RAM Syst√®me | Total |
| ------------------------- | ----------- | ----------- | ----- |
| CPU Uniquement            | 0 GB        | 24 GB       | 24 GB |
| Hybride (CuPy + sklearn)  | 6 GB        | 16 GB       | 22 GB |
| GPU Complet (RAPIDS cuML) | 8 GB        | 12 GB       | 20 GB |

### Traitement par Lots (100 tuiles)

- **CPU Uniquement**: ~100 heures
- **Mode Hybride**: ~12-15 heures (acc√©l√©ration 6-8x)
- **Mode GPU Complet**: ~5-8 heures (acc√©l√©ration 12-20x)

### Validation de la Pr√©cision

Les trois modes produisent des **r√©sultats identiques** (v√©rifi√© avec corr√©lation de caract√©ristiques > 0.9999).

## üîó Documentation Connexe

- [Guide de D√©marrage Rapide](./quick-start.md)
- [Optimisation des Performances](./performance.md)
- [D√©pannage](./troubleshooting.md)
- [Configuration Pipeline](../api/pipeline-config.md)
- [Guide d'Installation](../installation/quick-start.md)

## üí° Meilleures Pratiques

### 1. Choisir le Bon Mode

- **D√©veloppement/Tests**: Mode hybride (configuration facile, bonnes performances)
- **Production**: Mode GPU complet avec RAPIDS cuML (performance maximale)
- **Pas de GPU**: Mode CPU fonctionne bien pour les petits lots

### 2. Optimiser Votre Workflow

```yaml
# Configuration pipeline recommand√©e pour GPU
global:
  num_workers: 4 # Parall√©liser les E/S pendant que le GPU traite

enrich:
  use_gpu: true
  auto_params: true # Laisser le syst√®me optimiser les param√®tres
  preprocess: true # Nettoyer les donn√©es avant l'extraction de caract√©ristiques
```

### 3. Surveiller les Ressources

```bash
# Surveiller l'utilisation GPU en temps r√©el
watch -n 1 nvidia-smi

# Surveiller avec des m√©triques d√©taill√©es
nvidia-smi dmon -s pucvmet -d 1
```

### 4. Conseils pour le Traitement par Lots

- **Utiliser --force avec pr√©caution**: Ne retraiter que lorsque n√©cessaire
- **Activer le cache intelligent**: Utiliser `--rgb-cache-dir` et `--infrared-cache-dir`
- **Parall√©liser les E/S**: Utiliser `--num-workers` pour les op√©rations fichiers concurrentes
- **Traiter strat√©giquement**: Commencer par les tuiles urbaines (densit√© de points √©lev√©e) pour tester les param√®tres

### 5. Recommandations Mat√©rielles

| Cas d'Usage                       | GPU Minimum   | GPU Recommand√© | GPU Optimal      |
| --------------------------------- | ------------- | -------------- | ---------------- |
| Apprentissage/Petits jeux donn√©es | GTX 1660 6GB  | RTX 3060 12GB  | RTX 4060 Ti 16GB |
| Production/Lots moyens            | RTX 3060 12GB | RTX 4070 12GB  | RTX 4080 16GB    |
| Traitement grande √©chelle         | RTX 3080 10GB | RTX 4080 16GB  | A6000 48GB       |

## üéì Sujets Avanc√©s

### Strat√©gie d'Optimisation Per-Chunk

Lorsque RAPIDS cuML n'est pas disponible, le syst√®me utilise une strat√©gie intelligente per-chunk:

1. **Divise le nuage de points** en chunks de ~5M points
2. **Construit un KDTree local** par chunk (rapide avec sklearn)
3. **Utilise un chevauchement de 5%** entre chunks pour g√©rer les cas limites
4. **Fusionne les r√©sultats** de mani√®re transparente

**Performances**: Cette strat√©gie √©vite le goulet d'√©tranglement de la PCA CPU s√©quentielle (qui prendrait ~85 minutes), r√©duisant le temps de traitement √† 7-10 minutes. Cela fournit 6-8x d'acc√©l√©ration sans n√©cessiter l'installation de RAPIDS cuML.

### Gestion de la M√©moire GPU

Le syst√®me g√®re automatiquement la m√©moire GPU:

- **D√©coupage automatique**: Les grands nuages de points sont divis√©s en chunks de taille GPU
- **Pooling m√©moire**: CuPy r√©utilise la m√©moire allou√©e
- **Garbage collection**: Lib√®re la m√©moire entre les tuiles
- **Gestion des erreurs**: G√®re gracieusement les erreurs OOM

### Support Multi-GPU

Actuellement, la biblioth√®que utilise un seul GPU (device 0). Pour le traitement multi-GPU:

```bash
# Traiter diff√©rents r√©pertoires sur diff√©rents GPUs
CUDA_VISIBLE_DEVICES=0 ign-lidar-hd enrich --input dir1/ --output out1/ --use-gpu &
CUDA_VISIBLE_DEVICES=1 ign-lidar-hd enrich --input dir2/ --output out2/ --use-gpu &
```

---

_Pour des techniques d'optimisation GPU plus avanc√©es, consultez le [Guide de Performance](./performance.md)._

````

### 3. Surveiller l'Utilisation GPU

```bash
# Dans un terminal s√©par√©
watch -n 1 nvidia-smi

# Ou utiliser
gpustat -i 1
````

### 4. Profiler les Performances

```python
import time
from ign_lidar import LiDARProcessor

# Comparer CPU vs GPU
for use_gpu in [False, True]:
    processor = LiDARProcessor(lod_level="LOD2", use_gpu=use_gpu)

    start = time.time()
    processor.process_tile("data/tile.laz", "output/")
    elapsed = time.time() - start

    backend = "GPU" if use_gpu else "CPU"
    print(f"{backend}: {elapsed:.2f}s")
```

## Configuration Avanc√©e

### Variables d'Environnement

```bash
# Forcer l'utilisation CPU m√™me avec GPU disponible
export IGN_LIDAR_FORCE_CPU=1

# D√©finir le device GPU
export CUDA_VISIBLE_DEVICES=0  # Utiliser le GPU 0

# Limiter la m√©moire GPU
export CUPY_GPU_MEMORY_LIMIT=8GB
```

### S√©lection du Device

```python
from ign_lidar import LiDARProcessor
import cupy as cp

# S√©lectionner un GPU sp√©cifique
cp.cuda.Device(0).use()  # Utiliser le GPU 0

processor = LiDARProcessor(
    lod_level="LOD2",
    use_gpu=True
)
```

## Prochaines √âtapes

- üìñ Voir [Guide d'Utilisation de Base](basic-usage.md) pour plus d'exemples
- üîß Voir [Commandes CLI](cli-commands.md) pour toutes les options
- üé® Voir [Augmentation RGB](rgb-augmentation.md) pour l'enrichissement couleur
- üìã Voir [Configuration Pipeline](pipeline-configuration.md) pour les workflows YAML

## Ressources

- [Documentation CuPy](https://docs.cupy.dev/)
- [Documentation RAPIDS](https://docs.rapids.ai/)
- [Guide d'Installation CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)
