---
sidebar_position: 1
title: "Vue d'ensemble de l'Acc√©l√©ration GPU"
description: "Configuration et utilisation de l'acc√©l√©ration GPU pour un traitement LiDAR plus rapide"
keywords: [gpu, cuda, cupy, performance, acceleration]
---

# Vue d'ensemble de l'Acc√©l√©ration GPU

**Disponible dans :** v1.3.0+  
**Gain de Performance :** 5 √† 10x plus rapide que le CPU  
**Pr√©requis :** GPU NVIDIA avec CUDA 11.0+

:::tip Statut du D√©veloppement GPU
üöß **Am√©lioration Majeure GPU en Cours** - Nous impl√©mentons une acc√©l√©ration GPU compl√®te sur l'ensemble du pipeline. Consultez notre feuille de route d√©taill√©e dans la section "D√©veloppement Futur" ci-dessous pour les fonctionnalit√©s √† venir.
:::

## Vue d'ensemble

L'acc√©l√©ration GPU peut fournir une **acc√©l√©ration de 4 √† 10x** pour le calcul des caract√©ristiques par rapport au traitement CPU, ce qui la rend essentielle pour les jeux de donn√©es LiDAR √† grande √©chelle et les pipelines de production.

### Avantages

- ‚ö° **4 √† 10x plus rapide** pour le calcul des caract√©ristiques
- üîÑ **Basculement automatique vers CPU** lorsque le GPU n'est pas disponible
- üì¶ **Aucune modification de code** requise - ajoutez simplement un flag
- üéØ **Pr√™t pour la production** avec gestion d'erreurs compl√®te
- üíæ **Efficacit√© m√©moire** avec traitement par lots intelligent

:::tip Gains de Performance
L'acc√©l√©ration GPU est plus b√©n√©fique pour les nuages de points avec >100K points. Pour les petits jeux de donn√©es, le traitement CPU peut √™tre plus rapide en raison de la surcharge d'initialisation du GPU.
:::

## Pr√©requis

### Pr√©requis Mat√©riel

- **GPU :** GPU NVIDIA avec support CUDA
- **M√©moire :** 4GB+ de RAM GPU recommand√©e (8GB+ pour les grandes tuiles)
- **Capacit√© de Calcul :** 3.5 ou sup√©rieure

### Pr√©requis Logiciel

- **CUDA Toolkit :** 11.0 ou sup√©rieur (11.8 ou 12.x recommand√©)
- **Python :** 3.8 ou sup√©rieur
- **Packages Python :** CuPy (requis), RAPIDS cuML (optionnel, meilleures performances)

### Mod√®les GPU Test√©s

| Mod√®le GPU  | M√©moire | Performance | Notes                    |
| ----------- | ------- | ----------- | ------------------------ |
| RTX 4090    | 24 GB   | Excellente  | Meilleures performances  |
| RTX 3080    | 10 GB   | Tr√®s Bonne  | Bon rapport qualit√©/prix |
| RTX 3060    | 12 GB   | Bonne       | √âconomique               |
| Tesla V100  | 16 GB   | Tr√®s Bonne  | Serveur/cloud            |
| GTX 1080 Ti | 11 GB   | Mod√©r√©e     | Ancienne g√©n√©ration      |

## Installation

### √âtape 1 : V√©rifier la Disponibilit√© CUDA

Tout d'abord, v√©rifiez que vous avez un GPU NVIDIA et CUDA install√© :

```bash
# V√©rifier si vous avez un GPU NVIDIA
nvidia-smi

# Devrait afficher les informations de votre GPU et la version CUDA
```

Si `nvidia-smi` n'est pas trouv√©, vous devez d'abord installer les pilotes NVIDIA et le CUDA Toolkit.

### √âtape 2 : Installer le CUDA Toolkit

Visitez [NVIDIA CUDA Downloads](https://developer.nvidia.com/cuda-downloads) et suivez les instructions pour votre OS.

**Versions recommand√©es :**

- CUDA 11.8 (la plus compatible)
- CUDA 12.x (derni√®res fonctionnalit√©s)

:::info Support WSL2
L'acc√©l√©ration GPU fonctionne sur WSL2 ! Pr√©requis :

- Windows 11 ou Windows 10 21H2+
- Pilotes NVIDIA install√©s sur Windows
- CUDA toolkit install√© dans WSL2

Consultez le [guide WSL NVIDIA](https://docs.nvidia.com/cuda/wsl-user-guide/index.html) pour plus de d√©tails.
:::

### √âtape 3 : Installer les D√©pendances Python GPU

:::warning Installation de CuPy
CuPy doit √™tre install√© s√©par√©ment car il n√©cessite une version sp√©cifique correspondant √† votre CUDA Toolkit. L'installation via `pip install ign-lidar-hd[gpu]` **ne fonctionnera pas** car elle tenterait de compiler CuPy depuis les sources.
:::

```bash
# Option 1 : Support GPU basique avec CuPy (recommand√© pour la plupart des utilisateurs)
pip install ign-lidar-hd
pip install cupy-cuda11x  # Pour CUDA 11.x
# OU
pip install cupy-cuda12x  # Pour CUDA 12.x

# Option 2 : GPU avanc√© avec RAPIDS cuML (meilleures performances)
pip install ign-lidar-hd
pip install cupy-cuda12x  # Choisir selon votre version CUDA
conda install -c rapidsai -c conda-forge -c nvidia cuml

# Option 3 : RAPIDS via pip (peut n√©cessiter plus de configuration)
pip install ign-lidar-hd
pip install cupy-cuda11x  # Pour CUDA 11.x
pip install cuml-cu11     # Pour CUDA 11.x
# OU
pip install cupy-cuda12x  # Pour CUDA 12.x
pip install cuml-cu12     # Pour CUDA 12.x
```

**Recommandations d'Installation :**

- **Installer CuPy s√©par√©ment** : Toujours choisir `cupy-cuda11x` ou `cupy-cuda12x` selon votre version CUDA
- **CuPy uniquement** : Installation la plus simple, acc√©l√©ration de 5-6x
- **CuPy + RAPIDS** : Meilleures performances, jusqu'√† 10x d'acc√©l√©ration
- **Conda pour RAPIDS** : Plus fiable pour les d√©pendances RAPIDS cuML

### √âtape 4 : V√©rifier l'Installation

```python
from ign_lidar.features_gpu import GPU_AVAILABLE, CUML_AVAILABLE

print(f"GPU (CuPy) available: {GPU_AVAILABLE}")
print(f"RAPIDS cuML available: {CUML_AVAILABLE}")
```

Sortie attendue :

```
GPU (CuPy) available: True
RAPIDS cuML available: True
```

## D√©marrage Rapide

### Interface en Ligne de Commande

Ajoutez simplement le flag `--use-gpu` √† n'importe quelle commande `enrich` :

```bash
# Utilisation basique
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu

# Avec des options suppl√©mentaires
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
  --mode full \
  --num-workers 4
```

:::tip Basculement Automatique
Le flag `--use-gpu` basculera automatiquement vers le CPU si le GPU n'est pas disponible. Votre traitement continuera sans erreurs.
:::

### API Python

#### Utilisation de LiDARProcessor

```python
from pathlib import Path
from ign_lidar.processor import LiDARProcessor

# Cr√©er un processeur avec acc√©l√©ration GPU
processor = LiDARProcessor(
    lod_level='LOD2',
    patch_size=150.0,
    num_points=16384,
    use_gpu=True  # ‚ö° Activer le GPU
)

# Traiter les tuiles - acc√©l√©ration GPU automatique
num_patches = processor.process_tile(
    laz_file=Path("data/tiles/tile.laz"),
    output_dir=Path("data/patches")
)

print(f"Cr√©√© {num_patches} patches avec GPU")
```

#### Calcul Direct de Caract√©ristiques

```python
import numpy as np
from ign_lidar.features import compute_all_features_with_gpu

# Charger votre nuage de points
points = np.random.rand(1000000, 3).astype(np.float32)
classification = np.random.randint(0, 10, 1000000).astype(np.uint8)

# Calculer les caract√©ristiques avec GPU
normals, curvature, height, geo_features = compute_all_features_with_gpu(
    points=points,
    classification=classification,
    k=10,
    auto_k=False,
    use_gpu=True  # Active le GPU
)

print(f"Calcul√© {len(normals)} normales sur GPU")
```

## Configuration

### Configuration Python

```python
from ign_lidar import Config

config = Config(
    use_gpu=True,
    gpu_memory_limit=0.8,  # Utiliser 80% de la m√©moire GPU
    cuda_device=0  # Utiliser le premier GPU (si plusieurs)
)
```

### Variables d'Environnement

```bash
# Sp√©cifier le p√©riph√©rique CUDA (si plusieurs GPUs)
export CUDA_VISIBLE_DEVICES=0

# Limiter l'utilisation de la m√©moire GPU
export CUPY_GPU_MEMORY_LIMIT="8GB"
```

```python
import os

# D√©finir avant d'importer ign_lidar
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from ign_lidar.processor import LiDARProcessor
```

## Quand Utiliser le GPU

### ‚úÖ Utiliser le GPU pour

- Grands nuages de points (>100K points)
- Traitement par lots de nombreuses tuiles
- Pipelines de production n√©cessitant de la vitesse
- Applications temps r√©el ou interactives
- Traitement de 10+ tuiles

### ‚ùå Utiliser le CPU pour

- Petits nuages de points (&lt;10K points)
- T√¢ches de traitement ponctuelles
- Syst√®mes sans GPU NVIDIA
- Prototypage et d√©bogage
- Tests rapides avec 1-2 tuiles

### Arbre de D√©cision

```mermaid
flowchart TD
    Start([Need to Process LiDAR]) --> Size{Point Cloud Size}

    Size -->|< 10K points| UseCPU[Use CPU]
    Size -->|10K - 100K points| Consider{Batch Processing?}
    Size -->|> 100K points| UseGPU[Use GPU]

    Consider -->|Yes, many tiles| UseGPU
    Consider -->|No, 1-2 tiles| Either[Either CPU or GPU]

    UseGPU --> Check{GPU Available?}
    Check -->|Yes| GPUProcess[‚ö° GPU Processing]
    Check -->|No| Fallback[Automatic CPU Fallback]

    UseCPU --> CPUProcess[CPU Processing]
    Either --> CPUProcess
    Fallback --> CPUProcess

    style GPUProcess fill:#e8f5e8
    style CPUProcess fill:#e3f2fd
    style Fallback fill:#fff3e0
```

## Benchmarks de Performance

### Acc√©l√©rations Attendues

Bas√© sur des tests avec diff√©rents GPUs :

| Nombre de Points | CPU (12 c≈ìurs) | GPU (RTX 3080) | Acc√©l√©ration |
| ---------------- | -------------- | -------------- | ------------ |
| 1K points        | 0.02s          | 0.01s          | 2x           |
| 10K points       | 0.15s          | 0.03s          | 5x           |
| 100K points      | 0.50s          | 0.08s          | 6.3x         |
| 1M points        | 4.5s           | 0.8s           | 5.6x         |
| 10M points       | 45s            | 8s             | 5.6x         |

**Facteurs affectant les performances :**

- Mod√®le GPU et m√©moire
- Densit√© et distribution du nuage de points
- Param√®tre K-neighbors (plus grand = plus de calcul)
- R√©f√©rence CPU (plus de c≈ìurs = acc√©l√©ration relative plus faible)

### Comparaison des Performances

```mermaid
xychart-beta
    title "Processing Speed Comparison (Tiles per Hour)"
    x-axis [Small Tiles, Medium Tiles, Large Tiles, Very Large Tiles]
    y-axis "Tiles per Hour" 0 --> 60
    bar "CPU (8 cores)" [12, 8, 4, 2]
    bar "GPU (RTX 3080)" [48, 32, 20, 12]
    bar "GPU (RTX 4090)" [60, 40, 28, 16]
```

### Benchmark de Votre Syst√®me

Utilisez le script de benchmark inclus pour tester les performances GPU vs CPU :

```bash
# Benchmark synth√©tique rapide
python scripts/benchmarks/benchmark_gpu.py --synthetic

# Benchmark avec des donn√©es r√©elles
python scripts/benchmarks/benchmark_gpu.py path/to/file.laz

# Benchmark complet multi-tailles
python scripts/benchmarks/benchmark_gpu.py --multi-size
```

## Meilleures Pratiques

### Optimisation des Performances GPU

1. **Traitement par lots** : Traiter plusieurs tuiles en s√©quence pour amortir la surcharge d'initialisation GPU
2. **K-neighbors appropri√©** : Plus grand k = plus de b√©n√©fice de calcul du GPU
3. **Surveiller la m√©moire** : Utiliser `nvidia-smi` pour v√©rifier l'utilisation de la m√©moire GPU
4. **Utiliser workers=1 avec GPU** : Le GPU parall√©lise en interne, plusieurs workers peuvent rivaliser pour les ressources GPU

### Gestion des Erreurs

La biblioth√®que g√®re les erreurs GPU avec √©l√©gance :

```python
# Basculement automatique vers CPU
processor = LiDARProcessor(use_gpu=True)

# Si le GPU √©choue ou n'est pas disponible :
# - Avertissement enregistr√©
# - Utilise automatiquement le CPU
# - Le traitement continue avec succ√®s
```

### Surveillance de l'Utilisation GPU

Surveiller l'utilisation du GPU pendant le traitement :

```bash
# V√©rification ponctuelle
nvidia-smi

# Surveillance continue (mise √† jour chaque seconde)
watch -n 1 nvidia-smi

# Surveillance en temps r√©el
nvidia-smi -l 1
```

## D√©pannage

### "GPU requested but CuPy not available"

**Probl√®me :** CuPy n'est pas install√© ou incompatibilit√© de version CUDA.

**Solution :**

```bash
# V√©rifier la version CUDA
nvidia-smi

# Installer la version CuPy correspondante
pip install cupy-cuda11x  # pour CUDA 11.x
pip install cupy-cuda12x  # pour CUDA 12.x
```

### Erreur "Out of memory"

**Probl√®me :** M√©moire GPU insuffisante pour la taille du nuage de points.

**Solutions :**

1. Traiter les tuiles en plus petits lots
2. R√©duire la taille des lots dans le calculateur GPU
3. Utiliser le CPU pour les tr√®s grandes tuiles

```python
# R√©duire la taille des lots pour les grandes tuiles
from ign_lidar.features_gpu import GPUFeatureComputer

computer = GPUFeatureComputer(use_gpu=True, batch_size=50000)
```

### Performances lentes sur GPU

**Causes possibles :**

1. **GPU non utilis√©** : V√©rifier avec `nvidia-smi`
2. **Petits nuages de points** : La surcharge GPU domine (utiliser CPU pour &lt;10K points)
3. **Goulot d'√©tranglement de transfert m√©moire** : Regrouper plusieurs op√©rations ensemble

**Solutions :**

```bash
# Surveiller l'utilisation GPU pendant le traitement
watch -n 1 nvidia-smi

# Utiliser le GPU uniquement pour les grands lots
# (g√©r√© automatiquement par la biblioth√®que)
```

### Avertissements d'importation CuPy

**Probl√®me :** Avertissements concernant la version CUDA ou les biblioth√®ques cuBLAS.

**Solution :** G√©n√©ralement sans danger si les op√©rations se terminent avec succ√®s. Pour supprimer :

```python
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='cupy')
```

### Arbre de D√©cision de D√©pannage

```mermaid
flowchart TD
    Start([GPU Issues?]) --> Check1{CUDA Available?}

    Check1 -->|No| Install[Install CUDA Toolkit<br/>+ GPU Drivers]
    Check1 -->|Yes| Check2{Out of Memory?}

    Install --> Restart[Restart System]
    Restart --> Check1

    Check2 -->|Yes| MemFix[Reduce Memory Usage]
    Check2 -->|No| Check3{Slow Performance?}

    MemFix --> MemOptions[‚Ä¢ Lower gpu_memory_limit<br/>‚Ä¢ Reduce batch_size<br/>‚Ä¢ Use smaller tiles]
    MemOptions --> Test1[Test Again]

    Check3 -->|Yes| PerfFix[Optimize Settings]
    Check3 -->|No| Check4{Driver Issues?}

    PerfFix --> PerfOptions[‚Ä¢ Update GPU drivers<br/>‚Ä¢ Check GPU utilization<br/>‚Ä¢ Verify CUDA version]
    PerfOptions --> Test2[Test Again]

    Check4 -->|Yes| DriverFix[Update Drivers]
    Check4 -->|No| Success[GPU Working]

    DriverFix --> Test3[Test Again]
    Test1 --> Success
    Test2 --> Success
    Test3 --> Success

    style Start fill:#e3f2fd
    style Success fill:#e8f5e8
    style Install fill:#fff3e0
    style MemFix fill:#fff3e0
    style PerfFix fill:#fff3e0
    style DriverFix fill:#fff3e0
```

## FAQ

### Q : Puis-je utiliser des GPUs AMD ?

**R :** Actuellement, seuls les GPUs NVIDIA avec CUDA sont support√©s. Le support AMD ROCm pourrait √™tre ajout√© dans les versions futures.

### Q : Le GPU fonctionne-t-il sur WSL2 ?

**R :** Oui ! Le support CUDA dans WSL2 n√©cessite :

- Windows 11 ou Windows 10 21H2+
- Pilotes NVIDIA install√©s sur Windows
- CUDA toolkit install√© dans WSL2

Voir le [guide WSL NVIDIA](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)

### Q : Qu'en est-il de Google Colab / Kaggle ?

**R :** Oui, fonctionne parfaitement dans les notebooks cloud avec runtime GPU. Exemple :

```python
# Installer dans Colab
!pip install ign-lidar-hd[gpu]

# Utiliser le GPU (d√©tect√© automatiquement)
from ign_lidar.processor import LiDARProcessor
processor = LiDARProcessor(use_gpu=True)
```

### Q : Cela fonctionne-t-il avec TensorFlow/PyTorch ?

**R :** Oui, CuPy et TensorFlow/PyTorch peuvent coexister. Ils partagent la m√©moire GPU. Surveillez l'utilisation pour √©viter les erreurs OOM.

### Q : Puis-je m√©langer le traitement CPU et GPU ?

**R :** Oui ! Utilisez `use_gpu=True` pour le calcul des caract√©ristiques mais les autres op√©rations (I/O, extraction de patches) restent sur CPU pour des performances optimales.

## Compatibilit√© des Versions

| ign-lidar-hd | CuPy  | CUDA        | Python |
| ------------ | ----- | ----------- | ------ |
| 1.5.0+       | 10.0+ | 11.0 - 12.x | 3.8+   |
| 1.3.0+       | 10.0+ | 11.0 - 12.x | 3.8+   |
| 1.2.1+       | 10.0+ | 11.0+       | 3.8+   |

## üöÄ D√©veloppement Futur

Nous d√©veloppons continuellement les capacit√©s d'acc√©l√©ration GPU :

### Phase 3 : Pipeline GPU Avanc√© (En Cours)

- **Traitement GPU Universel** : Acc√©l√©ration GPU du pipeline complet
- **Support Multi-GPU** : Traitement distribu√© sur plusieurs GPUs
- **Algorithmes Avanc√©s** : Indexation spatiale et recherche de voisinage bas√©es sur GPU
- **Optimisation M√©moire** : Pooling m√©moire avanc√© et streaming
- **Analytique de Performance** : Surveillance des performances GPU en temps r√©el

**Calendrier Pr√©vu :** Versions progressives tout au long de 2024-2025

### Fonctionnalit√©s √Ä Venir

- üîÑ **Pooling M√©moire GPU** : R√©duire la surcharge d'allocation
- üìä **Tableau de Bord Performance GPU** : Surveillance en temps r√©el
- üåê **Traitement Multi-GPU** : Traitement de tuiles en parall√®le
- ‚ö° **Traitement en Streaming** : G√©rer des jeux de donn√©es plus grands que la m√©moire GPU
- üéØ **S√©lection Auto-GPU** : Distribution intelligente des t√¢ches GPU/CPU

:::info Restez Inform√©
Suivez notre [d√©p√¥t GitHub](https://github.com/sducournau/IGN_LIDAR_HD_DATASET) pour les derniers d√©veloppements d'acc√©l√©ration GPU et annonces de versions.
:::

## Voir Aussi

- **[Fonctionnalit√©s GPU](features.md)** - Calcul de caract√©ristiques d√©taill√© et r√©f√©rence API
- **[Acc√©l√©ration RGB GPU](rgb-augmentation.md)** - Augmentation RGB acc√©l√©r√©e par GPU (v1.5.0+)
- **[Architecture](../architecture.md)** - Architecture syst√®me
- **[Flux de Travail](../workflows.md)** - Exemples de flux de travail GPU

## Ressources Externes

- [CuPy: NumPy-compatible Array Library](https://cupy.dev/)
- [RAPIDS cuML: GPU-Accelerated Machine Learning](https://rapids.ai/)
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)
- [RAPIDS cuML](https://rapids.ai/)
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)
- [GPU-Accelerated Computing](https://www.nvidia.com/en-us/data-center/gpu-accelerated-applications/)
