---
sidebar_position: 1
title: "Aper√ßu de l'Acc√©l√©ration GPU"
description: "Configuration et utilisation de l'acc√©l√©ration GPU pour un traitement LiDAR plus rapide"
keywords: [gpu, cuda, cupy, performance, acc√©l√©ration]
---

# Aper√ßu de l'Acc√©l√©ration GPU

**Disponible depuis :** v1.3.0+  
**Boost de Performance :** 5-10x plus rapide que CPU  
**Requis :** GPU NVIDIA avec CUDA 11.0+

:::tip Statut du D√©veloppement GPU
üöß **Am√©lioration GPU Majeure en Cours** - Nous impl√©mentons une acc√©l√©ration GPU compl√®te √† travers tout le pipeline. Voir notre feuille de route d√©taill√©e dans la section "D√©veloppement Futur" ci-dessous pour les fonctionnalit√©s √† venir.
:::

## Aper√ßu

L'acc√©l√©ration GPU peut fournir une **acc√©l√©ration de 4-10x** pour le calcul des caract√©ristiques par rapport au traitement CPU, ce qui la rend essentielle pour les grands jeux de donn√©es LiDAR et les pipelines de production.

### Avantages

- ‚ö° **4-10x plus rapide** calcul des caract√©ristiques
- üîÑ **Repli automatique sur CPU** quand GPU indisponible
- üì¶ **Aucun changement de code** requis - juste un flag
- üéØ **Pr√™t pour la production** avec gestion compl√®te des erreurs
- üíæ **Efficace en m√©moire** avec traitement par lots intelligent

:::tip Gains de Performance
L'acc√©l√©ration GPU est plus b√©n√©fique pour les nuages de points avec >100K points. Pour les petits datasets, le traitement CPU peut √™tre plus rapide en raison de l'overhead d'initialisation GPU.
:::

## Pr√©requis

### Pr√©requis Mat√©riels

- **GPU :** GPU NVIDIA avec support CUDA
- **M√©moire :** 4GB+ RAM GPU recommand√©e (8GB+ pour grandes dalles)
- **Capacit√© de Calcul :** 3.5 ou sup√©rieur

### Pr√©requis Logiciels

- **CUDA Toolkit :** 11.0 ou sup√©rieur (11.8 ou 12.x recommand√©)
- **Python :** 3.8 ou sup√©rieur
- **Packages Python :** CuPy (requis), RAPIDS cuML (optionnel, meilleures performances)

### Mod√®les GPU Test√©s

| Mod√®le GPU  | M√©moire | Performance | Notes                    |
| ----------- | ------- | ----------- | ------------------------ |
| RTX 4090    | 24 GB   | Excellente  | Meilleure performance    |
| RTX 3080    | 10 GB   | Tr√®s Bonne  | Bon rapport qualit√©/prix |
| RTX 3060    | 12 GB   | Bonne       | √âconomique               |
| Tesla V100  | 16 GB   | Tr√®s Bonne  | Serveur/cloud            |
| GTX 1080 Ti | 11 GB   | Mod√©r√©e     | Ancienne g√©n√©ration      |

## Installation

### √âtape 1 : V√©rifier la Disponibilit√© CUDA

D'abord, v√©rifiez que vous avez un GPU NVIDIA et CUDA install√© :

```bash
# V√©rifier si vous avez un GPU NVIDIA
nvidia-smi

# Devrait afficher les infos de votre GPU et la version CUDA
```

Si `nvidia-smi` n'est pas trouv√©, vous devez d'abord installer les pilotes NVIDIA et le CUDA Toolkit.

### √âtape 2 : Installer le CUDA Toolkit

Visitez [NVIDIA CUDA Downloads](https://developer.nvidia.com/cuda-downloads) et suivez les instructions pour votre OS.

**Versions recommand√©es :**

- CUDA 11.8 (le plus compatible)
- CUDA 12.x (derni√®res fonctionnalit√©s)

:::info Support WSL2
L'acc√©l√©ration GPU fonctionne sur WSL2 ! Pr√©requis :

- Windows 11 ou Windows 10 21H2+
- Pilotes NVIDIA install√©s sur Windows
- CUDA toolkit install√© dans WSL2

Voir le [guide NVIDIA WSL](https://docs.nvidia.com/cuda/wsl-user-guide/index.html) pour les d√©tails.
:::

### √âtape 3 : Installer les D√©pendances GPU Python

```bash
# Option 1: Basic GPU support with CuPy (recommended for most users)
pip install ign-lidar-hd[gpu]

# Option 2: Advanced GPU with RAPIDS cuML (best performance)
pip install ign-lidar-hd[gpu-full]

# Option 3: RAPIDS via conda (recommended for RAPIDS cuML)
conda install -c rapidsai -c conda-forge -c nvidia cuml
pip install ign-lidar-hd[gpu]

# Option 4: Manual installation
# For CUDA 11.x
pip install cupy-cuda11x
pip install cuml-cu11  # Optional: RAPIDS cuML

# For CUDA 12.x
pip install cupy-cuda12x
pip install cuml-cu12  # Optional: RAPIDS cuML
```

**Installation Recommendations:**

- **CuPy only** (`[gpu]`): Easiest installation, 5-6x speedup
- **CuPy + RAPIDS** (`[gpu-full]`): Best performance, up to 10x speedup
- **Conda for RAPIDS**: More reliable for RAPIDS cuML dependencies

### Step 4: Verify Installation

```python
from ign_lidar.features_gpu import GPU_AVAILABLE, CUML_AVAILABLE

print(f"GPU (CuPy) available: {GPU_AVAILABLE}")
print(f"RAPIDS cuML available: {CUML_AVAILABLE}")
```

Expected output:

```
GPU (CuPy) available: True
RAPIDS cuML available: True
```

## D√©marrage Rapide

### Interface en Ligne de Commande

Ajoutez simplement le flag `--use-gpu` √† n'importe quelle commande `enrich` :

```bash
# Utilisation de base
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu

# Avec options additionnelles
ign-lidar-hd enrich \
  --input tiles/ \
  --output enriched/ \
  --use-gpu \
  --mode full \
  --num-workers 4
```

:::tip Repli Automatique
Le flag `--use-gpu` basculera automatiquement sur CPU si le GPU n'est pas disponible. Votre traitement continuera sans erreurs.
:::

### Python API

#### Using LiDARProcessor

```python
from pathlib import Path
from ign_lidar.processor import LiDARProcessor

# Create processor with GPU acceleration
processor = LiDARProcessor(
    lod_level='LOD2',
    patch_size=150.0,
    num_points=16384,
    use_gpu=True  # ‚ö° Enable GPU
)

# Process tiles - automatic GPU acceleration
num_patches = processor.process_tile(
    laz_file=Path("data/tiles/tile.laz"),
    output_dir=Path("data/patches")
)

print(f"Created {num_patches} patches using GPU")
```

#### Direct Feature Computation

```python
import numpy as np
from ign_lidar.features import compute_all_features_with_gpu

# Load your point cloud
points = np.random.rand(1000000, 3).astype(np.float32)
classification = np.random.randint(0, 10, 1000000).astype(np.uint8)

# Compute features with GPU
normals, curvature, height, geo_features = compute_all_features_with_gpu(
    points=points,
    classification=classification,
    k=10,
    auto_k=False,
    use_gpu=True  # Enables GPU
)

print(f"Computed {len(normals)} normals on GPU")
```

## Configuration

### Python Configuration

```python
from ign_lidar import Config

config = Config(
    use_gpu=True,
    gpu_memory_limit=0.8,  # Use 80% of GPU memory
    cuda_device=0  # Use first GPU (if multiple)
)
```

### Environment Variables

```bash
# Specify CUDA device (if multiple GPUs)
export CUDA_VISIBLE_DEVICES=0

# Limit GPU memory usage
export CUPY_GPU_MEMORY_LIMIT="8GB"
```

```python
import os

# Set before importing ign_lidar
os.environ['CUDA_VISIBLE_DEVICES'] = '0'

from ign_lidar.processor import LiDARProcessor
```

## When to Use GPU

### ‚úÖ Use GPU for:

- Large point clouds (>100K points)
- Batch processing of many tiles
- Production pipelines requiring speed
- Real-time or interactive applications
- Processing 10+ tiles

### ‚ùå Use CPU for:

- Small point clouds (&lt;10K points)
- One-off processing tasks
- Systems without NVIDIA GPU
- Prototyping and debugging
- Quick tests with 1-2 tiles

### Decision Tree

```mermaid
flowchart TD
    Start([Need to Process LiDAR]) --> Size{Point Cloud Size}

    Size -->|< 10K points| UseCPU[Use CPU]
    Size -->|10K - 100K points| Consider{Batch Processing?}
    Size -->|> 100K points| UseGPU[Use GPU]

    Consider -->|Yes, many tiles| UseGPU
    Consider -->|No, 1-2 tiles| Either[Either CPU or GPU]

    UseGPU --> Check{GPU Available?}
    Check -->|Yes| GPUProcess[‚ö° GPU Processing]
    Check -->|No| Fallback[Automatic CPU Fallback]

    UseCPU --> CPUProcess[CPU Processing]
    Either --> CPUProcess
    Fallback --> CPUProcess

    style GPUProcess fill:#e8f5e8
    style CPUProcess fill:#e3f2fd
    style Fallback fill:#fff3e0
```

## Benchmarks de Performance

### Acc√©l√©rations Attendues

Bas√© sur des tests avec diff√©rents GPU :

| Nombre de Points | CPU (12 c≈ìurs) | GPU (RTX 3080) | Acc√©l√©ration |
| ---------------- | -------------- | -------------- | ------------ |
| 1K points        | 0.02s          | 0.01s          | 2x           |
| 10K points       | 0.15s          | 0.03s          | 5x           |
| 100K points      | 0.50s          | 0.08s          | 6.3x         |
| 1M points        | 4.5s           | 0.8s           | 5.6x         |
| 10M points       | 45s            | 8s             | 5.6x         |

**Factors affecting performance:**

- GPU model and memory
- Point cloud density and distribution
- K-neighbors parameter (larger = more computation)
- CPU baseline (more cores = smaller relative speedup)

### Performance Comparison

```mermaid
xychart-beta
    title "Processing Speed Comparison (Tiles per Hour)"
    x-axis [Small Tiles, Medium Tiles, Large Tiles, Very Large Tiles]
    y-axis "Tiles per Hour" 0 --> 60
    bar "CPU (8 cores)" [12, 8, 4, 2]
    bar "GPU (RTX 3080)" [48, 32, 20, 12]
    bar "GPU (RTX 4090)" [60, 40, 28, 16]
```

### Benchmarking de Votre Syst√®me

Utilisez le script de benchmark inclus pour tester les performances GPU vs CPU :

```bash
# Benchmark synth√©tique rapide
python scripts/benchmarks/benchmark_gpu.py --synthetic

# Benchmark avec des donn√©es r√©elles
python scripts/benchmarks/benchmark_gpu.py path/to/file.laz

# Comprehensive multi-size benchmark
python scripts/benchmarks/benchmark_gpu.py --multi-size
```

## Best Practices

### Optimizing GPU Performance

1. **Batch processing**: Process multiple tiles in sequence to amortize GPU initialization overhead
2. **Appropriate k-neighbors**: Larger k = more computation benefit from GPU
3. **Monitor memory**: Use `nvidia-smi` to check GPU memory usage
4. **Use workers=1 with GPU**: GPU parallelizes internally, multiple workers may compete for GPU resources

### Error Handling

The library handles GPU errors gracefully:

```python
# Automatic CPU fallback
processor = LiDARProcessor(use_gpu=True)

# If GPU fails or unavailable:
# - Warning logged
# - Automatically uses CPU
# - Processing continues successfully
```

### Monitoring GPU Usage

Monitor GPU utilization during processing:

```bash
# One-time check
nvidia-smi

# Continuous monitoring (updates every second)
watch -n 1 nvidia-smi

# Real-time monitoring
nvidia-smi -l 1
```

## Troubleshooting

### "GPU requested but CuPy not available"

**Problem:** CuPy is not installed or CUDA version mismatch.

**Solution:**

```bash
# Check CUDA version
nvidia-smi

# Install matching CuPy version
pip install cupy-cuda11x  # for CUDA 11.x
pip install cupy-cuda12x  # for CUDA 12.x
```

### "Out of memory" error

**Problem:** GPU memory insufficient for point cloud size.

**Solutions:**

1. Process tiles in smaller batches
2. Reduce batch size in GPU computer
3. Use CPU for very large tiles

```python
# Reduce batch size for large tiles
from ign_lidar.features_gpu import GPUFeatureComputer

computer = GPUFeatureComputer(use_gpu=True, batch_size=50000)
```

### Slow performance on GPU

**Possible causes:**

1. **GPU not utilized**: Check with `nvidia-smi`
2. **Small point clouds**: GPU overhead dominates (use CPU for &lt;10K points)
3. **Memory transfer bottleneck**: Batch multiple operations together

**Solutions:**

```bash
# Monitor GPU usage while processing
watch -n 1 nvidia-smi

# Use GPU for large batches only
# (automatically handled by the library)
```

### CuPy import warnings

**Problem:** Warnings about CUDA version or cuBLAS libraries.

**Solution:** Usually safe to ignore if operations complete successfully. To suppress:

```python
import warnings
warnings.filterwarnings('ignore', category=UserWarning, module='cupy')
```

### Troubleshooting Decision Tree

```mermaid
flowchart TD
    Start([GPU Issues?]) --> Check1{CUDA Available?}

    Check1 -->|No| Install[Install CUDA Toolkit<br/>+ GPU Drivers]
    Check1 -->|Yes| Check2{Out of Memory?}

    Install --> Restart[Restart System]
    Restart --> Check1

    Check2 -->|Yes| MemFix[Reduce Memory Usage]
    Check2 -->|No| Check3{Slow Performance?}

    MemFix --> MemOptions[‚Ä¢ Lower gpu_memory_limit<br/>‚Ä¢ Reduce batch_size<br/>‚Ä¢ Use smaller tiles]
    MemOptions --> Test1[Test Again]

    Check3 -->|Yes| PerfFix[Optimize Settings]
    Check3 -->|No| Check4{Driver Issues?}

    PerfFix --> PerfOptions[‚Ä¢ Update GPU drivers<br/>‚Ä¢ Check GPU utilization<br/>‚Ä¢ Verify CUDA version]
    PerfOptions --> Test2[Test Again]

    Check4 -->|Yes| DriverFix[Update Drivers]
    Check4 -->|No| Success[GPU Working]

    DriverFix --> Test3[Test Again]
    Test1 --> Success
    Test2 --> Success
    Test3 --> Success

    style Start fill:#e3f2fd
    style Success fill:#e8f5e8
    style Install fill:#fff3e0
    style MemFix fill:#fff3e0
    style PerfFix fill:#fff3e0
    style DriverFix fill:#fff3e0
```

## FAQ

### Q: Can I use AMD GPUs?

**A:** Currently only NVIDIA GPUs with CUDA are supported. AMD ROCm support may be added in future versions.

### Q: Does GPU work on WSL2?

**A:** Yes! CUDA support in WSL2 requires:

- Windows 11 or Windows 10 21H2+
- NVIDIA drivers installed on Windows
- CUDA toolkit installed in WSL2

See [NVIDIA WSL guide](https://docs.nvidia.com/cuda/wsl-user-guide/index.html)

### Q: What about Google Colab / Kaggle?

**A:** Yes, works great in cloud notebooks with GPU runtime. Example:

```python
# Install in Colab
!pip install ign-lidar-hd[gpu]

# Use GPU (automatically detected)
from ign_lidar.processor import LiDARProcessor
processor = LiDARProcessor(use_gpu=True)
```

### Q: Does this work with TensorFlow/PyTorch?

**A:** Yes, CuPy and TensorFlow/PyTorch can coexist. They share GPU memory. Monitor usage to avoid OOM errors.

### Q: Can I mix CPU and GPU processing?

**A:** Yes! Use `use_gpu=True` for feature computation but other operations (I/O, patch extraction) remain on CPU for optimal performance.

## Version Compatibility

| ign-lidar-hd | CuPy  | CUDA        | Python |
| ------------ | ----- | ----------- | ------ |
| 1.5.0+       | 10.0+ | 11.0 - 12.x | 3.8+   |
| 1.3.0+       | 10.0+ | 11.0 - 12.x | 3.8+   |
| 1.2.1+       | 10.0+ | 11.0+       | 3.8+   |

## üöÄ D√©veloppement Futur

Nous √©tendons continuellement les capacit√©s d'acc√©l√©ration GPU :

### Phase 3 : Pipeline GPU Avanc√© (En Cours)

- **Traitement GPU Universel** : Acc√©l√©ration GPU compl√®te du pipeline
- **Support Multi-GPU** : Traitement distribu√© sur plusieurs GPU
- **Algorithmes Avanc√©s** : Indexation spatiale et recherche de voisinage bas√©es GPU
- **Optimisation M√©moire** : Pooling m√©moire avanc√© et streaming
- **Analytiques de Performance** : Surveillance des performances GPU en temps r√©el

**Calendrier Pr√©vu :** Versions progressives tout au long de 2024-2025

### Fonctionnalit√©s √† Venir

- üîÑ **Pooling M√©moire GPU** : R√©duction de l'overhead d'allocation
- üìä **Tableau de Bord Performance GPU** : Surveillance temps r√©el
- üåê **Traitement Multi-GPU** : Traitement parall√®le des dalles
- ‚ö° **Traitement en Streaming** : Gestion de datasets plus grands que la m√©moire GPU
- üéØ **S√©lection GPU Automatique** : Distribution intelligente des t√¢ches GPU/CPU

:::info Restez Inform√©
Suivez notre [d√©p√¥t GitHub](https://github.com/sducournau/IGN_LIDAR_HD_DATASET) pour les derniers d√©veloppements d'acc√©l√©ration GPU et les annonces de version.
:::

## Voir Aussi

- **[Fonctionnalit√©s GPU](features.md)** - Calcul de caract√©ristiques d√©taill√© et r√©f√©rence API
- **[Acc√©l√©ration GPU RGB](rgb-augmentation.md)** - Augmentation RGB acc√©l√©r√©e GPU (v1.5.0+)
- **[Architecture](../architecture.md)** - Architecture syst√®me
- **[Workflows](../workflows.md)** - Exemples de workflows GPU

## Ressources Externes

- [CuPy: Biblioth√®que de Tableaux Compatible NumPy](https://cupy.dev/)
- [RAPIDS cuML: Apprentissage Automatique Acc√©l√©r√© GPU](https://rapids.ai/)
- [NVIDIA CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit)
