---
sidebar_position: 1
title: Notes de Version v1.7.4
description: Acc√©l√©ration GPU et am√©liorations de performance
---

# Version 1.7.4 - Acc√©l√©ration GPU et Am√©liorations de Performance

**Date de sortie** : 4 octobre 2025  
**Type** : Version de fonctionnalit√©s  
**Th√®me** : Acc√©l√©ration GPU et Performance

---

## üöÄ Fonctionnalit√©s Principales

### 1. Support d'Acc√©l√©ration GPU

Cette version introduit un support complet d'acc√©l√©ration GPU, offrant des am√©liorations de performance spectaculaires pour le traitement LiDAR.

#### Trois Modes de Performance

**Mode CPU Uniquement** (Ligne de Base)

- Traitement standard sans GPU requis
- Utilise NumPy et scikit-learn
- Temps de traitement : 60 minutes pour 17M points
- Parfait pour les petits ensembles de donn√©es ou les syst√®mes sans GPU

**Mode Hybride GPU (CuPy)**

- Tableaux GPU avec algorithmes CPU
- N√©cessite uniquement CuPy (installation facile)
- **Acc√©l√©ration 6-8x** sur CPU
- Temps de traitement : 7-10 minutes pour 17M points
- Id√©al pour le d√©marrage rapide et les tests

**Mode GPU Complet (RAPIDS cuML)**

- Pipeline de traitement GPU complet de bout en bout
- N√©cessite RAPIDS cuML (installation conda)
- **Acc√©l√©ration 12-20x** sur CPU
- Temps de traitement : 3-5 minutes pour 17M points
- Recommand√© pour les charges de travail en production

#### Benchmarks de Performance

| Mode                     | Temps    | Acc√©l√©ration | M√©moire GPU | RAM   |
| ------------------------ | -------- | ------------ | ----------- | ----- |
| CPU Uniquement           | 60 min   | 1x           | 0 GB        | 24 GB |
| Hybride (CuPy + sklearn) | 7-10 min | 6-8x         | 6 GB        | 16 GB |
| GPU Complet (RAPIDS)     | 3-5 min  | 12-20x       | 8 GB        | 12 GB |

**Mat√©riel de test** : NVIDIA RTX 4080 16GB, WSL2 Ubuntu 24.04, 32GB RAM, CUDA 13.0

#### Utilisation

```bash
# Activer l'acc√©l√©ration GPU - un seul flag
ign-lidar-hd enrich --input-dir data/ --output enriched/ --use-gpu

# Avec toutes les fonctionnalit√©s
ign-lidar-hd enrich \
  --input-dir data/ \
  --output enriched/ \
  --use-gpu \
  --auto-params \
  --preprocess \
  --add-rgb \
  --add-infrared
```

### 2. Optimisation de Strat√©gie Per-Chunk

Impl√©mentation d'une strat√©gie intelligente de traitement par blocs locaux qui offre d'excellentes performances m√™me sans RAPIDS cuML.

**Comment √ßa fonctionne :**

1. Divise le nuage de points en blocs de ~5M points
2. Construit un KDTree local pour chaque bloc
3. Utilise 5% de chevauchement pour g√©rer les cas limites
4. Fusionne les r√©sultats de mani√®re transparente

**B√©n√©fices :**

- 80-90% des performances du GPU complet sans cuML
- Pas de goulot d'√©tranglement de m√©moire sur les grandes tuiles
- Fonctionne avec n'importe quelle taille de nuage de points
- Am√©lioration de performance de 10x sur le KDTree global

### 3. Documentation Compl√®te

Documentation extensive pour l'acc√©l√©ration GPU dans toutes les langues :

**Documentation Anglaise :**

- Guide complet d'acc√©l√©ration GPU
- Guide d'installation RAPIDS cuML
- Guide de d√©marrage rapide GPU
- R√©sum√© de l'impl√©mentation technique

**Documentation Fran√ßaise :**

- Guide d'acc√©l√©ration GPU traduit
- Instructions d'installation compl√®tes
- Exemples et meilleures pratiques

**Contenu :**

- Trois options d'installation (facile ‚Üí avanc√©)
- Benchmarks mat√©riels r√©els
- Guide de d√©pannage complet
- Instructions sp√©cifiques WSL2
- Exemples d'API Python
- Configuration de pipeline YAML

---

## üìö Am√©liorations de Documentation

### Nouvelles Ressources de Documentation

1. **GPU_QUICK_START.md** - R√©f√©rence de configuration rapide
2. **GPU_IMPLEMENTATION_SUMMARY.md** - D√©tails techniques de l'impl√©mentation
3. **INSTALL_CUML_GUIDE.md** - Guide d'installation RAPIDS
4. **PER_CHUNK_OPTIMIZATION.md** - Explication de la strat√©gie
5. **install_cuml.sh** - Script d'installation automatis√©
6. **install_cuda_wsl2.sh** - Installation CUDA Toolkit

### Documentation Am√©lior√©e

- **README.md** : Ajout de la section "Nouveaut√©s v1.7.4"
- **CHANGELOG.md** : Entr√©e d√©taill√©e v1.7.4
- **website/docs/intro.md** : Mise √† jour avec les fonctionnalit√©s GPU
- **website/i18n/fr/.../intro.md** : Version fran√ßaise mise √† jour
- **Release Notes** : Notes de version compl√®tes (EN/FR)

---

## üîß Am√©liorations Techniques

### D√©tection et Bascule GPU

```python
# D√©tection automatique et bascule √©l√©gante
try:
    import cupy as cp
    import cuml
    GPU_AVAILABLE = True
    CUML_AVAILABLE = True
except ImportError:
    GPU_AVAILABLE = False  # Bascule vers CPU
```

### S√©lection Intelligente de Strat√©gie

Le syst√®me s√©lectionne automatiquement la meilleure approche :

- **Avec cuML** : Utilise KDTree GPU global (le plus rapide)
- **Sans cuML** : Utilise KDTree per-chunk CPU (toujours rapide)
- **Sans GPU** : Traitement CPU standard

### Gestion de M√©moire Optimis√©e

- D√©coupage automatique pour les nuages de points volumineux
- Pooling m√©moire GPU efficace
- Garbage collection entre les tuiles
- Gestion √©l√©gante des erreurs OOM

---

## üêõ Corrections de Bugs

### D√©tection GPU

**Probl√®me** : Le code n√©cessitait √† la fois CuPy ET cuML pour activer le GPU  
**Correction** : Indicateurs s√©par√©s - fonctionne avec CuPy seul (mode hybride)

```python
# Avant : n√©cessitait les deux
use_gpu = use_gpu and GPU_AVAILABLE and CUML_AVAILABLE

# Apr√®s : fonctionne avec CuPy seul
use_gpu = use_gpu and GPU_AVAILABLE
```

### Performance KDTree Global

**Probl√®me** : KDTree global lent sur CPU sklearn (15-20 min)  
**Correction** : Strat√©gie per-chunk avec chevauchement (2-3 min)

### D√©tection CUDA CuPy

**Probl√®me** : CuPy ne trouvait pas les biblioth√®ques CUDA sur WSL2  
**Correction** : Instructions d'installation compl√®tes de CUDA Toolkit + configuration LD_LIBRARY_PATH

---

## üì¶ Installation

### Mode Hybride (D√©marrage Rapide)

```bash
# Installer CuPy pour CUDA 12.x
pip install cupy-cuda12x

# Ou pour CUDA 11.x
pip install cupy-cuda11x
```

### Mode GPU Complet (Performance Maximale)

```bash
# Cr√©er un environnement conda
conda create -n ign_gpu python=3.12 -y
conda activate ign_gpu

# Installer RAPIDS cuML
conda install -c rapidsai -c conda-forge -c nvidia \
    cuml=24.10 cupy cudatoolkit=12.5 -y

# Installer IGN LiDAR HD
pip install ign-lidar-hd
```

### Installation Automatis√©e

```bash
# T√©l√©charger et ex√©cuter le script d'installation
wget https://raw.githubusercontent.com/sducournau/IGN_LIDAR_HD_DATASET/main/install_cuml.sh
chmod +x install_cuml.sh
./install_cuml.sh
```

---

## üéØ Guide de Migration

### Depuis v1.7.3

**Aucun changement de rupture** - le support GPU est enti√®rement optionnel !

```bash
# Comportement existant (CPU) - fonctionne toujours
ign-lidar-hd enrich --input-dir data/ --output enriched/

# Nouveau comportement (GPU) - ajouter simplement --use-gpu
ign-lidar-hd enrich --input-dir data/ --output enriched/ --use-gpu
```

**API Python** - √©galement r√©trocompatible :

```python
# Code existant - aucun changement requis
processor = LiDARProcessor(lod_level="LOD2")

# Nouveau code - activer le GPU
processor = LiDARProcessor(lod_level="LOD2", use_gpu=True)
```

### Depuis v1.7.0-1.7.2

M√™mes instructions que ci-dessus. Toutes les fonctionnalit√©s (auto-params, pr√©traitement, RGB, infrarouge) fonctionnent avec l'acc√©l√©ration GPU.

### Depuis v1.6.x ou ant√©rieur

Consultez les notes de version pr√©c√©dentes pour conna√Ætre les nouvelles fonctionnalit√©s interm√©diaires :

- v1.7.3 : Augmentation infrarouge
- v1.7.1 : Auto-param√®tres
- v1.7.0 : Pr√©traitement

---

## üìä Benchmarks de Performance D√©taill√©s

### Tuile Unique (17M points)

#### Extraction de Caract√©ristiques

| Op√©ration               | CPU    | GPU Hybride | GPU Complet | Meilleure Acc√©l√©ration |
| ----------------------- | ------ | ----------- | ----------- | ---------------------- |
| Calcul des Normales     | 25 min | 4 min       | 1.5 min     | 16x                    |
| Recherche KNN           | 20 min | 12 min      | 1 min       | 20x                    |
| PCA (valeurs propres)   | 8 min  | 6 min       | 0.5 min     | 16x                    |
| Calcul de Courbure      | 5 min  | 2 min       | 0.5 min     | 10x                    |
| Autres Caract√©ristiques | 2 min  | 1 min       | 0.5 min     | 4x                     |

**Total** : 60 min ‚Üí 7-10 min ‚Üí 3-5 min

### Traitement par Lots (100 tuiles)

- **CPU Uniquement** : ~100 heures
- **Mode Hybride** : ~14 heures (acc√©l√©ration 7x)
- **Mode GPU Complet** : ~6 heures (acc√©l√©ration 16x)

### Validation de Pr√©cision

Les trois modes produisent des **r√©sultats identiques** (v√©rifi√© avec corr√©lation de caract√©ristiques > 0.9999).

---

## üí° Meilleures Pratiques

### 1. Choisir le Bon Mode

- **D√©veloppement/Tests** : Mode hybride (configuration facile, bonnes performances)
- **Production** : Mode GPU complet avec RAPIDS cuML (performance maximale)
- **Pas de GPU** : Mode CPU fonctionne bien pour les petits lots

### 2. Mat√©riel Recommand√©

| Cas d'Usage                    | GPU Minimum   | GPU Recommand√© | GPU Optimal      |
| ------------------------------ | ------------- | -------------- | ---------------- |
| Apprentissage/Petits ensembles | GTX 1660 6GB  | RTX 3060 12GB  | RTX 4060 Ti 16GB |
| Production/Lots moyens         | RTX 3060 12GB | RTX 4070 12GB  | RTX 4080 16GB    |
| Traitement √† grande √©chelle    | RTX 3080 10GB | RTX 4080 16GB  | A6000 48GB       |

### 3. Surveiller les Ressources

```bash
# Surveiller l'utilisation GPU en temps r√©el
watch -n 1 nvidia-smi

# Surveiller avec des m√©triques d√©taill√©es
nvidia-smi dmon -s pucvmet -d 1
```

### 4. Configuration Pipeline Optimale

```yaml
global:
  num_workers: 4 # Parall√©liser les E/S pendant le traitement GPU

enrich:
  use_gpu: true
  auto_params: true
  preprocess: true
  add_rgb: true
  add_infrared: true
```

---

## üîó Ressources

### Documentation

- [Guide d'Acc√©l√©ration GPU](../guides/gpu-acceleration.md)
- [Guide de D√©marrage Rapide](../guides/quick-start.md)
- [R√©f√©rence API](../api/processor.md)
- [Configuration Pipeline](../api/pipeline-config.md)

### R√©f√©rences Externes

- [Documentation CuPy](https://docs.cupy.dev/en/stable/)
- [Documentation RAPIDS cuML](https://docs.rapids.ai/api/cuml/stable/)
- [Guide d'Installation CUDA](https://docs.nvidia.com/cuda/cuda-installation-guide-linux/)
- [Support WSL2 CUDA](https://docs.nvidia.com/cuda/wsl-user-guide/)

### Fichiers du D√©p√¥t

- [README.md](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/blob/main/README.md)
- [CHANGELOG.md](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/blob/main/CHANGELOG.md)
- [GPU_QUICK_START.md](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/blob/main/GPU_QUICK_START.md)
- [INSTALL_CUML_GUIDE.md](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/blob/main/INSTALL_CUML_GUIDE.md)

---

## üéì Sujets Avanc√©s

### Strat√©gie d'Optimisation Per-Chunk

Lorsque RAPIDS cuML n'est pas disponible, le syst√®me utilise une strat√©gie intelligente per-chunk :

1. **Divise le nuage de points** en blocs de ~5M points
2. **Construit un KDTree local** pour chaque bloc (rapide avec sklearn)
3. **Utilise 5% de chevauchement** pour g√©rer les cas limites
4. **Fusionne les r√©sultats** de mani√®re transparente

Cela fournit 80-90% des performances GPU sans n√©cessiter l'installation de RAPIDS cuML.

### Support Multi-GPU

Actuellement, la biblioth√®que utilise un seul GPU (device 0). Pour le traitement multi-GPU :

```bash
# Traiter diff√©rents r√©pertoires sur diff√©rents GPUs
CUDA_VISIBLE_DEVICES=0 ign-lidar-hd enrich --input dir1/ --output out1/ --use-gpu &
CUDA_VISIBLE_DEVICES=1 ign-lidar-hd enrich --input dir2/ --out out2/ --use-gpu &
```

### Gestion de M√©moire GPU

Le syst√®me g√®re automatiquement la m√©moire GPU :

- **D√©coupage automatique** : Les grands nuages de points sont divis√©s en blocs de taille GPU
- **Pooling m√©moire** : CuPy r√©utilise la m√©moire allou√©e
- **Garbage collection** : Lib√®re la m√©moire entre les tuiles
- **Gestion des erreurs** : G√®re gracieusement les erreurs OOM

---

## üìû Support

### Signaler des Probl√®mes

Si vous rencontrez des probl√®mes avec l'acc√©l√©ration GPU :

1. **V√©rifier la configuration GPU** : `nvidia-smi`
2. **V√©rifier l'installation CuPy** : `python -c "import cupy; print(cupy.__version__)"`
3. **V√©rifier les logs** : Le syst√®me affiche des messages de statut GPU d√©taill√©s
4. **Cr√©er un probl√®me** : [GitHub Issues](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/issues)

### Obtenir de l'Aide

- üìñ [Documentation](https://sducournau.github.io/IGN_LIDAR_HD_DATASET/)
- üí¨ [Discussions GitHub](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/discussions)
- üêõ [Signaler un Bug](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/issues)

---

## üôè Remerciements

- **√âquipe NVIDIA RAPIDS** - Pour la biblioth√®que RAPIDS cuML
- **√âquipe CuPy** - Pour la biblioth√®que de tableaux GPU
- **Communaut√©** - Pour les tests et les retours
- **Contributeurs** - Pour les am√©liorations de documentation

---

## üìù Notes de Version

**v1.7.4** (4 octobre 2025)

### Ajout√©

- Support d'acc√©l√©ration GPU avec trois modes de performance
- Optimisation de strat√©gie per-chunk pour KDTree
- Documentation compl√®te GPU (EN/FR)
- Scripts d'installation automatis√©s
- Support WSL2 avec instructions d'installation CUDA

### Chang√©

- Refactorisation du code GPU pour s√©parer les indicateurs CuPy et cuML
- Structure de documentation am√©lior√©e
- Benchmarks de performance mis √† jour

### Corrig√©

- D√©tection GPU n√©cessitant √† la fois CuPy et cuML
- Performance du KDTree global sur CPU
- D√©tection CUDA CuPy sur WSL2

---

_Pour les versions pr√©c√©dentes, consultez le [CHANGELOG](https://github.com/sducournau/IGN_LIDAR_HD_DATASET/blob/main/CHANGELOG.md)._
